{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "# Analysis of the State and Evolution of Empirical Research in Requirements Engineering\n",
    "\n",
    "**Remark:** This Jupyter Notebook is a supplementary material for the accepted paper \"O. Karras et al.: *Divide and Conquer the EmpiRE: A Community-Maintainable Knowledge Graph of Empirical Research in Requirements Engineering*, In Proceedings of the [17th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement](https://conf.researchr.org/home/esem-2023) (ESEM'23).\".\n",
    "\n",
    "<details>\n",
    "  <summary>Table of Contents</summary>\n",
    "\n",
    "1. [Summary](#step1)\n",
    "2. [Reusable Functions for Data Analysis](#step2)\n",
    "3. [Analysis of Competency Question](#step3)\n",
    "    \n",
    "    3.1 [How has the proportion of empirical studies evolved over time?](#q1)\n",
    "\n",
    "    3.2 [How often are which empirical methods used over time?](#q2)\n",
    "    \n",
    "    3.3 [How has the proportion of papers that do not have an empirical study evolved over time?](#q3)\n",
    "    \n",
    "    3.4 [How often are which empirical methods used?](#q4)\n",
    "\n",
    "    3.5 [How have the proportions of experiments, secondary research (reviews), surveys, case studies, and action research in the empirical methods used evolved over time?](#q5)\n",
    "    \n",
    "    3.6 [How often are which statistical methods used?](#q6)\n",
    "    \n",
    "    3.7 [How has the use of statistical methods evolved over time?](#q7)\n",
    "    \n",
    "    3.8 [How has the reporting of threats to validity evolved over time?](#q8)\n",
    "    \n",
    "    3.9 [What types of threats to validity do the authors report?](#q9)\n",
    "    \n",
    "    3.10 [How have the proportions of case studies and action research in the empirical methods used evolved over time?](#q10)\n",
    "    \n",
    "    3.11 [How has the provision of data (the materials used, the raw data collected, and the study results identified) evolved over time?](#q11)\n",
    "    \n",
    "    3.12 [How has the reporting of research questions and answers evolved over time?](#q12)\n",
    "    \n",
    "    3.13 [What empirical methods are used to conduct integrative and interpretive (systematic literature) reviews, so-called secondary research?](#q13)\n",
    "    \n",
    "    3.14 [How has the proportions of empirical methods to conduct (systematic literature) reviews, so-called secondary research, evolved over time?](#q14)\n",
    "    \n",
    "    3.15 [How many different empirical methods are used per publication?](#q15)\n",
    "    \n",
    "    3.16 [How has the number of empirical methods used per publication evolved over time?](#q16)\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## 1. Summary\n",
    "\n",
    "### Background\n",
    "Empirical research in Requirements Engineering (RE) is a constantly evolving topic. Over the years, several publications examined how empirical research in RE is conducted and how it should be conducted in the future by presenting snapshots of the \"current\" state of empirical research in RE and, more generally, in Software Engineering (SE). These researchers share the same goal of synthesizing a comprehensive, up-to-date, and long-term available overview of the state and evolution of empirical research in RE and SE. Although they share the same goal, use similar methods, i.a., (systematic) literature reviews, and even examine overlapping periods, venues, and themes, they have not collaborated to build on and update earlier works. **Lack of collaboration among researchers** and **updating literature revuews** are two well-known challenges of literature reviews. Overcoming these challenges is critical to ensure the quality, reliability, and timeliness of research findings from literature reviews.\n",
    "\n",
    "### Motivation\n",
    "Recent research addresses the above challenges by focusing on when and how to update (systematic) literature reviews in SE and its subfields. While these works provide social and economic decision support and guidance for updating literature reviews, **the central problem is the unavailability of the extracted and analyzed data**, corresponding to open science in SE. Unavailable data complicates **collaboration among researchers** and **updating literature reviews** as the entire data collection, extraction, and analysis must be repeated and expanded for a comprehensive review. Researchers need support in the form of technical infrastructures and services to conduct sustainable literature reviews so that all data is openly available in the long term according to the FAIR data principles (Findable, Accessible, Interoperable, and Reusable). For this purpose, the data must be organized in a flexible, fine-grained, context-sensitive, and semantic representation to be understandable, processable, and usable by humans and machines. Over the last decade, Knowledge Graphs (KGs) have become an emerging technology in industry and academia as they enable this versatile data representation. Besides well-known KGs for encyclopedic and factual data, such as [DBpedia](https://www.dbpedia.org/) and [WikiData](https://www.wikidata.org), using so-called Research Knowledge Graphs (RKGs) for scientific data is a rather new approach. RKGs include bibliographic metadata, e.g., titles, authors, and venues, as well as scientific data, e.g., research designs, methods, and results. They are a promising technology to sustainably organize scientific data so that the data is openly available for long-term collaborations.\n",
    "\n",
    "### Aims\n",
    "**Our longterm objective is to constantly maintain a KG of empirical research in RE (KG-EmpiRE) with the research community to synthesize a comprehensive, up-to-date, and long-term available overview of the state and evolution of empirical research in RE**. For this purpose, we examine the use of RKGs as technical infrastructure for building and publishing an initial KG-EmpiRE, that the research community can constantly maintain, (re-)use, update, and expand by *dividing* the efforts to *conquer* the EmpiRE. In particular, we use the Open Research Knowledge Graph ([ORKG](https://orkg.org/)), a cross-domain and cross-topic RKG with services using that combine manual crowdsourcing and automated approaches to organize scientific data. With this work, we lay the foundation for such a comprehensive, up-to-date, and long-term available overview of the state and evolution of empirical research in RE by building, publishing, and evaluating the initial KG-EmpiRE.\n",
    "\n",
    "### Method\n",
    "<p align=\"center\">\n",
    "    <img src=\"Figures/approach.png\" width=\"600\"/>\n",
    "    \n",
    "</p>\n",
    "<p align=\"center\">\n",
    "    <em>Research approach for building, publishing, and evaluating the initial KG-EmpiRE.</em>\n",
    "</p>\n",
    "\n",
    "Our research approach consists of three steps: Data collection, Data extraction, and Data analysis. So far, **we collected 570 papers** published in the research track of the [IEEE International Requirements Engineering Conference](https://ieeexplore.ieee.org/xpl/conhome/1000630/all-proceedings) from 2000 to 2022. **We extracted and organized their scientific data**, i.a., research paradigm, research design, empirical method (data collection and data analysis), and bibliographic metadata using a developed [ORKG template](https://orkg.org/template/R186491). ORKG templates are an implementation of a subset of SHACL and allow specifying the structure of descriptions of papers. In this way, we determined which data to extract and ensured that all the descriptions of papers are consistent and comparable to **build and publish the initial KG-EmpiRE**.\n",
    "\n",
    "In this Jupyter Notebook, we perform the data analysis of the KG-EmpiRE, which has two purposes:\n",
    "\n",
    "(1) We evaluate the coverage of the curated topic of empirical research in RE by the initial KG-EmpiRE.\n",
    "\n",
    "(2) We get initial insights into the state and evolution of empirical research in RE.\n",
    "\n",
    "The data analysis is based on competency questions regarding empirical research in SE, including RE, derived from the vision of [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30). [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) describe their vision of the role of empirical methods in SE, including RE, for the period of 2020 – 2025 by comparing the **\"current\" state of practice (2007)** with their **target state (2020 - 2025)**. We analyzed these descriptions and derived a total of [77 competency questions](competency-questions.xlsx). The number of competency questions answered reflects the **coverage of the curated topic in KG-EmpiRE** (1), and the answers to competency questions provide **initial insights into the curated topic** (2). For each competency question that could be answered with KG-EmpiRE, we specified the a [SPARQL](https://www.w3.org/TR/sparql11-query/) query to retrieve and analyze the data from the [ORKG](https://orkg.org/).\n",
    "\n",
    "### Results\n",
    "**Coverage:**\n",
    "\n",
    "Regarding the coverage of the curated topic by the initial KG-EmpirE, we can state that we are able to answer 16 of the 77 competence questions (21%) using the extracted data. While this number of answered competency questions represents an acceptable coverage of the curated topic, the need to expand the [ORKG template](https://orkg.org/template/R186491) to extract and organize more data required to answer the open competency questions is clearly evident. However, we did not focus on building and publishing an already comprehensive KG of empirical research in RE that can be used to answer as many competency questions as possible. Instead, we aimed to lay its foundation by building, publishing, and evaluating the initial KG-EmpiRE. We focused on conducting a literature review to illustrate how researchers can use RKGs, specifically the ORKG, as a technical infrastructure for organizing scientific data in an openly available and long-term way to build and publish KGs that the research community can constantly maintain, (re-)use, update, and expand.\n",
    "\n",
    "**State and evolution of empirical research in RE:**\n",
    "\n",
    "Regarding the state and evolution of empirical research in RE by analyzing the KG-EmpiRE, we can report a positive development towards the vision of [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30). We found that the proportion of papers with an empirical study increases over time with a average proportion of 94.3% for the **target state (2020 - 2025)**. For data collection, researchers frequently and constantly use the established empricial methods *experiment*, *secondary research*, and *survey* with average proportions of 35.7% (*experiment*), 40% (*secondary research*), and 18.7% (*survey*) for the **target state (2020 - 2025)**. We also found that the use of the empirical method *case study*, whose increased use is envisioned, decreases over time with a proportion of 22.3% for the **target state (2020 - 2025)**. Despite the decrease, the emprical method *case study* is actually used more frequently than surveys on average in the **target state (2020 - 2025)**. Furthermore, this decrease represents a positive development of the empirical research in RE, as researchers seem to be more aware of the definition of a case study and therefore use the term more purposefully than in the past. This finding is consistent with the conclusion of [Wohlin](https://doi.org/10.1016/j.infsof.2021.106514) who stated that the term *case study* is often misused in software engineering. Consequently, empirical research that is called as a *case study* in recent years appears to actually be a *case study*. For data analysis, researchers mainly and constantly use *descriptive statistics* with a proportion of 87.6% overall and 92% for the **target state (2020 - 2025)**. In contrast, the use of *inferential statistics* with a proportion of 19.2% overall and 26.3% for the **target state (2020 - 2025)** is small. Regarding the general use of empirical methods, we found that the number of empirical methods used for data collection and data analysis in a single papers increases over time, with *three to four empirical methods* most frequently used in one paper. For the **target state (2020 - 2025)**, researchers mainly use *three to even five empirical methods* in a single paper with average proportions of 22% (*three empirical methods used*), 25.3% (*four empirical methods used*), and 26.7% (*five empirical methods used*). This increase in the number of empirical methods used shows a shift as envisioned towards the use of several empirical methods and thus the collection and analysis of data from different perspectives to synthesize evidence. In addition to the empirical methods used, we also found a positive development with regard to the reporting of important information of experimental design. For the **target state (2020 - 2025)**, the proportion of papers reporting *threats to validity*, providing *raw data and supplementary materials*, and highlighting their *research questions and answers* steadily increase over time with average proportions of 91.3% (*threats to validity*), 71.3% (*raw data and supplementary materials*), and 23.7% (*highlighted research questions and answer*) respectively 53% (*highlighted research question and answer hidden in the running text*). \n",
    "\n",
    "Despite the positive developments towards the vision of [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), we also identified the need for future improvements of empirical research in RE. While [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envisioned an increased use of *action research, we found that the proportion of *action research* is small over the entire timeframe analyzed (2000 - 2022) with an average proportion of only 2%. For the **target state (2020 - 2025)**, no paper reported the use of *action research*. According to [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), more *case studies* and *action research* are needed to ensure the industrial relevance of empirical research. This part of the vision is not yet nearly achieved. Regarding the reporting of threats to validity, we found two issues for future improvement. First, a proportion of 33.6% of the analyzed papers reporting threats to validity *only mentioned threats to validity* without any further classification of the types of validity. Although the general reporting of threats to validity is useful, the lack of classification of the reported threats to validity makes it difficult for a reader to have a clear overview of whether the threats to validity have been discussed comprehensively. In the future, researchers need to communicate their threats to validity comprehensively and transparently by discussing all type of validity equally and naming the type of validity addressed. Second, the proportion of papers reporting threats to *conclusion validity* with 18.2% is small compared to the other mainly discussed types of valdity (*external validity*: 60.4%, *internal validity*: 56.1%, and *construct validity*: 47.9%). Therefore, researchers need to make more effort to comprehensively discuss the validity of their empirical research by also addressing the conclusion valditiy similar to the other types of validity. Regarding data analysis, the proportion of paper using *inferential statistics* is small with a proportion of only 26.2% for the **target state (2020 - 2025)**. For a mature use of statistical methods as envisioned by [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), researchers have to deal more with *inferential statistics* and include them in the data analysis of their empirical research.\n",
    "\n",
    "Below, we provide for each competency question answered the corresponding key findings as brief statements of the main insights from the data analysis. For more details, please refer to the respective analysis in the corresponding section.\n",
    "<details>\n",
    "  <summary>Key findings</summary>\n",
    "  \n",
    "1. [How has the proportion of empirical studies evolved over time?](#q1)\n",
    "   \n",
    "   The proportion of papers with an empirical study has steadily increased over time and the average proportion of papers with an empirical study for the **target state (2020 - 2025)** of the vision by [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) is currently 94.3%.\n",
    "   \n",
    "2. [How often are which empirical methods used over time?](#q2)\n",
    "   \n",
    "   For data collection, researchers use *surveys* and *interviews* more or less constantly over time. While the use of *case studies* decreased, the use of *experiments* and *secondary research* increased, and the use of *action research* is constantly low over time.\n",
    "   \n",
    "   For data analysis, researchers use constantly *descriptive statistics* over time. While the use of *inferential statistics* slightly increased but varies significantly, the use of *machine learning* increased constantly over time. In addition, we have found that there is a large amount of other empirical methods used for data analysis, which we currently group under *other methods*. In the future, further analysis of this *other methods* is needed for more detailed insights.\n",
    "\n",
    "3. [How has the proportion of papers that do not have an empirical study evolved over time?](#q3)\n",
    "   \n",
    "   The proportion of papers without an empirical study has steadily dereased over time and the average proportion of papers without an empirical study for the **target state (2020 - 2025)** of the vision by [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) is currently 5.7%.\n",
    "\n",
    "4. [How often are which empirical methods used?](#q4)\n",
    "   \n",
    "   For data collection, researchers use most commonly *case studys* (192 times), *experiments* (128 times), and *other methods* (175 times) as default category for data collection, with a very similar proportion of about 20% of all papers analyzed. These methods are followed by *surveys* (88 times), *interviews* (86 times), and *secondary research* (81 times) that also have a very similar proportion of about 11% of all papers analyzed. Only *action research* (10 times) is rarely used with a proportion of only 1.3% of all papers analyzed.\n",
    "\n",
    "   For data analysis, reseracher use most frequently *descriptive statistics* (398 times) with a proportion of 88% of all papers analyzed. *Other methods* (278 times) are used second most frequently with a proportion of 61%. This large proportion requires further analysis in the future for more fine-grained insights. While *machine learning* (94 times) is used in 21% of the papers analyzed, *inferential statistics* (89 times) is used least frequently with a proportion of only 20%.\n",
    "\n",
    "5. [How have the proportions of experiments, secondary research (reviews), surveys, case studies, and action research in the empirical methods used evolved over time?](#q5)\n",
    "   \n",
    "   While the proportions of *experiments* (overall average proportion 27.4%), *surveys* (overall average proportion 17.4%), and *action research* (overall average proportion 2%) are more or less constant used over time, the proportion of *secondary research* increases over time with an average proportion of 40% for the **target state (2020 - 2025)** of the vision by [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30). The proportion of *case studies* decreases over time, but this decrease is a positive development in empirical research in RE, as researchers seem to be more aware of how a case study is defined and therefore use the term more purposefully than in the past.\n",
    "\n",
    "6. [How often are which statistical methods used?](#q6)\n",
    "   \n",
    "   For descriptive statistics, researchers mainly use four statistical methods: *count* (86% proportion of all papers analyzed), *percent* (59% proportion of all papers analyzed), *mean* (43% proportion of all papers analyzed), and *range* (24% proportion of all papers analyzed). All other statistical methods of descriptive statistics are rarely used with an average proportion of 6.3% of all papers analyzed.\n",
    "\n",
    "   For inferential statistics, researchers use a diverse set of statistical methods with a maximum proportion of 2.9% of all analyzed papers for the Wilcoxon signed rank test and the Shapiro-Wilk test. Thus, the application of statistical methods of inferential statistics is, on the one hand, low and, on the other hand, very diverse.\n",
    "\n",
    "7. [How has the use of statistical methods evolved over time?](#q7)\n",
    "   \n",
    "   While the statistical methods of descriptive statistics, in particular *count*, *percent*, and *mean*, are more or less constantly used over time, there is no clear trend that a mature use of statistical methods of inferential statistics has emerged over time, especially not for the **target state (2020 - 2025)** of the vision by [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) so far.\n",
    "\n",
    "8. [How has the reporting of threats to validity evolved over time?](#q8)\n",
    "   \n",
    "   The proportion of papers reporting threats to validity has steadily increased over time and the average proportion of papers reporting threats to validity for the **target state (2020 - 2025)** of the vision by [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) is currently 91.3%.\n",
    "\n",
    "9.  [What types of threats to validity do the authors report?](#q9)\n",
    "    \n",
    "    Researchers mainly report five types of validity: *external validity* (169 times) with a proportion of 60.4%, *internal validity* (157 times) with a proportion of 56.1%, *construct validity* (134 times) with a proportion of 47.9%, *conclusion validity* (51 times) with a proportion of 18.2%, and *reliability* (30 times) with a proportion of 10.7%. In addition, we found five other types of validity but their proportion is below 3%. Furthermore, researchers frequently mention threats to validity without classifying the types of validity (94 times). This type of reporting occurs in just over 33.6% of all papers that report threats to validity.\n",
    "\n",
    "10. [How have the proportions of case studies and action research in the empirical methods used evolved over time?](#q10)\n",
    "    \n",
    "    The proportion of *case studies* decreases over time. From an average proportion of 53.2% before 2013, the proportion for the **target state (2020 - 2025)** decreased to 22.3%. This decrease, however, is a positive development in empirical research in RE, as researchers seem to be more aware of how a case study is defined and therefore use the term more purposefully than in the past.\n",
    "\n",
    "    The proportion of *action research* is constantly low over time. Researchers only used *action research* 10 times with an overall average proportion of only 2%.\n",
    "\n",
    "11. [How has the provision of data (the materials used, the raw data collected, and the study results identified) evolved over time?](#q11)\n",
    "    \n",
    "    The proportion of papers that provide at least one URL to data has steadily increased over time and the average proportion of papers that provide at least one URL to data for the **target state (2020 - 2025)** of the vision by [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) is currently 71.3%.\n",
    "\n",
    "12. [How has the reporting of research questions and answers evolved over time?](#q12)\n",
    "    \n",
    "    First, the proportion of papers without research question(s) and answer hidden in the running text steadily decreases over time. For the **target state (2020 - 2025)** the average proportion of papers without research question(s) and answer hidden in the running text is 18% compared to a proportion of 96% in 2001. Second, the proportion of papers with research questions and answers hidden in the running text is low but slightly increased until 2018. From 2019 onwards, the proportion of papers with research questions and answers hidden in the running is on average only 5%. Third, the proportion of papers with highlighted research questions and answers hidden in the running text constantly increases and is with an overall average propotion of 25.7% high. Fourth, the proportion of highlighted research questions and answers increases slightly over time with a current maximum proportion of 44%.\n",
    "\n",
    "13. [What empirical methods are used to conduct integrative and interpretive (systematic literature) reviews, so-called secondary research?](#q13)\n",
    "    \n",
    "    Researchers mainly use three empirical methods to condcut integrative and interpretive (systematic literature) reviews, so-called secondary research: *Archive analysis* (48 times) with a proportion of 59%, *literature review* (11 times) with a proportion of 14%, and *systematic literature review* (11 times) with a proportion of 14%. In addition, we found seven other empirical mehtods, all with a proportion below 3%.\n",
    "\n",
    "14. [How has the proportions of empirical methods to conduct (systematic literature) reviews, so-called secondary research, evolved over time?](#q14)\n",
    "    \n",
    "    Regarding the three empirical methods (*archive analysis*, *literature review*, and *systematic literature review*) mainly used, researchers use *archive analysis* most frequently and constantly over time. From 2008 onwards, researchers perform *literature reviews* and *systematic literature reviews* with increasing frequency.\n",
    "\n",
    "15. [How many different empirical methods are used per publication?](#q15)\n",
    "\n",
    "    Researchers use mainly three (31.3% proportion) to four (21.6% proportion) empirical methods per paper. However, the number of empirical methods used ranges from one to twelve methods in a single paper.\n",
    "\n",
    "16. [How has the number of empirical methods used per publication evolved over time?](#q16)\n",
    "    \n",
    "    The proportion of papers using only one or two empricial methods steadily decreases over time. In contrast, the proportion of papers using three or more empirical mehtods steadily increases over time. From 2016 onwards, researchers often use four or even five empirical methods in one paper.\n",
    "</details>\n",
    "\n",
    "### Conclusions\n",
    "First of all, we want to remark that the generalizability of our findings is limited as KG-EmpiRE is in an initial stage due to the limited analysis of the 570 papers from the research track of the [IEEE International Requirements Engineering Conference](https://ieeexplore.ieee.org/xpl/conhome/1000630/all-proceedings) from 2000 to 2022. This conference is the largest international conference in the research field of RE where a large number of established researchers in this field regularly publish high-quality, peer-reviewed (empirical) research papers. Therefore, the papers analyzed are a representative for the target population of all papers in RE, but they still form only a small subset. Nevertheless, the results provide important insights into the state and evolution of empirical research in RE published in [IEEE International Requirements Engineering Conference](https://ieeexplore.ieee.org/xpl/conhome/1000630/all-proceedings). For this reason, we consider the current scope of our literature review to be appropriate to llustrate how researchers can use RKGs, specifically the ORKG, as a technical infrastructure for organizing scientific data in an openly available and long-term way to build and publish KGs that the research community can constantly maintain, (re-)use, update, and expand, thus enabling sustainable literature reviews.\n",
    "\n",
    "Using the ORKG, the extracted data is not encapsulated in a file as usual, which is, at best, published on a data repository, but in a openly available knowledge graph, which, to put it simply, is nothing more than a graph-based database. Overall, the ORKG offers an ready-to-use and sustainably governed infrastructure that implements best practices, such as FAIR principles and versioning, with services to support researchers in organizing (acquiring, curating, publishing, and processing) FAIR scientific data. As a result, the FAIR scientific data is openly available in the long term and can be understood, processed, and used by humans and machines. Thus, the research community can constantly maintain, (re-)use, update, and expand the initial KG-EmpiRE, that we have built, published, evaluated, in a long-term and collaborative manner. For example, in case of errors in data extraction, anyone, and in the best case the authors themselves, can update the data. It is also possible to expand the KG-EmpiRE by curating more papers using or even expanding the [ORKG template](https://orkg.org/template/R186491) to extract more data in a structured, consistent, and comparable way. In all these cases, anyone can (re-)use this Jupyter Notebook to reproduce the data analysis and its (updated) results. Using RKGs to organize scientific data helps to address two of the key challenges of literature reviews: **Lack of collaboration among researchers** and **updating literature reviews**. For this reason, we conclude that using RKGs represents a step in the right direction towards sustainable literature reviews to ensure the quality, reliability, and timeliness of research findings for a successful long-term collaboration of researchers.\n",
    "\n",
    "For our future work, we have a plan with short-, mid-, and long-term actions. As short-term actions, we expand KG-EmpiRE by describing more papers of the [IEEE International Requirements Engineering Conference](https://ieeexplore.ieee.org/xpl/conhome/1000630/all-proceedings) with our [ORKG template](https://orkg.org/template/R186491). Our goal over the coming months is to cover the entire research track of the [IEEE International Requirements Engineering Conference](https://ieeexplore.ieee.org/xpl/conhome/1000630/all-proceedings) from 1994 - 2022 to get a comprehensive overview of the state and evolution of empirical research in RE at this conference. We also establish a more general [ORKG observatory](https://orkg.org/observatory/Empirical_Software_Engineering) as a central access point to all curated papers. The observatory is an open group that anyone can join to contribute to the topic. As mid-term actions, we write and publish an [ORKG review](https://orkg.org/about/16/Reviews) about the state and evolution of empirical research in RE, based on the complete collection of all papers from the research track of the [IEEE International Requirements Engineering Conference](https://ieeexplore.ieee.org/xpl/conhome/1000630/all-proceedings) from 1994 - 2022. An [ORKG review](https://orkg.org/about/16/Reviews) is a special kind of literature review article that the research community can constantly maintain when underlying content in the ORKG changes due to updates or expansions. Besides the [ORKG review](https://orkg.org/about/16/Reviews), we expand the KG-EmpiRE by including more papers from other important venues, such as the journal [Requirements Engineering](https://link.springer.com/journal/766/volumes-and-issues) or the [International Working Conference on Requirement Engineering: Foundation for Software Quality](https://link.springer.com/conference/refsq), to gain a more comprehensive overview of the state and evolution of empirical research in RE. As long-term action, we extend the [ORKG template](https://orkg.org/template/R186491) to organize more extensive scientific data about empirical resarch in a structured, consistent, and comparable manner and thus to address the 61 still open [competency questions](competency-questions.xlsx). With this plan, we work towards maintaining, updating, and expanding the initial KG-EmpiRE togehter with the research community by *dividing* the efforts to *conquer* the EmpiRE.\n",
    "\n",
    "[Back to top](#top)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## 2. Reusable Functions for Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from SPARQLWrapper import SPARQLWrapper, CSV\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import dataframe_image as dfi\n",
    "\n",
    "ENDPOINT_URL = \"https://www.orkg.org/triplestore\"\n",
    "\n",
    "PREFIXES =  \"\"\"\n",
    "            PREFIX orkgr: <http://orkg.org/orkg/resource/>\n",
    "            PREFIX orkgc: <http://orkg.org/orkg/class/>\n",
    "            PREFIX orkgp: <http://orkg.org/orkg/predicate/>\n",
    "            PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "            PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "            PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "            \"\"\"\n",
    "\n",
    "DATE = '2024-02-19'\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (18, 8)\n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(font_scale=1.25)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def retrieve_data(id, query):\n",
    "        \n",
    "        sparql = SPARQLWrapper(ENDPOINT_URL)#, agent=user_agent)\n",
    "        sparql.setQuery(PREFIXES+query)\n",
    "        sparql.setReturnFormat(CSV)\n",
    "        \n",
    "        try:\n",
    "                results = sparql.queryAndConvert()\n",
    "        except Exception as e:\n",
    "                print(e)\n",
    "        \n",
    "        now = datetime.now()\n",
    "        with open('SPARQL-Data/query_' + id + '_data_' + now.strftime('%Y-%m-%d') + '.csv', 'wb') as file:\n",
    "                file.write(results)\n",
    "\n",
    "def explore_data(df):\n",
    "        display('Number of total entries in the dataset: ' + str(df.shape[0]))\n",
    "        display('Number of unique entries in the dataset: ' + str(df.index.nunique()))\n",
    "        display(df.head(15))\n",
    "        display(df.info())\n",
    "\n",
    "        #Missing value analysis\n",
    "        missing_values = df.isna().sum()\n",
    "        plt.figure()\n",
    "        ax_exp = missing_values.plot(kind='barh')\n",
    "        ax_exp.set_xlim(left=0)\n",
    "        #start, end = ax_exp.get_xlim()\n",
    "        #ax_exp.xaxis.set_ticks(np.arange(start, end, 1))\n",
    "        plt.title('Number of missing values per column in the dataset')\n",
    "        plt.xlabel('Number of missing values')\n",
    "        plt.ylabel('Column of the dataset')\n",
    "        plt.show()\n",
    "\n",
    "        # Proportion of missing values in the entire data set \n",
    "        data = missing_values / df.shape[0] * 100\n",
    "        display(pd.DataFrame(data, columns=[\"Proportion of missing values\"]).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## 3. Analysis of the Competency Questions\n",
    "\n",
    "Below, we present the individual analyses for each answerable competency question. Each analysis follows the same structure:\n",
    "\n",
    "1. Data Selection: Explaining the competency question and the required data for the analysis.\n",
    "2. Data Collection: Executing the specified SPARQL query.\n",
    "3. Data Exploration: Exploring the data, including its cleaning and validation, to prepare the data for data analysis.\n",
    "4. Data Analysis: Analyzing the data and creating visualizations.\n",
    "5. Data Interpretation: Interpreting the data and derive insights.\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='q1'></a>\n",
    "### 3.1 How has the proportion of empirical studies evolved over time?\n",
    "\n",
    "#### <ins>*Data Selection*</ins> \n",
    "\n",
    "*Explanation of the Competency Question*:\n",
    "\n",
    "According to [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), the **\"current\" state of practice (2007)** shows that there are relatively **few empirical studies**. For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision a **large number of studies**. This predicted change from a few to a large number of empirical studies leads to the corresponding competency question.\n",
    "\n",
    "*Required Data for the Analysis*:\n",
    "\n",
    "We must retrieve all papers with their publication year that use our ORKG template and report an empirical study. However, we need to define what we mean by an empirical study. According to [Empirical Software Engineering Journal](https://www.springer.com/journal/10664), \"*Empirical studies presented here usually involve the collection and analysis of data and experience...*\". For this reason, we define that an empirical study is a study that includes data analysis as a necessary condition to be a study (*Necessity*) and data collection as a sufficient condition to be an empirical study (*Sufficiency*). Thus, a study must always include data analysis and an empirical study must include data collection and data analysis. We do not consider the mere reporting of a data collection as a study or even an empirical study.\n",
    "\n",
    "[Back to top](#step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Collection*</ins> \n",
    "Below, we retrieve the required data from KG-EmpiRE in the [ORKG](https://www.orkg.org/orkg/) using its [SPARQL endpoint](https://orkg.org/sparql/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '1'\n",
    "\n",
    "query_1 = \"\"\"\n",
    "        SELECT ?paper, ?year, ?dc_label, ?da_label\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                        orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "                \n",
    "                OPTIONAL{?contribution orkgp:P56008 ?data_collection.\n",
    "                        ?data_collection rdfs:label ?dc_label.\n",
    "                }\n",
    "                OPTIONAL{?contribution orkgp:P15124 ?data_analysis.\n",
    "                        ?data_analysis rdfs:label ?da_label.\n",
    "                }\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_1)\n",
    "\n",
    "df_query_1 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Exploration*</ins>\n",
    "Below, we explore the retrieved data, including its cleaning and validation, to prepare the data for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_1['dc_label'] = df_query_1['dc_label'].astype('category')\n",
    "df_query_1['da_label'] = df_query_1['da_label'].astype('category')\n",
    "display(df_query_1['dc_label'].value_counts())\n",
    "display(df_query_1['da_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Analysis*</ins>\n",
    "For this data analysis, we select all papers that have an empirical study according to our definition (data collection and data analysis). For this reason, we remove all papers that have \"no collection\" and/or \"no analysis\". In addition, a paper can involve more than one empirical method for data collection and data analysis so that we must exclude duplicate papers. In this way, we can determine the number of all unique papers. For more detailed insights, we normalize the number of all papers with an empirical study based on the number of all unique papers per year, as the total number of papers per year varies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(df_query_1.drop_duplicates(subset=['paper']).reset_index(drop=True)['year'].value_counts())\n",
    "result.columns = ['number_of_all_papers']\n",
    "\n",
    "papers_with_emp_study = df_query_1[(df_query_1['dc_label'] != 'no collection') & (df_query_1['da_label'] != 'no analysis')]\n",
    "papers_with_emp_study = papers_with_emp_study.drop_duplicates(subset=['paper'])\n",
    "result['number_of_papers_with_emp_studies'] = papers_with_emp_study.reset_index(drop=True)['year'].value_counts()\n",
    "\n",
    "result['normalized_papers_with_emp_studies'] = (result['number_of_papers_with_emp_studies'] / result['number_of_all_papers']).round(2)\n",
    "#display(result.sort_index())\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.barplot(data=result, x=result.index, y='number_of_papers_with_emp_studies', color='b')\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title('Number of papers with an empirical study per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of papers with an empirical study')\n",
    "plt.savefig('Figures/CQ1/number_of_papers_with_empirical_study.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.barplot(data=result, x=result.index, y='normalized_papers_with_emp_studies', color='b')\n",
    "ax.bar_label(ax.containers[0], fmt='%.2f')\n",
    "plt.title('Normalized number of papers with an empirical study per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Proportion of papers with an empirical study')\n",
    "plt.savefig('Figures/CQ1/proportion_of_papers_with_empirical_study.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Interpretation*</ins>\n",
    "Based on the figure [\"Normalized number of papers with an empirical study per year\"](Figures/CQ1/proportion_of_papers_with_empirical_study.png), an increasing proportion of empirical studies can be observed over time. While before 2010 the average proportion of papers with an empirical study is 69.5%, the average proportion for the period 2010 - 2019 is 85.2%. For the **target state (2020 - 2025)**, the average proportion of papers with an empirical study is 94.3%. Based on these data, we observe a positive development towards the vision of [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) that the large number of studies envisioned for the **target state (2020 - 2025)** can be achieved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='q2'></a>\n",
    "### 3.2 How often are which empirical methods used over time?\n",
    "\n",
    "#### <ins>*Data Selection*</ins> \n",
    "\n",
    "*Explanation of the Competency Question*:\n",
    "\n",
    "According to [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), the **\"current\" state of practice (2007)** shows a that there are relatively **few empirical studies**. For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision a **large number of studies [...] using different empirical methods**. This predicted change from a few to a large number of empirical studies using different empirical methods leads to the corresponding competency question.\n",
    "\n",
    "*Required Data for the Analysis*:\n",
    "\n",
    "We must retrieve all papers with their publication year that use our ORKG template and report on the use of empirical methods. According to [Dan (2017)](https://doi.org/10.1002/9781118901731.iecrm0083), empirical methods include data collection and data analysis. An empirical method can therefore be a method for data collection and data analysis. We consider the empirical method used for data collection or data analysis respectively, as our template allows for a correspondingly more fine-grained analysis.\n",
    "\n",
    "[Back to top](#step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Collection*</ins> \n",
    "Below, we retrieve the required data from KG-EmpiRE in the [ORKG](https://www.orkg.org/orkg/) using its [SPARQL endpoint](https://orkg.org/sparql/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '2.1'\n",
    "\n",
    "query_2_1_data_collection = \"\"\"\n",
    "        SELECT ?paper, ?year, ?dc_label\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                        orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "\n",
    "                OPTIONAL{?contribution orkgp:P56008 ?data_collection.\n",
    "                        ?data_collection rdfs:label ?dc_label.\n",
    "                }\n",
    "                FILTER(?dc_label != \"no collection\"^^xsd:string)\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_2_1_data_collection)\n",
    "df_query_2_1 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')\n",
    "\n",
    "ID = '2.2'\n",
    "query_2_2_data_analysis = \"\"\"\n",
    "        SELECT ?paper, ?year, ?da_label, ?descriptive, ?inferential, ?machine_learning, ?method\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                        orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "                \n",
    "                \n",
    "                OPTIONAL{?contribution orkgp:P15124 ?data_analysis.\n",
    "                        ?data_analysis rdfs:label ?da_label.\n",
    "                        \n",
    "                        OPTIONAL{?data_analysis orkgp:P56048/rdfs:label ?descriptive.}\n",
    "                        OPTIONAL{?data_analysis orkgp:P56043/rdfs:label ?inferential.}\n",
    "                        OPTIONAL{?data_analysis orkgp:P57016/rdfs:label ?machine_learning.}\n",
    "                        OPTIONAL{?data_analysis orkgp:P76003/rdfs:label ?method}\n",
    "                }\n",
    "                FILTER(?da_label != \"no analysis\"^^xsd:string)\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_2_2_data_analysis)\n",
    "df_query_2_2 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Exploration*</ins>\n",
    "Below, we explore the retrieved data, including its cleaning and validation, to prepare the data for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_2_1['dc_label'] = df_query_2_1['dc_label'].astype('category')\n",
    "display(df_query_2_1['dc_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_2_2['da_label'] = df_query_2_2['da_label'].astype('category')\n",
    "df_query_2_2['descriptive'] = df_query_2_2['descriptive'].astype('category')\n",
    "df_query_2_2['inferential'] = df_query_2_2['inferential'].astype('category')\n",
    "df_query_2_2['machine_learning'] = df_query_2_2['machine_learning'].astype('category')\n",
    "df_query_2_2['method'] = df_query_2_2['method'].astype('category')\n",
    "\n",
    "display(df_query_2_2['da_label'].value_counts())\n",
    "display(df_query_2_2['descriptive'].value_counts())\n",
    "display(df_query_2_2['inferential'].value_counts())\n",
    "display(df_query_2_2['machine_learning'].value_counts())\n",
    "display(df_query_2_2['method'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Analysis*</ins>\n",
    "For this data analysis, we consider the empirical methods used for data collection. We identify the empirical methods used for data collection. A paper can involve more than one empirical method for data collection so that the number of empirical methods can be larger than the number of papers. In addition, the number of papers per year varies. For this reason, we normalize the number of empirical methods used based on the number of all unique papers per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers_per_year = pd.DataFrame(df_query_2_1.drop_duplicates(subset=['paper']).reset_index(drop=True)['year'].value_counts())\n",
    "all_papers_per_year.columns = ['number_of_papers_with_dc']\n",
    "all_papers_per_year = all_papers_per_year.sort_index()\n",
    "\n",
    "result = pd.DataFrame(df_query_2_1.groupby('year')['dc_label'].value_counts().unstack())\n",
    "result = result[result.sum().sort_values(ascending=False).index]\n",
    "result = result.reindex(columns = [col for col in result.columns if col != 'study'] + ['study'])\n",
    "#display(result)\n",
    "\n",
    "ax = result.plot(kind='bar', rot=0)\n",
    "ax.legend(bbox_to_anchor=(0.75, 0.55), labels=['Case study', 'Experiment', 'Survey', 'Interview', 'Secondary research', 'Action research', 'Other method'])\n",
    "plt.title('Number of empirical methods used for data collection per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of empirical method used')\n",
    "plt.savefig('Figures/CQ2/dc_number_of_empirical_methods_used.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "figure, axis = plt.subplots(4, 2, figsize=(20, 15), sharey=True)\n",
    "# Plot barplots\n",
    "bar1 = sns.barplot(data = result, x = result.index, y='case study', ax=axis[0,0], color=sns.color_palette()[0])\n",
    "bar1.bar_label(bar1.containers[0])\n",
    "bar1.tick_params('x', labelrotation=45)\n",
    "bar2 = sns.barplot(data = result, x = result.index, y='experiment', ax=axis[0,1], color=sns.color_palette()[1])\n",
    "bar2.bar_label(bar2.containers[0])\n",
    "bar2.tick_params('x', labelrotation=45)\n",
    "bar3 = sns.barplot(data = result, x = result.index, y='survey', ax=axis[1,0], color=sns.color_palette()[2])\n",
    "bar3.bar_label(bar3.containers[0])\n",
    "bar3.tick_params('x', labelrotation=45)\n",
    "bar4 = sns.barplot(data = result, x = result.index, y='interview', ax=axis[1,1], color=sns.color_palette()[3])\n",
    "bar4.bar_label(bar4.containers[0])\n",
    "bar4.tick_params('x', labelrotation=45)\n",
    "bar5 = sns.barplot(data = result, x = result.index, y='secondary research', ax=axis[2,0], color=sns.color_palette()[4])\n",
    "bar5.bar_label(bar5.containers[0])\n",
    "bar5.tick_params('x', labelrotation=45)\n",
    "bar6 = sns.barplot(data = result, x = result.index, y='action research', ax=axis[2,1], color=sns.color_palette()[5])\n",
    "bar6.bar_label(bar6.containers[0])\n",
    "bar6.tick_params('x', labelrotation=45)\n",
    "bar7 = sns.barplot(data = result, x = result.index, y='study', ax=axis[3,0], color=sns.color_palette()[6])\n",
    "bar7.bar_label(bar7.containers[0])\n",
    "bar7.tick_params('x', labelrotation=45)\n",
    "\n",
    "# Remove unnecessary subplot\n",
    "figure.delaxes(axis[3,1])\n",
    "\n",
    "# Set titles\n",
    "plt.suptitle(\"Number of empirical method used for data collection per year grouped by empirical method\")\n",
    "bar1.set(title = 'Number of case studies used for data collection per year', ylabel='Number of case studies', xlabel='Year')\n",
    "bar2.set(title = 'Number of experiments used for data collection per year', ylabel='Number of experiments', xlabel='Year')\n",
    "bar3.set(title = 'Number of surveys used for data collection per year', ylabel='Number of surveys', xlabel='Year')\n",
    "bar4.set(title = 'Number of interviews used for data collection per year', ylabel='Number of interviews', xlabel='Year')\n",
    "bar5.set(title = 'Number of secondary research used for data collection per year', ylabel='Number of secondary research', xlabel='Year')\n",
    "bar6.set(title = 'Number of actions research used for data collection per year', ylabel='Number of action research', xlabel='Year')\n",
    "bar7.set(title = 'Number of other methods used for data collection per year', ylabel='Number of other methods', xlabel='Year')\n",
    "\n",
    "# Set spacing between subplots\n",
    "figure.tight_layout()\n",
    "plt.savefig('Figures/CQ2/dc_number_of_empirical_methods_used_grouped_by_method.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "result = pd.concat([result, all_papers_per_year], axis=1)\n",
    "result['normalized case study'] = (result['case study'] / result['number_of_papers_with_dc']).round(2)\n",
    "result['normalized experiment'] = (result['experiment'] / result['number_of_papers_with_dc']).round(2)\n",
    "result['normalized survey'] = (result['survey'] / result['number_of_papers_with_dc']).round(2)\n",
    "result['normalized interview'] = (result['interview'] / result['number_of_papers_with_dc']).round(2)\n",
    "result['normalized secondary research'] = (result['secondary research'] / result['number_of_papers_with_dc']).round(2)\n",
    "result['normalized action research'] = (result['action research'] / result['number_of_papers_with_dc']).round(2)\n",
    "result['normalized study'] = (result['study'] / result['number_of_papers_with_dc']).round(2)\n",
    "#display(result)\n",
    "\n",
    "ax = result.loc[:, 'normalized case study':'normalized study'].plot(kind='bar', rot=0)\n",
    "ax.legend(bbox_to_anchor=(1.0, 0.8), labels=['Case study', 'Experiment', 'Survey', 'Interview', 'Secondary research', 'Action research', 'Other method'])\n",
    "plt.title('Normalized number of empirical methods used for data collection per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Proportion of empirical method used')\n",
    "plt.savefig('Figures/CQ2/dc_proportion_of_empirical_methods_used.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "figure, axis = plt.subplots(4, 2, figsize=(20, 17), sharey=True)\n",
    "# Plot barplots\n",
    "bar1 = sns.barplot(data = result, x = result.index, y='normalized case study', ax=axis[0,0], color=sns.color_palette()[0])\n",
    "bar1.bar_label(bar1.containers[0], rotation=45)\n",
    "bar1.tick_params('x', labelrotation=45)\n",
    "bar2 = sns.barplot(data = result, x = result.index, y='normalized experiment', ax=axis[0,1], color=sns.color_palette()[1])\n",
    "bar2.bar_label(bar2.containers[0], rotation=45)\n",
    "bar2.tick_params('x', labelrotation=45)\n",
    "bar3 = sns.barplot(data = result, x = result.index, y='normalized survey', ax=axis[1,0], color=sns.color_palette()[2])\n",
    "bar3.bar_label(bar3.containers[0], rotation=45)\n",
    "bar3.tick_params('x', labelrotation=45)\n",
    "bar4 = sns.barplot(data = result, x = result.index, y='normalized interview', ax=axis[1,1], color=sns.color_palette()[3])\n",
    "bar4.bar_label(bar4.containers[0], rotation=45)\n",
    "bar4.tick_params('x', labelrotation=45)\n",
    "bar5 = sns.barplot(data = result, x = result.index, y='normalized secondary research', ax=axis[2,0], color=sns.color_palette()[4])\n",
    "bar5.bar_label(bar5.containers[0], rotation=45)\n",
    "bar5.tick_params('x', labelrotation=45)\n",
    "bar6 = sns.barplot(data = result, x = result.index, y='normalized action research', ax=axis[2,1], color=sns.color_palette()[5])\n",
    "bar6.bar_label(bar6.containers[0], rotation=45)\n",
    "bar6.tick_params('x', labelrotation=45)\n",
    "bar7 = sns.barplot(data = result, x = result.index, y='normalized study', ax=axis[3,0], color=sns.color_palette()[6])\n",
    "bar7.bar_label(bar7.containers[0], rotation=45)\n",
    "bar7.tick_params('x', labelrotation=45)\n",
    "\n",
    "# Remove unnecessary subplot\n",
    "figure.delaxes(axis[3,1])\n",
    "\n",
    "# Set titles\n",
    "plt.suptitle(\"Normalized number of empirical methods used for data collection per year grouped by empirical method\")\n",
    "bar1.set(title = 'Normalized number of case studies used for data collection per year', ylabel='Proportion of case studies', xlabel='Year')\n",
    "bar2.set(title = 'Normalized number of experiments used for data collection per year', ylabel='Proportion of experiments', xlabel='Year')\n",
    "bar3.set(title = 'Normalized number of surveys used for data collection per year', ylabel='Proportion of surveys', xlabel='Year')\n",
    "bar4.set(title = 'Normalized number of interviews used for data collection per year', ylabel='Proportion of interviews', xlabel='Year')\n",
    "bar5.set(title = 'Normalized number of secondary research used for data collection per year', ylabel='Proportion of secondary research', xlabel='Year')\n",
    "bar6.set(title = 'Normalized number of actions research used for data collection per year', ylabel='Proportion of action research', xlabel='Year')\n",
    "bar7.set(title = 'Normalized number of other methods used for data collection per year', ylabel='Proportion of other methods', xlabel='Year')\n",
    "\n",
    "# Set spacing between subplots\n",
    "figure.tight_layout()\n",
    "plt.savefig('Figures/CQ2/dc_proportion_of_empirical_methods_used_grouped_by_method.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this data analysis, we consider the empirical methods used for data analysis. We identify the empirical methods used for data analysis. A paper can involve more than one empirical method for data analysis so that the number of empirical methods can be larger than the number of papers. In addition, the number of papers per year varies. For this reason, we normalize the number of empirical methods used based on the number of all unique papers per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers_per_year = pd.DataFrame(df_query_2_2.drop_duplicates(subset=['paper']).reset_index(drop=True)['year'].value_counts())\n",
    "all_papers_per_year.columns = ['number_of_papers_with_da']\n",
    "all_papers_per_year = all_papers_per_year.sort_index()\n",
    "#display(all_papers_per_year)\n",
    "\n",
    "df_query_2_2 = df_query_2_2.drop_duplicates(subset=['paper'])\n",
    "result = pd.DataFrame(df_query_2_2.groupby('year')[['descriptive', 'inferential', 'machine_learning', 'method']].count())\n",
    "#display(result)\n",
    "\n",
    "ax = result.plot(kind='bar', rot=0)\n",
    "ax.legend(bbox_to_anchor=(0.77, 0.7), labels=['Descriptive statistic', 'Inferential statistic', 'Machine learning method', 'Other method'])\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.title('Number of empirical methods used for data analysis per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of empirical method used')\n",
    "plt.savefig('Figures/CQ2/da_number_of_empirical_methods_used.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "figure, axis = plt.subplots(2, 2, figsize=(20, 15), sharey=True)\n",
    "# Plot barplots\n",
    "bar1 = sns.barplot(data = result, x = result.index, y='descriptive', ax=axis[0,0], color=sns.color_palette()[0])\n",
    "bar1.bar_label(bar1.containers[0])\n",
    "bar1.tick_params('x', labelrotation=45)\n",
    "bar1.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "bar2 = sns.barplot(data = result, x = result.index, y='inferential', ax=axis[0,1], color=sns.color_palette()[1])\n",
    "bar2.bar_label(bar2.containers[0])\n",
    "bar2.tick_params('x', labelrotation=45)\n",
    "bar2.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "bar3 = sns.barplot(data = result, x = result.index, y='machine_learning', ax=axis[1,0], color=sns.color_palette()[2])\n",
    "bar3.bar_label(bar3.containers[0])\n",
    "bar3.tick_params('x', labelrotation=45)\n",
    "bar3.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "bar4 = sns.barplot(data = result, x = result.index, y='method', ax=axis[1,1], color=sns.color_palette()[3])\n",
    "bar4.bar_label(bar4.containers[0])\n",
    "bar4.tick_params('x', labelrotation=45)\n",
    "bar4.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# Set titles\n",
    "plt.suptitle(\"Number of empirical method used for data analysis per year grouped by empirical method\")\n",
    "bar1.set(title = 'Number of decriptive statistics used for data analysis per year', ylabel='Number of decriptive statistics', xlabel='Year')\n",
    "bar2.set(title = 'Number of inferential statistics used for data analysis per year', ylabel='Number of inferential statistics', xlabel='Year')\n",
    "bar3.set(title = 'Number of machine learning methods used for data analysis per year', ylabel='Number of machine learning methods', xlabel='Year')\n",
    "bar4.set(title = 'Number of other methods used for data analysis per year', ylabel='Number of other methods', xlabel='Year')\n",
    "\n",
    "# Set spacing between subplots\n",
    "figure.tight_layout()\n",
    "plt.savefig('Figures/CQ2/da_number_of_empirical_methods_used_grouped_by_method.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "result = pd.concat([result, all_papers_per_year], axis=1)\n",
    "result['normalized descriptive'] = (result['descriptive'] / result['number_of_papers_with_da']).round(2)\n",
    "result['normalized inferential'] = (result['inferential'] / result['number_of_papers_with_da']).round(2)\n",
    "result['normalized machine_learning'] = (result['machine_learning'] / result['number_of_papers_with_da']).round(2)\n",
    "result['normalized method'] = (result['method'] / result['number_of_papers_with_da']).round(2)\n",
    "#display(result)\n",
    "\n",
    "ax = result.loc[:, 'normalized descriptive':'normalized method'].plot(kind='bar', rot=0)\n",
    "ax.legend(bbox_to_anchor=(1.0, 0.8), labels=['Descriptive statistic', 'Inferential statistic', 'Machine learning method', 'Other method'])\n",
    "plt.title('Normalized number of empirical methods used for data analysis per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Proportion of empirical method used')\n",
    "plt.savefig('Figures/CQ2/da_proportion_of_empirical_methods_used.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "figure, axis = plt.subplots(2, 2, figsize=(20, 15), sharey=True)\n",
    "# Plot barplots\n",
    "bar1 = sns.barplot(data = result, x = result.index, y='normalized descriptive', ax=axis[0,0], color=sns.color_palette()[0])\n",
    "bar1.bar_label(bar1.containers[0], rotation=45)\n",
    "bar1.tick_params('x', labelrotation=45)\n",
    "bar2 = sns.barplot(data = result, x = result.index, y='normalized inferential', ax=axis[0,1], color=sns.color_palette()[1])\n",
    "bar2.bar_label(bar2.containers[0], rotation=45)\n",
    "bar2.tick_params('x', labelrotation=45)\n",
    "bar3 = sns.barplot(data = result, x = result.index, y='normalized machine_learning', ax=axis[1,0], color=sns.color_palette()[2])\n",
    "bar3.bar_label(bar3.containers[0], rotation=45)\n",
    "bar3.tick_params('x', labelrotation=45)\n",
    "bar4 = sns.barplot(data = result, x = result.index, y='normalized method', ax=axis[1,1], color=sns.color_palette()[3])\n",
    "bar4.bar_label(bar4.containers[0], rotation=45)\n",
    "bar4.tick_params('x', labelrotation=45)\n",
    "\n",
    "# Set titles\n",
    "plt.suptitle(\"Normalized number of empirical methods used for data analysis per year grouped by empirical method\")\n",
    "bar1.set(title = 'Normalized number of decriptive statistics used for data analysis per year', ylabel='Proportion of decriptive statistics', xlabel='Year')\n",
    "bar2.set(title = 'Normalized number of inferential statistics used for data analysis per year', ylabel='Proportion of inferential statistics', xlabel='Year')\n",
    "bar3.set(title = 'Normalized number of machine learning methods used for data analysis per year', ylabel='Proportion of machine learning methods', xlabel='Year')\n",
    "bar4.set(title = 'Normalized number of other methods used for data analysis per year', ylabel='Proportion of other methods', xlabel='Year')\n",
    "\n",
    "# Set spacing between subplots\n",
    "figure.tight_layout()\n",
    "plt.savefig('Figures/CQ2/da_proportion_of_empirical_methods_used_grouped_by_method.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Interpretation*</ins>\n",
    "Based on the figure [\"Normalized number of empirical methods used for data collection per year\"](Figures/CQ2/dc_proportion_of_empirical_methods_used.png), we observe that mainly seven empirical methods are used for data collection. These seven methods are *case study* (192  times), *experiment* (128 times), *survey* (88 times), *interview* (86 times), *secondary research* (81 times), *action research* (10 times), and *study* as a default category (175 times). While the use of *experiment*, *survey* and *interview* is more or less constantly over time, we observe an three important aspects:\n",
    "\n",
    "1) The proportion of *case studies* decreases over time. We assume this change is a result of a clear definition of the term. According to [Wohlin](https://doi.org/10.1016/j.infsof.2021.106514), the term case study is often misused in software engineering research. Based on the manual curation of the 570 papers, we can confirm this finding. Prior to 2013, we found many papers that use the term case study (with an average proportion of 53.2%), although at best they report an experiment or a larger use case in the sense of an application example. Despite the decrease, this finding represents a positive development of the empirical research in RE as researchers appear to be more aware of how a case study is defined.\n",
    "2) The proportion of *secondary research*, including literature reviews and archive analysis, is steadily increasing over time. While before 2010 the average proportion of secondary research is 11.5%, the average proportion for the period 2010 - 2019 is 16.4%. For the **target state (2020 - 2025)**, the average proportion of secondary research is already 40% which is more than double the previous averages. In the last year 2022 we observe the current maximum with a proportion of 50% of the analyzed papers using some kind of secondary research.\n",
    "3) The proportion of *action research* is constantly low over the entire analyzed timeframe (2000 - 2022). In all years analyzed, the proportion of action research is at most 10% of the respective papers with an overall average proportion of only 2%. Furthermore, as of 2018, there is no publication using action research.\n",
    "\n",
    "The default category *study* with 175 entries is quite extensive and requires a more fine-grained analysis in the future. \n",
    "\n",
    "Based on the figure [\"Normalized number of empirical methods used for data analysis per year\"](Figures/CQ2/da_proportion_of_empirical_methods_used.png), we observe that mainly four empirical methods are used for data analysis. These four methods are *descriptive statistic* (510 times), *inferential statistic* (104 times), *machine learning* (109 times), and *other method* as a default category (278 times). We observe an four important aspects:\n",
    "\n",
    "1) The proportion of *descritpive statistics* is constantly high with an average proportion of 87.6% of all paper reporting descriptive statistics over the entire analyzed timeframe (2000 - 2022).\n",
    "2) The proportion of *inferential statistics* varies significantly but is relatively low overall with an average proportion of 19.2% of all paper reporting on data analysis over the entire analyzed timeframe (2000 - 2022).\n",
    "3) The proportion of *machine learning* has increased slighlty over time with its maximum of 58% in 2020. This increase reflects the current importance and high relevance of the topic of artificial intelligence in academia and industry.\n",
    "4) The proportion of *other methods* has its minimum with 36% in 2022 and its maximum with 94% in 2003. Based on the manual of the 570 papers, we can report that these other methods often include some kind of *coding* as qualitative analysis method. For this reason, the default category *other method* requires a more fine-grained analysis in the future. \n",
    "\n",
    "The results show that over time, more and more papers report empirical studies using different empirical methods. In particular, there are essentially six different methods used for data collection and three different methods used for data analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='q3'></a>\n",
    "### 3.3 How has the proportion of papers that do not have an empirical study evolved over time?\n",
    "\n",
    "#### <ins>*Data Selection*</ins> \n",
    "\n",
    "*Explanation of the Competency Question*:\n",
    "\n",
    "For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision that there should be good reason for **not including** a proper evaluation. This predicted state leads to the corresponding competency question.\n",
    "\n",
    "*Required Data for the Analysis*:\n",
    "\n",
    "We must retrieve all papers with their publication year that use our ORKG template and do not report an empirical study. However, we need to define what we mean by an empirical study. According to [Empirical Software Engineering Journal](https://www.springer.com/journal/10664), \"*Empirical studies presented here usually involve the collection and analysis of data and experience...*\". For this reason, we define that an empirical study is a study that includes data analysis as a necessary condition to be a study (*Necessity*) and data collection as a sufficient condition to be an empirical study (*Sufficiency*). Thus, a study must always include data analysis and an empirical study must include data collection and data analysis. We do not consider the mere reporting of a data collection as a study or even an empirical study. Therefore, we must retrieve all papers that do not have data collection, data analysis, or both.\n",
    "\n",
    "[Back to top](#step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Collection*</ins> \n",
    "Below, we retrieve the required data from KG-EmpiRE in the [ORKG](https://www.orkg.org/orkg/) using its [SPARQL endpoint](https://orkg.org/sparql/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '3'\n",
    "\n",
    "query_3 = \"\"\"\n",
    "        SELECT ?paper, ?year, ?dc_label, ?da_label\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                        orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "                \n",
    "                OPTIONAL{?contribution orkgp:P56008 ?data_collection.\n",
    "                        ?data_collection rdfs:label ?dc_label.\n",
    "                }\n",
    "                OPTIONAL{?contribution orkgp:P15124 ?data_analysis.\n",
    "                        ?data_analysis rdfs:label ?da_label.\n",
    "                }\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_3)\n",
    "\n",
    "df_query_3 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Exploration*</ins>\n",
    "Below, we explore the retrieved data, including its cleaning and validation, to prepare the data for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_3['dc_label'] = df_query_3['dc_label'].astype('category')\n",
    "df_query_3['da_label'] = df_query_3['da_label'].astype('category')\n",
    "display(df_query_3['dc_label'].value_counts())\n",
    "display(df_query_3['da_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Analysis*</ins>\n",
    "For this data analysis, we select all papers that do not have an empirical study according to our definition (data collection and data analysis). For this reason, we only keep all papers that have \"no collection\" and/or \"no analysis\". For more detailed insights, we normalize the number of all papers without an empirical study based on the number of all unique papers per year, as the total number of papers per year varies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(df_query_3.drop_duplicates(subset=['paper']).reset_index(drop=True)['year'].value_counts())\n",
    "result.columns = ['number_of_all_papers']\n",
    "\n",
    "papers_without_emp_study = df_query_3[(df_query_3['dc_label'] == 'no collection') | (df_query_3['da_label'] == 'no analysis')]\n",
    "papers_without_emp_study = papers_without_emp_study.drop_duplicates(subset=['paper'])\n",
    "result['number_of_papers_without_emp_studies'] = papers_without_emp_study.reset_index(drop=True)['year'].value_counts()\n",
    "result['number_of_papers_without_emp_studies'].fillna(0,inplace=True)\n",
    "result['number_of_papers_without_emp_studies'] = result['number_of_papers_without_emp_studies'].astype('int64')\n",
    "\n",
    "result['normalized_papers_without_emp_studies'] = (result['number_of_papers_without_emp_studies'] / result['number_of_all_papers']).round(2)\n",
    "#display(result.sort_index())\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.barplot(data=result, x=result.index, y='number_of_papers_without_emp_studies', color='b')\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title('Number of papers without an empirical study per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of papers without an empirical study')\n",
    "plt.savefig('Figures/CQ3/number_of_papers_without_empirical_study.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.barplot(data=result, x=result.index, y='normalized_papers_without_emp_studies', color='b')\n",
    "ax.bar_label(ax.containers[0], fmt='%.2f')\n",
    "plt.title('Normalized number of papers without an empirical study per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Proportion of papers without an empirical study')\n",
    "plt.savefig('Figures/CQ3/proportion_of_papers_without_empirical_study.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Interpretation*</ins>\n",
    "Based on the figure [\"Normalized number of papers without an empirical study per year\"](Figures/CQ3/proportion_of_papers_without_empirical_study.png), an decreasing proportion of empirical studies can be observed over time. While before 2010 the average proportion of papers without an empirical study is 30.5%, the average proportion for the period 2010 - 2019 is 14.8%. For the **target state (2020 - 2025)**, the average proportion of papers with an empirical study is 5.7%. Based on these data, we observe a positive development towards the vision of [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) that the small number of papers without an empiricial study envisioned for the **target state (2020 - 2025)** can be achieved. Regarding the aspect that the papers should provide a good reason for **not including** a proper evaluation, further analysis is needed as we have not yet examined how papers without empiricial studies justify why they do not provide proper evaluations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='q4'></a>\n",
    "### 3.4 How often are which empirical methods used?\n",
    "\n",
    "#### <ins>*Data Selection*</ins> \n",
    "\n",
    "*Explanation of the Competency Question*:\n",
    "\n",
    "For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision that researchers are trained in using a **large set of research methods and technqiues**. This predicted state leads to the corresponding competency question.\n",
    "\n",
    "*Required Data for the Analysis*:\n",
    "\n",
    "We must retrieve all papers that use our ORKG template and report on the use of empirical methods. According to [Dan (2017)](https://doi.org/10.1002/9781118901731.iecrm0083), empirical methods include data collection and data analysis. An empirical method can therefore be a method for data collection and data analysis. We consider the empirical method used for data collection or data analysis respectively, as our template allows for a correspondingly more fine-grained analysis.\n",
    "\n",
    "[Back to top](#step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Collection*</ins> \n",
    "Below, we retrieve the required data from KG-EmpiRE in the [ORKG](https://www.orkg.org/orkg/) using its [SPARQL endpoint](https://orkg.org/sparql/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '4.1'\n",
    "\n",
    "query_4_1_data_collection = \"\"\"\n",
    "        SELECT ?paper, ?dc_label\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                       orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "\n",
    "                OPTIONAL{?contribution orkgp:P56008 ?data_collection.\n",
    "                         ?data_collection rdfs:label ?dc_label.\n",
    "                }\n",
    "                FILTER(?dc_label != \"no collection\"^^xsd:string)\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_4_1_data_collection)\n",
    "df_query_4_1 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')\n",
    "\n",
    "ID = '4.2'\n",
    "query_4_2_data_analysis = \"\"\"\n",
    "        SELECT ?paper, ?da_label, ?descriptive, ?inferential, ?machine_learning, ?method\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                       orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "                                \n",
    "                OPTIONAL{?contribution orkgp:P15124 ?data_analysis.\n",
    "                        ?data_analysis rdfs:label ?da_label.\n",
    "                        \n",
    "                        OPTIONAL{?data_analysis orkgp:P56048/rdfs:label ?descriptive.}\n",
    "                        OPTIONAL{?data_analysis orkgp:P56043/rdfs:label ?inferential.}\n",
    "                        OPTIONAL{?data_analysis orkgp:P57016/rdfs:label ?machine_learning.}\n",
    "                        OPTIONAL{?data_analysis orkgp:P76003/rdfs:label ?method}\n",
    "                }\n",
    "                FILTER(?da_label != \"no analysis\"^^xsd:string)\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_4_2_data_analysis)\n",
    "df_query_4_2 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Exploration*</ins>\n",
    "Below, we explore the retrieved data, including its cleaning and validation, to prepare the data for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_4_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_4_1['dc_label'] = df_query_4_1['dc_label'].astype('category')\n",
    "display(df_query_4_1['dc_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_4_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_4_2['da_label'] = df_query_4_2['da_label'].astype('category')\n",
    "df_query_4_2['descriptive'] = df_query_4_2['descriptive'].astype('category')\n",
    "df_query_4_2['inferential'] = df_query_4_2['inferential'].astype('category')\n",
    "df_query_4_2['machine_learning'] = df_query_4_2['machine_learning'].astype('category')\n",
    "df_query_4_2['method'] = df_query_4_2['method'].astype('category')\n",
    "\n",
    "display(df_query_4_2['da_label'].value_counts())\n",
    "display(df_query_4_2['descriptive'].value_counts())\n",
    "display(df_query_4_2['inferential'].value_counts())\n",
    "display(df_query_4_2['machine_learning'].value_counts())\n",
    "display(df_query_4_2['method'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Analysis*</ins>\n",
    "For this data analysis, we consider the empirical methods used for data collection. We identify the empirical methods used for data collection. A paper can involve more than one empirical method for data collection so that the number of empirical methods can be larger than the number of papers using empirical methods for data collection. We normalize the number of empirical methods used for data collection based on the number of all papers using at least one empirical methods for data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df_query_4_1['dc_label'].value_counts().rename_axis('dc_label').to_frame('counts')\n",
    "result.index = result.index.map(str.capitalize)\n",
    "result = result.rename(index={'Study': 'Other method'})\n",
    "index = result.index.tolist()\n",
    "index.pop(1)\n",
    "result = result.reindex(index + ['Other method'])\n",
    "#display(result)\n",
    "\n",
    "ax = result.plot(kind='barh', rot=0)\n",
    "ax.invert_yaxis()\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.get_legend().remove()\n",
    "plt.title('Number of empirical methods used for data collection')\n",
    "plt.xlabel('Number of empirical method used')\n",
    "plt.ylabel('Empirical method used')\n",
    "plt.savefig('Figures/CQ4/dc_number_of_empirical_methods_used.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "number_of_all_papers_with_dc = result['counts'].sum()\n",
    "result['normalized'] = (result['counts'] / number_of_all_papers_with_dc).round(3)\n",
    "#display(result)\n",
    "\n",
    "plt.figure()\n",
    "ax = result.loc[:, 'normalized'].plot(kind='barh', rot=0)\n",
    "ax.invert_yaxis()\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title('Normalized number of empirical methods used for data collection')\n",
    "plt.xlabel('Proportion of empirical method used')\n",
    "plt.ylabel('Empirical method used')\n",
    "plt.savefig('Figures/CQ4/dc_proportion_of_empirical_methods_used.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this data analysis, we consider the empirical methods used for data analysis. We identify the empirical methods used for data analysis. A paper can involve more than one empirical method for data analysis so that the number of empirical methods can be larger than the number of papers using empirical methods for data analysis. We normalize the number of empirical methods used for data analysis based on the number of all papers using at least one empirical methods for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_4_2 = df_query_4_2.drop_duplicates(subset=['paper'])\n",
    "result = pd.DataFrame(df_query_4_2[['descriptive', 'inferential', 'machine_learning', 'method']].count(), columns=['number of method'])\n",
    "result = result.rename(index={'descriptive': 'Descriptive statistics', 'inferential': 'Inferential statistics', 'machine_learning': 'Machine learning method','method': 'Other method'})\n",
    "result.index = result.index.map(str.capitalize)\n",
    "#display(result)\n",
    "\n",
    "ax = result.plot(kind='barh', rot=0)\n",
    "ax.invert_yaxis()\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.get_legend().remove()\n",
    "plt.title('Number of empirical methods used for data analysis')\n",
    "plt.xlabel('Number of empirical method used')\n",
    "plt.ylabel('Empirical method used')\n",
    "plt.savefig('Figures/CQ4/da_number_of_empirical_methods_used.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "number_of_all_papers_with_da = df_query_4_2.count()['da_label']\n",
    "result['normalized'] = (result['number of method'] / number_of_all_papers_with_da).round(2)\n",
    "#display(result)\n",
    "\n",
    "plt.figure()\n",
    "ax = result.loc[:, 'normalized'].plot(kind='barh', rot=0)\n",
    "ax.invert_yaxis()\n",
    "xmin, xmax = plt.xlim()\n",
    "plt.xlim(xmin, xmax+0.01)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title('Normalized number of empirical methods used for data analysis')\n",
    "plt.xlabel('Proportion of empirical method used')\n",
    "plt.ylabel('Empirical method used')\n",
    "plt.savefig('Figures/CQ4/da_proportion_of_empirical_methods_used.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Interpretation*</ins>\n",
    "Based on the figure [\"Normalized number of empirical methods used for data collection\"](Figures/CQ4/dc_proportion_of_empirical_methods_used.png), we observe that mainly seven empirical methods are used for data collection. These seven methods are *case study* (192 times), *experiment* (128 times), *survey* (88 times), *interview* (86 times), *secondary research* (81 times), *action research* (10 times), and *study* as a default category (175 times). *Case study* (25.3%), *experiment* (16.8%), and *other method* as default category (23%) are most commonly used for data collection, with a very similar proportion of about 20%. These methods are followed by *survey* (11.6%), *secondary research* (10.7%), and *interview* (11.3%) that also have a very similar proportion of about 12%. Only *action research* is rarely used with a proportion of only 1.3% of all analyzed papers with a data collection.\n",
    "\n",
    "Based on the figure [\"Normalized number of empirical methods used for data analysis\"](Figures/CQ4/da_proportion_of_empirical_methods_used.png), we observe that mainly four empirical methods are used for data analysis. These four methods are *descriptive statistic* (398 times), *inferential statistic* (89 times), *machine learning* (94 times), and *other method* as a default category (278 times). Most frequently *descriptive statistic* is used with a proportion of 88% of all analyzed papers with a data analysis. *Other methods* are used second most frequently with a proportion of 61%. This large proportion requires further analysis in the future for more fine-grained insights. While *machine learning* is used in 21% of the analyzed papers, *inferential statistics*is used least frequently with a proportion of only 20%.\n",
    "\n",
    "Overall, the results show researchers use a **larger set of research methods and techniques**. In particular, there are essentially six different methods used for data collection and three different methods used for data analysis. However, the proportion of *action research* for data collection and especially *inferential statistics* for data analysis is very low."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='q5'></a>\n",
    "### 3.5 How have the proportions of experiments, secondary research (reviews), surveys, case studies, and action research in the empirical methods used evolved over time?\n",
    "\n",
    "#### <ins>*Data Selection*</ins> \n",
    "\n",
    "*Explanation of the Competency Question*:\n",
    "\n",
    "According to [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), the **\"current\" state of practice (2007)** shows that **researchers are skilled** (frequently use) **experiments and reviews** (secondary research), but **researchers are not skilled** (do not frequently use) **surveys, case studies, and action research**. For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision that researchers are trained in using **large set of research methods and technqiues** and that their **skills** (frequent use) **of conducting case studies and actions research are stimulated**. This predicted change leads to the corresponding competency question.\n",
    "\n",
    "*Required Data for the Analysis*:\n",
    "\n",
    "We must retrieve all papers with their publication year that use our ORKG template and report on the use of the empirical methods: experiments, secondary reserach (reviews), surveys, case studies, and action research.\n",
    "\n",
    "[Back to top](#step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Collection*</ins> \n",
    "Below, we retrieve the required data from KG-EmpiRE in the [ORKG](https://www.orkg.org/orkg/) using its [SPARQL endpoint](https://orkg.org/sparql/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '5'\n",
    "\n",
    "query_5_data_collection = \"\"\"\n",
    "        SELECT ?paper, ?year, ?dc_label\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                        orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "\n",
    "                OPTIONAL{?contribution orkgp:P56008 ?data_collection.\n",
    "                        ?data_collection rdfs:label ?dc_label.\n",
    "                }\n",
    "                FILTER(?dc_label != \"no collection\"^^xsd:string)\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_5_data_collection)\n",
    "df_query_5 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Exploration*</ins>\n",
    "Below, we explore the retrieved data, including its cleaning and validation, to prepare the data for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_5['dc_label'] = df_query_5['dc_label'].astype('category')\n",
    "display(df_query_5['dc_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Analysis*</ins>\n",
    "For this data analysis, we consider all papers that report on the use of the empirical methods: experiment, secondary research, survey, case study, action research. A paper can involve more than one empirical method for data collection so that the number of empirical methods can be larger than the number of papers. We normalize the number of empirical methods (experiment, secondary research, survey, case study, action research) used based on the number of all unique papers per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers_per_year = pd.DataFrame(df_query_5.drop_duplicates(subset=['paper']).reset_index(drop=True)['year'].value_counts())\n",
    "all_papers_per_year.columns = ['number_of_papers_with_dc']\n",
    "all_papers_per_year = all_papers_per_year.sort_index()\n",
    "\n",
    "result = pd.DataFrame(df_query_5.groupby('year')['dc_label'].value_counts().unstack())\n",
    "result = result[result.sum().sort_values(ascending=False).index]\n",
    "#display(result)\n",
    "\n",
    "result = pd.concat([result, all_papers_per_year], axis=1)\n",
    "result['normalized experiment'] = (result['experiment'] / result['number_of_papers_with_dc']).round(2)\n",
    "result['normalized case study'] = (result['case study'] / result['number_of_papers_with_dc']).round(2)\n",
    "result['normalized secondary research'] = (result['secondary research'] / result['number_of_papers_with_dc']).round(2)\n",
    "result['normalized survey'] = (result['survey'] / result['number_of_papers_with_dc']).round(2)\n",
    "result['normalized action research'] = (result['action research'] / result['number_of_papers_with_dc']).round(2)\n",
    "#display(result)\n",
    "\n",
    "ax = result.loc[:, 'normalized experiment':'normalized action research'].plot(kind='bar', rot=0)\n",
    "ax.legend(bbox_to_anchor=(1.0, 0.8), labels=['Experiment', 'Case study', 'Secondary research', 'Survey', 'Action research',])\n",
    "plt.title('Normalized number of empirical methods used for data collection per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Proportion of empirical method used')\n",
    "plt.savefig('Figures/CQ5/dc_proportion_of_empirical_methods_used.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "figure, axis = plt.subplots(3, 2, figsize=(20, 15), sharey=True)\n",
    "# Plot barplots\n",
    "bar1 = sns.barplot(data = result, x = result.index, y='normalized experiment', ax=axis[0,0], color=sns.color_palette()[0])\n",
    "bar1.bar_label(bar1.containers[0], rotation=45)\n",
    "bar1.tick_params('x', labelrotation=45)\n",
    "bar2 = sns.barplot(data = result, x = result.index, y='normalized case study', ax=axis[0,1], color=sns.color_palette()[1])\n",
    "bar2.bar_label(bar2.containers[0], rotation=45)\n",
    "bar2.tick_params('x', labelrotation=45)\n",
    "bar3 = sns.barplot(data = result, x = result.index, y='normalized secondary research', ax=axis[1,0], color=sns.color_palette()[2])\n",
    "bar3.bar_label(bar3.containers[0], rotation=45)\n",
    "bar3.tick_params('x', labelrotation=45)\n",
    "bar4 = sns.barplot(data = result, x = result.index, y='normalized survey', ax=axis[1,1], color=sns.color_palette()[4])\n",
    "bar4.bar_label(bar4.containers[0], rotation=45)\n",
    "bar4.tick_params('x', labelrotation=45)\n",
    "bar5 = sns.barplot(data = result, x = result.index, y='normalized action research', ax=axis[2,0], color=sns.color_palette()[5])\n",
    "bar5.bar_label(bar5.containers[0], rotation=45)\n",
    "bar5.tick_params('x', labelrotation=45)\n",
    "\n",
    "# Remove unnecessary subplot\n",
    "figure.delaxes(axis[2,1])\n",
    "\n",
    "# Set titles\n",
    "plt.suptitle(\"Normalized number of empirical methods used for data collection per year grouped by empirical method\")\n",
    "bar1.set(title = 'Normalized number of experiments used for data collection per year', ylabel='Proportion of experiments', xlabel='Year')\n",
    "bar2.set(title = 'Normalized number of case studies used for data collection per year', ylabel='Proportion of case studies', xlabel='Year')\n",
    "bar3.set(title = 'Normalized number of secondary research used for data collection per year', ylabel='Proportion of secondary research', xlabel='Year')\n",
    "bar4.set(title = 'Normalized number of surveys used for data collection per year', ylabel='Proportion of surveys', xlabel='Year')\n",
    "bar5.set(title = 'Normalized number of actions research used for data collection per year', ylabel='Proportion of action research', xlabel='Year')\n",
    "\n",
    "# Set spacing between subplots\n",
    "figure.tight_layout()\n",
    "plt.savefig('Figures/CQ5/dc_proportion_of_empirical_methods_used_grouped_by_method.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Interpretation*</ins>\n",
    "Based on the figure [\"Normalized number of empirical methods used for data collection per year\"](Figures/CQ5/dc_proportion_of_empirical_methods_used.png), we observe the following trends for the five empirical methods considered for data collection.\n",
    "\n",
    " that mainly seven empirical methods are used for data collection. These seven methods are *case study* (192  times), *experiment* (128 times), *survey* (88 times), *interview* (86 times), *secondary research* (81 times), *action research* (10 times), and *study* as a default category (175 times). While the use of *experiment*, *survey* and *interview* is more or less constantly over time, we observe an three important aspects:\n",
    "\n",
    "1) The proportion of *experiment* is more or less constant over time with an average proportion of 27.4% of all analyzed papers.\n",
    "2) The proportion of *case studies* decreases over time. We assume this change is a result of a clear definition of the term. According to [Wohlin](https://doi.org/10.1016/j.infsof.2021.106514), the term case study is often misused in software engineering research. Based on the manual curation of the 570 papers, we can confirm this finding. Prior to 2013, we found many papers that use the term case study (with an average proportion of 53.2% of all analyzed papers), although at best they report an experiment or a larger use case in the sense of an application example. Despite the decrease, this finding represents a positive development of the empirical research in RE as researchers appear to be more aware of how a case study is defined.\n",
    "3) The proportion of *secondary research*, including literature reviews and archive analysis, is steadily increasing over time. While before 2010 the average proportion of secondary research is 11.5%, the average proportion for the period 2010 - 2019 is 16.4%. For the **target state (2020 - 2025)**, the average proportion of secondary research is already 40% which is more than double the previous averages. In the last year 2022 we observe the current maximum with a proportion of 50% of the analyzed papers using some kind of secondary research.\n",
    "4) The proportion of *survey* is more or less constant with an average proportion of 17.4% of all analyzed papers.\n",
    "5) The proportion of *action research* is constant low over the entire analyzed timeframe (2000 - 2022). In all years analyzed, the proportion of action research is at most 10% of the respective papers with an overall average proportion of only 2% of all analyzed papers. Furthermore, as of 2018, there is no publication using action research.\n",
    "\n",
    "While *experiment* and *survey* are used more or less constantly over time, we even observe an an increasing use of *secondary research*. Regarding *case study*, we observe a decrease over time and *action research* is rarely used overall. This findings are in line with the vision of [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) as researchers often use experiments as well as literature reviews and partially surveys. However, the envisioned use of case studies and action research is not yet achieved. While action research is fundamentally used very little over the entire analyzed timeframe (2000 - 2022), we even observe a decrease in the use of case studies. Although the latter does not fundamentally help achieve the vision of [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), we believe this change nonetheless represents a positive development in empirical research in RE researchers appear to be more aware of how a case study is defined. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='q6'></a>\n",
    "### 3.6 How often are which statistical methods used?\n",
    "\n",
    "#### <ins>*Data Selection*</ins> \n",
    "\n",
    "*Explanation of the Competency Question*:\n",
    "\n",
    "According to [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), the **\"current\" state of practice (2007)** shows that **statistical methods are used mechanically, and with little knowledge about limitations and assumptions**. For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision that **the use of statistical methods is mature**. This predicted change leads to the corresponding competency question.\n",
    "\n",
    "*Required Data for the Analysis*:\n",
    "\n",
    "We must retrieve all papers that use our ORKG template and report on the use of the statistical methods: descriptive statistics and inferential statistics. We consider each of these two types of statistics separately, as our template allows for a correspondingly more fine-grained analysis.\n",
    "\n",
    "[Back to top](#step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Collection*</ins> \n",
    "Below, we retrieve the required data from KG-EmpiRE in the [ORKG](https://www.orkg.org/orkg/) using its [SPARQL endpoint](https://orkg.org/sparql/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '6.1'\n",
    "\n",
    "query_6_1_des_stats = \"\"\"\n",
    "        SELECT ?paper, ?da_label, ?count, ?percent, ?mean, ?median, ?mode, ?minimum, ?maximum, \n",
    "               ?range, ?variance, ?standard_deviation, ?percentile_rank, ?quartile_rank, ?boxplot\n",
    "        WHERE {\n",
    "        ?paper orkgp:P31 ?contribution;\n",
    "               orkgp:P29 ?year.\n",
    "        ?contribution a orkgc:C27001.\n",
    "\n",
    "        OPTIONAL{?contribution orkgp:P15124 ?data_analysis.\n",
    "                ?data_analysis rdfs:label ?da_label.\n",
    "                \n",
    "                OPTIONAl{?data_analysis orkgp:P56048 ?descriptive_stats.\n",
    "                        OPTIONAL{?descriptive_stats orkgp:P56049 ?frequency.\n",
    "                                OPTIONAL{?frequency orkgp:P55023 ?count.}\n",
    "                                OPTIONAL{?frequency orkgp:P56050 ?percent.}}\n",
    "                        OPTIONAL{?descriptive_stats orkgp:P57005 ?central_tendency.\n",
    "                                OPTIONAL{?central_tendency orkgp:P47000 ?mean.}\n",
    "                                OPTIONAL{?central_tendency orkgp:P57006 ?median.}\n",
    "                                OPTIONAL{?central_tendency orkgp:P57007 ?mode.}\n",
    "                                OPTIONAL{?central_tendency orkgp:P44107 ?minimum.}\n",
    "                                OPTIONAL{?central_tendency orkgp:P44108 ?maximum.}}\n",
    "                        OPTIONAL{?descriptive_stats orkgp:P57008 ?variation.\n",
    "                                OPTIONAL{?variation orkgp:P4013 ?range.}\n",
    "                                OPTIONAL{?variation orkgp:P57009 ?variance.}\n",
    "                                OPTIONAL{?variation orkgp:P44087 ?standard_deviation.}}\n",
    "                        OPTIONAL{?descriptive_stats orkgp:P57010 ?position.\n",
    "                                OPTIONAL{?position orkgp:P57011 ?percentile_rank.}\n",
    "                                OPTIONAL{?position orkgp:P57012 ?quartile_rank.}\n",
    "                                OPTIONAL{?position orkgp:P59065 ?boxplot.}}\n",
    "                }\n",
    "        }\n",
    "        FILTER(?da_label = 'analysis'^^xsd:string)\n",
    "        #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_6_1_des_stats)\n",
    "df_query_6_1 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')\n",
    "\n",
    "ID = '6.2'\n",
    "query_6_2_inf_stats = \"\"\"\n",
    "        SELECT ?paper, ?da_label, ?test\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                       orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "\n",
    "                OPTIONAL{?contribution orkgp:P15124 ?data_analysis.\n",
    "                        ?data_analysis rdfs:label ?da_label.\n",
    "                        \n",
    "                        OPTIONAl{?data_analysis orkgp:P56043 ?inferential_stats.\n",
    "                                OPTIONAL{?inferential_stats orkgp:P35133 ?stats_test.\n",
    "                                        ?stats_test rdfs:label ?test}\n",
    "                        }\n",
    "                }\n",
    "                FILTER(?da_label = 'analysis'^^xsd:string)\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_6_2_inf_stats)\n",
    "df_query_6_2 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Exploration*</ins>\n",
    "Below, we explore the retrieved data, including its cleaning and validation, to prepare the data for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_6_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_6_1['da_label'] = df_query_6_1['da_label'].astype('category')\n",
    "df_query_6_1['count'] = df_query_6_1['count'].fillna(False).astype(bool)\n",
    "df_query_6_1['percent'] = df_query_6_1['percent'].fillna(False).astype(bool)\n",
    "df_query_6_1['mean'] = df_query_6_1['mean'].fillna(False).astype(bool)\n",
    "df_query_6_1['median'] = df_query_6_1['median'].fillna(False).astype(bool)\n",
    "df_query_6_1['mode'] = df_query_6_1['mode'].fillna(False).astype(bool)\n",
    "df_query_6_1['minimum'] = df_query_6_1['minimum'].fillna(False).astype(bool)\n",
    "df_query_6_1['maximum'] = df_query_6_1['maximum'].fillna(False).astype(bool)\n",
    "df_query_6_1['range'] = df_query_6_1['range'].fillna(False).astype(bool)\n",
    "df_query_6_1['variance'] = df_query_6_1['variance'].fillna(False).astype(bool)\n",
    "df_query_6_1['standard_deviation'] = df_query_6_1['standard_deviation'].fillna(False).astype(bool)\n",
    "df_query_6_1['percentile_rank'] = df_query_6_1['percentile_rank'].fillna(False).astype(bool)\n",
    "df_query_6_1['quartile_rank'] = df_query_6_1['quartile_rank'].fillna(False).astype(bool)\n",
    "df_query_6_1['boxplot'] = df_query_6_1['boxplot'].fillna(False).astype(bool)\n",
    "#display(df_query_6_1.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_6_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_6_2['da_label'] = df_query_6_2['da_label'].astype('category')\n",
    "df_query_6_2['test'] = df_query_6_2['test'].astype('category')\n",
    "\n",
    "#display(df_query_6_2['da_label'].value_counts())\n",
    "#display(df_query_6_2['test'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Analysis*</ins>\n",
    "For this data analysis, we consider the statistical methods of descriptive statistics used for data analysis. We identify the statistical methods of descriptive statistics used for data analysis. A paper can involve more than one statistical methods of descriptive statistics used for data analysis so that the number of statistical methodsof descriptive statistics used for data analysis can be larger than the number of papers using empricial methods for data analysis. We normalize the number of statistical methods of descriptive statistics used for data analysis based on the number of all papers using at least one empirical method for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(df_query_6_1[['count', 'percent','mean', 'median', 'mode', 'minimum', 'maximum', 'range', 'variance', 'standard_deviation', 'percentile_rank', 'quartile_rank', 'boxplot']].sum().sort_values())\n",
    "result.columns = ['number_of_papers_with_des_stats']\n",
    "result.index = result.index.map(str.capitalize)\n",
    "result = result.rename(index={'Standard_deviation': 'Standard deviation', 'Percentile_rank': 'Percentile rank', 'Quartile_rank': 'Quartile rank'})\n",
    "#display(result)\n",
    "\n",
    "ax = result.plot(kind='barh', rot=0)\n",
    "#ax.invert_yaxis()\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.get_legend().remove()\n",
    "plt.title('Number of statistical methods of descriptive statistics used for data analysis')\n",
    "plt.xlabel('Number of statistical method used')\n",
    "plt.ylabel('Statistical method used')\n",
    "plt.savefig('Figures/CQ6/des_stats_number_of_statistical_methods_used.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "number_of_all_papers_with_da = df_query_6_1['da_label'].count()\n",
    "result['normalized'] = (result['number_of_papers_with_des_stats'] / number_of_all_papers_with_da).round(2)\n",
    "#display(result)\n",
    "\n",
    "plt.figure()\n",
    "ax = result.loc[:, 'normalized'].plot(kind='barh', rot=0)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title('Normalized number of statistical methods of descriptive statistics used for data analysis')\n",
    "plt.xlabel('Proportion of statistical method used')\n",
    "plt.ylabel('Statistical method used')\n",
    "plt.savefig('Figures/CQ6/des_stats_proportion_of_statistical_methods_used.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this data analysis, we consider the statistical methods of inferential statistics used for data analysis. We identify the statistical methods of inferenttial statistics used for data analysis. A paper can involve more than one statistical methods of inferential statistics used for data analysis so that the number of statistical methodsof inferential statistics used for data analysis can be larger than the number of papers using empricial methods for data analysis. We normalize the number of statistical methods of inferential statistics used for data analysis based on the number of all papers using at least one empirical method for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(df_query_6_2['test'].value_counts().rename_axis('Statistical test').to_frame(name='Number'))\n",
    "result.index = result.index.map(str.capitalize)\n",
    "number_of_all_papers_with_da = df_query_6_2.drop_duplicates(subset=['paper'])['da_label'].count()\n",
    "result['Normalized number'] = (result['Number'] / number_of_all_papers_with_da).round(3)\n",
    "dfi.export(result, 'Figures/CQ6/inf_stats_number_of_statistical_methods_used.png', table_conversion='matplotlib')\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Interpretation*</ins>\n",
    "Based on the figure [\"Normalized number of statistical methods of descriptive statistics used for data analysis\"](Figures/CQ6/des_stats_proportion_of_statistical_methods_used.png), we observe that ten out of twelve statistical methods of descriptive statistics are used for data analysis. These ten methods are *count* (390 times), *percent* (266 times), *mean* (194 times), *range* (110 times), *minimum* (56 times), *standard deviation* (53 times), *median* (49 times), *maximum* (47 times), *boxplot* (43 times), *variance* (7 times), and *mode* (3 times). Most frequently the analyzed papers report *count* with a proportion of 86%, followed by *percent* with a proportion of 59%, *mean* with a proportion of 43%, and *range* with a proportion of at least 24%. These results show that researcher mainly report absolut (*count*) and relative (*percent*) values as well averages. While they also report sometimes ranges, most other statistical methods of descriptive statistics are rarely used as they have a maximum proportion of 12% of the papers analyzed.\n",
    "\n",
    "Based on the figure [\"Number and Normalized number of statistical methods of inferential statistics used for data analysis\"](Figures/CQ6/inf_stats_number_of_statistical_methods_used.png), we see that 57 statistical tests are reported in the 570 papers analyzed. A closer look at the names of the statistical tests extracted from the papers shows that there seems to be a large number of different spellings for partly the same test, such as the Mann-Whitney-U-test with 6 different spellings. Unfortunately, most papers do not provide a reference with which it could be determined more precisely whether all the different spellings really always refer to the same test. Overall, the maximum proportion of the most frequently used statistical tests (Wilcoxon signed rank test and Shapiro-Wilk test) is 2.9%. Thus, the application of statistical methods of inferential statistics seems to be, on the one hand, rather low and, on the other hand, very diverse.\n",
    "\n",
    "The results indicate that the envisioned use of statistical methods is not yet mature as the overall and individual proporation of statistical tests is rather low and researchers already struggle with the consistent use of uniform names for the statistical tests applied. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='q7'></a>\n",
    "### 3.7 How has the use of statistical methods evolved over time?\n",
    "\n",
    "#### <ins>*Data Selection*</ins> \n",
    "\n",
    "*Explanation of the Competency Question*:\n",
    "\n",
    "According to [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), the **\"current\" state of practice (2007)** shows that **statistical methods are used mechanically, and with little knowledge about limitations and assumptions**. For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision that **the use of statistical methods is mature**. This predicted change leads to the corresponding competency question.\n",
    "\n",
    "*Required Data for the Analysis*:\n",
    "\n",
    "We must retrieve all papers with their publication year that use our ORKG template and report on the use of the statistical methods: descriptive statistics and inferential statistics. We consider each of these two types of statistics separately, as our template allows for a correspondingly more fine-grained analysis.\n",
    "\n",
    "[Back to top](#step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Collection*</ins> \n",
    "Below, we retrieve the required data from KG-EmpiRE in the [ORKG](https://www.orkg.org/orkg/) using its [SPARQL endpoint](https://orkg.org/sparql/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '7.1'\n",
    "\n",
    "query_7_1_des_stats = \"\"\"\n",
    "        SELECT ?paper, ?year, ?da_label, ?count, ?percent, ?mean, ?median, ?mode, ?minimum, ?maximum, \n",
    "               ?range, ?variance, ?standard_deviation, ?percentile_rank, ?quartile_rank, ?boxplot\n",
    "        WHERE {\n",
    "        ?paper orkgp:P31 ?contribution;\n",
    "               orkgp:P29 ?year.\n",
    "        ?contribution a orkgc:C27001.\n",
    "\n",
    "        OPTIONAL{?contribution orkgp:P15124 ?data_analysis.\n",
    "                ?data_analysis rdfs:label ?da_label.\n",
    "                \n",
    "                OPTIONAl{?data_analysis orkgp:P56048 ?descriptive_stats.\n",
    "                        OPTIONAL{?descriptive_stats orkgp:P56049 ?frequency.\n",
    "                                OPTIONAL{?frequency orkgp:P55023 ?count.}\n",
    "                                OPTIONAL{?frequency orkgp:P56050 ?percent.}}\n",
    "                        OPTIONAL{?descriptive_stats orkgp:P57005 ?central_tendency.\n",
    "                                OPTIONAL{?central_tendency orkgp:P47000 ?mean.}\n",
    "                                OPTIONAL{?central_tendency orkgp:P57006 ?median.}\n",
    "                                OPTIONAL{?central_tendency orkgp:P57007 ?mode.}\n",
    "                                OPTIONAL{?central_tendency orkgp:P44107 ?minimum.}\n",
    "                                OPTIONAL{?central_tendency orkgp:P44108 ?maximum.}}\n",
    "                        OPTIONAL{?descriptive_stats orkgp:P57008 ?variation.\n",
    "                                OPTIONAL{?variation orkgp:P4013 ?range.}\n",
    "                                OPTIONAL{?variation orkgp:P57009 ?variance.}\n",
    "                                OPTIONAL{?variation orkgp:P44087 ?standard_deviation.}}\n",
    "                        OPTIONAL{?descriptive_stats orkgp:P57010 ?position.\n",
    "                                OPTIONAL{?position orkgp:P57011 ?percentile_rank.}\n",
    "                                OPTIONAL{?position orkgp:P57012 ?quartile_rank.}\n",
    "                                OPTIONAL{?position orkgp:P59065 ?boxplot.}}\n",
    "                }\n",
    "        }\n",
    "        FILTER(?da_label = 'analysis'^^xsd:string)\n",
    "        #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_7_1_des_stats)\n",
    "df_query_7_1 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')\n",
    "\n",
    "ID = '7.2'\n",
    "query_7_2_inf_stats = \"\"\"\n",
    "        SELECT ?paper, ?year, ?da_label, ?test\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                        orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "\n",
    "                OPTIONAL{?contribution orkgp:P15124 ?data_analysis.\n",
    "                        ?data_analysis rdfs:label ?da_label.\n",
    "                        \n",
    "                        OPTIONAl{?data_analysis orkgp:P56043 ?inferential_stats.\n",
    "                                OPTIONAL{?inferential_stats orkgp:P35133 ?stats_test.\n",
    "                                        ?stats_test rdfs:label ?test}\n",
    "                        }\n",
    "                }\n",
    "                FILTER(?da_label = 'analysis'^^xsd:string)\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_7_2_inf_stats)\n",
    "df_query_7_2 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Exploration*</ins>\n",
    "Below, we explore the retrieved data, including its cleaning and validation, to prepare the data for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_7_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_7_1['da_label'] = df_query_7_1['da_label'].astype('category')\n",
    "df_query_7_1['count'] = df_query_7_1['count'].fillna(False).astype(bool)\n",
    "df_query_7_1['percent'] = df_query_7_1['percent'].fillna(False).astype(bool)\n",
    "df_query_7_1['mean'] = df_query_7_1['mean'].fillna(False).astype(bool)\n",
    "df_query_7_1['median'] = df_query_7_1['median'].fillna(False).astype(bool)\n",
    "df_query_7_1['mode'] = df_query_7_1['mode'].fillna(False).astype(bool)\n",
    "df_query_7_1['minimum'] = df_query_7_1['minimum'].fillna(False).astype(bool)\n",
    "df_query_7_1['maximum'] = df_query_7_1['maximum'].fillna(False).astype(bool)\n",
    "df_query_7_1['range'] = df_query_7_1['range'].fillna(False).astype(bool)\n",
    "df_query_7_1['variance'] = df_query_7_1['variance'].fillna(False).astype(bool)\n",
    "df_query_7_1['standard_deviation'] = df_query_7_1['standard_deviation'].fillna(False).astype(bool)\n",
    "df_query_7_1['percentile_rank'] = df_query_7_1['percentile_rank'].fillna(False).astype(bool)\n",
    "df_query_7_1['quartile_rank'] = df_query_7_1['quartile_rank'].fillna(False).astype(bool)\n",
    "df_query_7_1['boxplot'] = df_query_7_1['boxplot'].fillna(False).astype(bool)\n",
    "#display(df_query_7_1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_7_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_7_2['da_label'] = df_query_7_2['da_label'].astype('category')\n",
    "df_query_7_2['test'] = df_query_7_2['test'].astype('category')\n",
    "\n",
    "#display(df_query_7_2['da_label'].value_counts())\n",
    "#display(df_query_7_2['test'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Analysis*</ins>\n",
    "For this data analysis, we consider the statistical methods of descriptive statistics used for data analysis. We identify the statistical methods of descriptive statistics used for data analysis. A paper can involve more than one statistical methods of descriptive statistics used for data analysis so that the number of statistical methodsof descriptive statistics used for data analysis can be larger than the number of papers using empricial methods for data analysis. We normalize the number of statistical methods of descriptive statistics used for data analysis based on the number of all papers using at least one empirical method for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(df_query_7_1.groupby('year')[['count', 'percent', 'mean', 'median', 'mode', 'minimum', 'maximum', 'range', 'variance', 'standard_deviation', 'percentile_rank', 'quartile_rank', 'boxplot']].sum())\n",
    "#display(result)\n",
    "\n",
    "ax = result.plot(kind='bar', rot=0)\n",
    "ax.legend(bbox_to_anchor=(1.0, 0.8), labels=['Count', 'Percent', 'Mean', 'Median', 'Mode', 'Minimum', 'Maximum', 'Range', 'Variance', 'Standard deviation', 'Percentile rank', 'Quartile rank', 'Boxplot'])\n",
    "plt.title('Number of statistical methods of descriptive statistics used for data analysis per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of statistical method used')\n",
    "plt.savefig('Figures/CQ7/des_stats_number_of_statistical_methods_used.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "figure, axis = plt.subplots(7, 2, figsize=(22, 25), sharey=True)\n",
    "# Plot barplots\n",
    "bar1 = sns.barplot(data = result, x = result.index, y='count', ax=axis[0,0], color=sns.color_palette()[0])\n",
    "bar1.bar_label(bar1.containers[0])\n",
    "bar1.tick_params('x', labelrotation=45)\n",
    "bar2 = sns.barplot(data = result, x = result.index, y='percent', ax=axis[0,1], color=sns.color_palette()[1])\n",
    "bar2.bar_label(bar2.containers[0])\n",
    "bar2.tick_params('x', labelrotation=45)\n",
    "bar3 = sns.barplot(data = result, x = result.index, y='mean', ax=axis[1,0], color=sns.color_palette()[2])\n",
    "bar3.bar_label(bar3.containers[0])\n",
    "bar3.tick_params('x', labelrotation=45)\n",
    "bar4 = sns.barplot(data = result, x = result.index, y='median', ax=axis[1,1], color=sns.color_palette()[3])\n",
    "bar4.bar_label(bar4.containers[0])\n",
    "bar4.tick_params('x', labelrotation=45)\n",
    "bar5 = sns.barplot(data = result, x = result.index, y='mode', ax=axis[2,0], color=sns.color_palette()[4])\n",
    "bar5.bar_label(bar5.containers[0])\n",
    "bar5.tick_params('x', labelrotation=45)\n",
    "bar6 = sns.barplot(data = result, x = result.index, y='minimum', ax=axis[2,1], color=sns.color_palette()[5])\n",
    "bar6.bar_label(bar6.containers[0])\n",
    "bar6.tick_params('x', labelrotation=45)\n",
    "bar7 = sns.barplot(data = result, x = result.index, y='maximum', ax=axis[3,0], color=sns.color_palette()[6])\n",
    "bar7.bar_label(bar7.containers[0])\n",
    "bar7.tick_params('x', labelrotation=45)\n",
    "bar8 = sns.barplot(data = result, x = result.index, y='range', ax=axis[3,1], color=sns.color_palette()[7])\n",
    "bar8.bar_label(bar8.containers[0])\n",
    "bar8.tick_params('x', labelrotation=45)\n",
    "bar9 = sns.barplot(data = result, x = result.index, y='variance', ax=axis[4,0], color=sns.color_palette()[8])\n",
    "bar9.bar_label(bar9.containers[0])\n",
    "bar9.tick_params('x', labelrotation=45)\n",
    "bar10 = sns.barplot(data = result, x = result.index, y='standard_deviation', ax=axis[4,1], color=sns.color_palette()[9])\n",
    "bar10.bar_label(bar10.containers[0])\n",
    "bar10.tick_params('x', labelrotation=45)\n",
    "bar11 = sns.barplot(data = result, x = result.index, y='percentile_rank', ax=axis[5,0], color=sns.color_palette()[0])\n",
    "bar11.bar_label(bar11.containers[0])\n",
    "bar11.tick_params('x', labelrotation=45)\n",
    "bar12 = sns.barplot(data = result, x = result.index, y='quartile_rank', ax=axis[5,1], color=sns.color_palette()[1])\n",
    "bar12.bar_label(bar12.containers[0])\n",
    "bar12.tick_params('x', labelrotation=45)\n",
    "bar13 = sns.barplot(data = result, x = result.index, y='boxplot', ax=axis[6,0], color=sns.color_palette()[2])\n",
    "bar13.bar_label(bar13.containers[0])\n",
    "bar13.tick_params('x', labelrotation=45)\n",
    "\n",
    "# Remove unnecessary subplot\n",
    "figure.delaxes(axis[6,1])\n",
    "\n",
    "# Set titles\n",
    "plt.suptitle(\"Number of statistical method used for data analysis per year grouped by statistical method\")\n",
    "bar1.set(title = 'Number of count method used for data analysis per year', ylabel='Number of count method', xlabel='Year')\n",
    "bar2.set(title = 'Number of percent method used for data analysis per year', ylabel='Number of percent method', xlabel='Year')\n",
    "bar3.set(title = 'Number of mean method used for data analysis per year', ylabel='Number of mean method', xlabel='Year')\n",
    "bar4.set(title = 'Number of median method used for data analysis per year', ylabel='Number of median method', xlabel='Year')\n",
    "bar5.set(title = 'Number of mode method used for data analysis per year', ylabel='Number of mode method', xlabel='Year')\n",
    "bar6.set(title = 'Number of minimum method used for data analyis per year', ylabel='Number of minimum method', xlabel='Year')\n",
    "bar7.set(title = 'Number of maximum method used for data analysis per year', ylabel='Number of maximum method', xlabel='Year')\n",
    "bar8.set(title = 'Number of range method used for data analysis per year', ylabel='Number of range method', xlabel='Year')\n",
    "bar9.set(title = 'Number of variance method used for data analysis per year', ylabel='Number of variance method', xlabel='Year')\n",
    "bar10.set(title = 'Number of standard deviation method used for data analysis per year', ylabel='Number of standard deviation method', xlabel='Year')\n",
    "bar11.set(title = 'Number of percentile rank method used for data analysis per year', ylabel='Number of percentile rank method', xlabel='Year')\n",
    "bar12.set(title = 'Number of quartile rank method used for data analysis per year', ylabel='Number of quartile rank method', xlabel='Year')\n",
    "bar13.set(title = 'Number of boxplot method used for data analysis per year', ylabel='Number of boxplot method', xlabel='Year')\n",
    "\n",
    "# Set spacing between subplots\n",
    "figure.tight_layout()\n",
    "plt.savefig('Figures/CQ7/des_stats_number_of_statistical_methods_used_grouped_by_method.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "number_of_all_papers_with_da = df_query_7_1.groupby('year')['da_label'].count()\n",
    "\n",
    "result = pd.concat([result, number_of_all_papers_with_da], axis=1)\n",
    "result['normalized count'] = (result['count'] / result['da_label']).round(2)\n",
    "result['normalized percent'] = (result['percent'] / result['da_label']).round(2)\n",
    "result['normalized mean'] = (result['mean'] / result['da_label']).round(2)\n",
    "result['normalized median'] = (result['median'] / result['da_label']).round(2)\n",
    "result['normalized mode'] = (result['mode'] / result['da_label']).round(2)\n",
    "result['normalized minimum'] = (result['minimum'] / result['da_label']).round(2)\n",
    "result['normalized maximum'] = (result['maximum'] / result['da_label']).round(2)\n",
    "result['normalized range'] = (result['range'] / result['da_label']).round(2)\n",
    "result['normalized variance'] = (result['variance'] / result['da_label']).round(2)\n",
    "result['normalized standard deviation'] = (result['standard_deviation'] / result['da_label']).round(2)\n",
    "result['normalized percentile rank'] = (result['percentile_rank'] / result['da_label']).round(2)\n",
    "result['normalized quartile rank'] = (result['quartile_rank'] / result['da_label']).round(2)\n",
    "result['normalized boxplot'] = (result['boxplot'] / result['da_label']).round(2)\n",
    "#display(result)\n",
    "\n",
    "ax = result.loc[:, 'normalized count':'normalized boxplot'].plot(kind='bar', rot=0)\n",
    "ax.legend(bbox_to_anchor=(1.0, 0.8), labels=['Count', 'Percent', 'Mean', 'Median', 'Mode', 'Minimum', 'Maximum', 'Range', 'Variance', 'Standard deviation', 'Percentile rank', 'Quartile rank', 'Boxplot'])\n",
    "# #make_axes_area_auto_adjustable(ax)\n",
    "plt.title('Normalized statistical methods of descriptive statistics used for data analysis per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Proportion of statistical method used')\n",
    "plt.savefig('Figures/CQ7/des_stats_proportion_of_statistical_methods_used.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "figure, axis = plt.subplots(7, 2, figsize=(22, 25), sharey=True)\n",
    "# Plot barplots\n",
    "bar1 = sns.barplot(data = result, x = result.index, y='normalized count', ax=axis[0,0], color=sns.color_palette()[0])\n",
    "bar1.bar_label(bar1.containers[0])\n",
    "bar1.tick_params('x', labelrotation=45)\n",
    "bar2 = sns.barplot(data = result, x = result.index, y='normalized percent', ax=axis[0,1], color=sns.color_palette()[1])\n",
    "bar2.bar_label(bar2.containers[0])\n",
    "bar2.tick_params('x', labelrotation=45)\n",
    "bar3 = sns.barplot(data = result, x = result.index, y='normalized mean', ax=axis[1,0], color=sns.color_palette()[2])\n",
    "bar3.bar_label(bar3.containers[0])\n",
    "bar3.tick_params('x', labelrotation=45)\n",
    "bar4 = sns.barplot(data = result, x = result.index, y='normalized median', ax=axis[1,1], color=sns.color_palette()[3])\n",
    "bar4.bar_label(bar4.containers[0])\n",
    "bar4.tick_params('x', labelrotation=45)\n",
    "bar5 = sns.barplot(data = result, x = result.index, y='normalized mode', ax=axis[2,0], color=sns.color_palette()[4])\n",
    "bar5.bar_label(bar5.containers[0])\n",
    "bar5.tick_params('x', labelrotation=45)\n",
    "bar6 = sns.barplot(data = result, x = result.index, y='normalized minimum', ax=axis[2,1], color=sns.color_palette()[5])\n",
    "bar6.bar_label(bar6.containers[0])\n",
    "bar6.tick_params('x', labelrotation=45)\n",
    "bar7 = sns.barplot(data = result, x = result.index, y='normalized maximum', ax=axis[3,0], color=sns.color_palette()[6])\n",
    "bar7.bar_label(bar7.containers[0])\n",
    "bar7.tick_params('x', labelrotation=45)\n",
    "bar8 = sns.barplot(data = result, x = result.index, y='normalized range', ax=axis[3,1], color=sns.color_palette()[7])\n",
    "bar8.bar_label(bar8.containers[0])\n",
    "bar8.tick_params('x', labelrotation=45)\n",
    "bar9 = sns.barplot(data = result, x = result.index, y='normalized variance', ax=axis[4,0], color=sns.color_palette()[8])\n",
    "bar9.bar_label(bar9.containers[0])\n",
    "bar9.tick_params('x', labelrotation=45)\n",
    "bar10 = sns.barplot(data = result, x = result.index, y='normalized standard deviation', ax=axis[4,1], color=sns.color_palette()[9])\n",
    "bar10.bar_label(bar10.containers[0])\n",
    "bar10.tick_params('x', labelrotation=45)\n",
    "bar11 = sns.barplot(data = result, x = result.index, y='normalized percentile rank', ax=axis[5,0], color=sns.color_palette()[0])\n",
    "bar11.bar_label(bar11.containers[0])\n",
    "bar11.tick_params('x', labelrotation=45)\n",
    "bar12 = sns.barplot(data = result, x = result.index, y='normalized quartile rank', ax=axis[5,1], color=sns.color_palette()[1])\n",
    "bar12.bar_label(bar12.containers[0])\n",
    "bar12.tick_params('x', labelrotation=45)\n",
    "bar13 = sns.barplot(data = result, x = result.index, y='normalized boxplot', ax=axis[6,0], color=sns.color_palette()[2])\n",
    "bar13.bar_label(bar13.containers[0])\n",
    "bar13.tick_params('x', labelrotation=45)\n",
    "\n",
    "# Remove unnecessary subplot\n",
    "figure.delaxes(axis[6,1])\n",
    "\n",
    "# Set titles\n",
    "plt.suptitle(\"Normalized number of statistical method used for data analysis per year grouped by statistical method\")\n",
    "bar1.set(title = 'Normalized number of count method used for data analysis per year', ylabel='Proportion of count method', xlabel='Year')\n",
    "bar2.set(title = 'Normalized number of percent method used for data analysis per year', ylabel='Proportion of percent method', xlabel='Year')\n",
    "bar3.set(title = 'Normalized number of mean method used for data analysis per year', ylabel='Proportion of mean method', xlabel='Year')\n",
    "bar4.set(title = 'Normalized number of median method used for data analysis per year', ylabel='Proportion of median method', xlabel='Year')\n",
    "bar5.set(title = 'Normalized number of mode method used for data analysis per year', ylabel='Proportion of mode method', xlabel='Year')\n",
    "bar6.set(title = 'Normalized number of minimum method used for data analyis per year', ylabel='Proportion of minimum method', xlabel='Year')\n",
    "bar7.set(title = 'Normalized number of maximum method used for data analysis per year', ylabel='Proportion of maximum method', xlabel='Year')\n",
    "bar8.set(title = 'Normalized number of range method used for data analysis per year', ylabel='Proportion of range method', xlabel='Year')\n",
    "bar9.set(title = 'Normalized number of variance method used for data analysis per year', ylabel='Proportion of variance method', xlabel='Year')\n",
    "bar10.set(title = 'Normalized number of standard deviation method used for data analysis per year', ylabel='Proportion of standard deviation method', xlabel='Year')\n",
    "bar11.set(title = 'Normalized number of percentile rank method used for data analysis per year', ylabel='Proportion of percentile rank method', xlabel='Year')\n",
    "bar12.set(title = 'Normalized number of quartile rank method used for data analysis per year', ylabel='Proportion of quartile rank method', xlabel='Year')\n",
    "bar13.set(title = 'Normalized number of boxplot method used for data analysis per year', ylabel='Proportion of boxplot method', xlabel='Year')\n",
    "\n",
    "# Set spacing between subplots\n",
    "figure.tight_layout()\n",
    "plt.savefig('Figures/CQ7/des_stats_proportion_of_statistical_methods_used_grouped_by_method.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this data analysis, we consider the statistical methods of inferential statistics used for data analysis. We identify the statistical methods of inferenttial statistics used for data analysis. A paper can involve more than one statistical methods of inferential statistics used for data analysis so that the number of statistical methodsof inferential statistics used for data analysis can be larger than the number of papers using empricial methods for data analysis. We normalize the number of statistical methods of inferential statistics used for data analysis based on the number of all papers using at least one empirical method for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(df_query_7_2.groupby('year')['test'].value_counts().unstack())\n",
    "dfi.export(result, 'Figures/CQ7/inf_stats_number_of_statistical_methods_used.png', table_conversion='matplotlib', max_cols=-1)\n",
    "display(result)\n",
    "\n",
    "number_of_all_papers_with_da = df_query_7_1.groupby('year')['da_label'].count()\n",
    "result_2 = pd.DataFrame()\n",
    "for column in result:\n",
    "    result_2['normalized ' + str(column)] = (result[column] / number_of_all_papers_with_da).round(3)\n",
    "dfi.export(result_2, 'Figures/CQ7/inf_stats_proportion_of_statistical_methods_used.png', table_conversion='matplotlib', max_cols=-1)\n",
    "display(result_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Interpretation*</ins>\n",
    "Based on the figure [\"Normalized number of statistical methods of descriptive statistics used for data analysis per year grouped by statistical method\"](Figures/CQ7/des_stats_proportion_of_statistical_methods_used_grouped_by_method.png), we observe that ten out of twelve statistical methods of descriptive statistics are used for data analysis. These ten methods are *count* (390 times), *percent* (266 times), *mean* (194 times), *range* (110 times), *minimum* (56 times), *standard deviation* (53 times), *median* (49 times), *maximum* (49 times), *boxplot* (43 times), *variance* (7 times), and *mode* (3 times). While the statistical methods of decriptive statistics *count*, *percent*, and *mean* are most frequently used compared to the other statistical methods of descriptive statistics, we observe that each method itself is more or less constantly used over time.\n",
    "\n",
    "Based on the table [\"Number and Normalized number of statistical methods of inferential statistics used for data analysis\"](Figures/CQ7/inf_stats_proportion_of_statistical_methods_used.png), we see that the use of statistical tests of inferential statistics is very diverse due to the large number of 57 statistical tests (different based on their reported names). \n",
    "\n",
    "Overall, there is no clear trend that a mature use of statistical methods has emerged over time, especially not for the **target state (2020 - 2025)** so far."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='q8'></a>\n",
    "### 3.8 How has the reporting of threats to validity evolved over time?\n",
    "\n",
    "#### <ins>*Data Selection*</ins> \n",
    "\n",
    "*Explanation of the Competency Question*:\n",
    "\n",
    "According to [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), the **\"current\" state of practice (2007)** shows that researchers **lack knwoledge about limitations and assumptions of statistical tests, power analysis and effect size estiamtion as well as do not well define populations**. For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision that **all these aspects are sufficiently addressed**. All mentioned aspects related to threats to validity of an empirical study and this predicted change leads to the corresponding competency question.\n",
    "\n",
    "*Required Data for the Analysis*:\n",
    "\n",
    "We must retrieve all papers with their publication year that use our ORKG template and report on threats to validity.\n",
    "\n",
    "[Back to top](#step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Collection*</ins> \n",
    "Below, we retrieve the required data from KG-EmpiRE in the [ORKG](https://www.orkg.org/orkg/) using its [SPARQL endpoint](https://orkg.org/sparql/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '8'\n",
    "\n",
    "query_8 = \"\"\"\n",
    "        SELECT ?paper, ?year, ?threats, ?threats_label\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                        orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "\n",
    "                OPTIONAL{?contribution orkgp:P39099 ?threats.\n",
    "                        ?threats rdfs:label ?threats_label.\n",
    "                }\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_8)\n",
    "\n",
    "df_query_8 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Exploration*</ins>\n",
    "Below, we explore the retrieved data, including its cleaning and validation, to prepare the data for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_8['threats_label'] = df_query_8['threats_label'].astype('category')\n",
    "display(df_query_8['threats_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Analysis*</ins>\n",
    "For this data analysis, we select all papers that report threats to validity. For more detailed insights, we normalize the number of all papers reporting threats to validity based on the number of all unique papers per year, as the total number of papers per year varies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(df_query_8.drop_duplicates(subset=['paper']).reset_index(drop=True)['year'].value_counts())\n",
    "result.columns = ['number_of_all_papers']\n",
    "\n",
    "papers_with_threats = df_query_8[(df_query_8['threats_label'] != 'non')]\n",
    "papers_with_threats = papers_with_threats.drop_duplicates(subset=['paper'])\n",
    "result['number_of_papers_with_threats'] = papers_with_threats.reset_index(drop=True)['year'].value_counts()\n",
    "\n",
    "result['normalized_papers_with_threats'] = (result['number_of_papers_with_threats'] / result['number_of_all_papers']).round(2)\n",
    "result = result.fillna(0.0)\n",
    "#display(result.sort_index())\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.barplot(data=result, x=result.index, y='number_of_papers_with_threats', color='b')\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title('Number of papers reporting threats to validity per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of papers reporting threats to validity')\n",
    "plt.savefig('Figures/CQ8/number_of_papers_with_threats.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.barplot(data=result, x=result.index, y='normalized_papers_with_threats', color='b')\n",
    "ax.bar_label(ax.containers[0], fmt='%.2f')\n",
    "plt.title('Normalized number of papers reporting threats to validity per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Proportion of papers reporting threats to validity')\n",
    "plt.savefig('Figures/CQ8/proportion_of_papers_with_threats.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Interpretation*</ins>\n",
    "Based on the figure [\"Normalized number of papers reporting threats to validity per year\"](Figures/CQ8/proportion_of_papers_with_threats.png), an increasing proportion of papers reporting threats to validity can be observed over time. While before 2010 the average proportion of papers reporting threats to validity is 17.5%, the average proportion for the period 2010 - 2019 is 72%. For the **target state (2020 - 2025)**, the average proportion of papers reporting threats to validity is 91.3%. Based on these data, we observe a positive development towards the vision of [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) that researchers sufficiently address threats to validity as envisioned for the **target state (2020 - 2025)**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='q9'></a>\n",
    "### 3.9 What types of threats to validity do the authors report?\n",
    "\n",
    "#### <ins>*Data Selection*</ins> \n",
    "\n",
    "*Explanation of the Competency Question*:\n",
    "\n",
    "According to [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), the **\"current\" state of practice (2007)** shows that researchers **lack knwoledge about limitations and assumptions of statistical tests, power analysis and effect size estiamtion as well as do not well define populations**. For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision that **all these aspects are sufficiently addressed**. All mentioned aspects related to threats to validity of an empirical study and this predicted change leads to the corresponding competency question.\n",
    "\n",
    "*Required Data for the Analysis*:\n",
    "\n",
    "We must retrieve all papers with their publication year that use our ORKG template and report on threats to validity.\n",
    "\n",
    "[Back to top](#step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Collection*</ins> \n",
    "Below, we retrieve the required data from KG-EmpiRE in the [ORKG](https://www.orkg.org/orkg/) using its [SPARQL endpoint](https://orkg.org/sparql/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '9'\n",
    "\n",
    "query_9 = \"\"\"\n",
    "        SELECT ?paper, ?year, ?threats_label, ?external, ?internal, ?construct, ?conclusion, ?reliability, ?generalizability, ?content, ?descriptive, ?theoretical, ?repeatability\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                        orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "\n",
    "                OPTIONAL{?contribution orkgp:P39099 ?threats.\n",
    "                        ?threats rdfs:label ?threats_label.\n",
    "                        OPTIONAL{?threats orkgp:P55034 ?external.}\n",
    "                        OPTIONAL{?threats orkgp:P55035 ?internal.}\n",
    "                        OPTIONAL{?threats orkgp:P55037 ?construct.}\n",
    "                        OPTIONAL{?threats orkgp:P55036 ?conclusion.}\n",
    "                        OPTIONAL{?threats orkgp:P59109 ?reliability.}\n",
    "                        OPTIONAL{?threats orkgp:P60006 ?generalizability.}\n",
    "                        OPTIONAL{?threats orkgp:P68005 ?content.}\n",
    "                        OPTIONAL{?threats orkgp:P97000 ?descriptive.}\n",
    "                        OPTIONAL{?threats orkgp:P97001 ?theoretical.}\n",
    "                        OPTIONAL{?threats orkgp:P97002 ?repeatability.} \n",
    "                        }\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "                }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_9)\n",
    "\n",
    "df_query_9 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Exploration*</ins>\n",
    "Below, we explore the retrieved data, including its cleaning and validation, to prepare the data for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_9['external'] = df_query_9['external'].fillna(False).astype(bool)\n",
    "df_query_9['internal'] = df_query_9['internal'].fillna(False).astype(bool)\n",
    "df_query_9['construct'] = df_query_9['construct'].fillna(False).astype(bool)\n",
    "df_query_9['conclusion'] = df_query_9['conclusion'].fillna(False).astype(bool)\n",
    "df_query_9['reliability'] = df_query_9['reliability'].fillna(False).astype(bool)\n",
    "df_query_9['generalizability'] = df_query_9['generalizability'].fillna(False).astype(bool)\n",
    "df_query_9['content'] = df_query_9['content'].fillna(False).astype(bool)\n",
    "df_query_9['descriptive'] = df_query_9['descriptive'].fillna(False).astype(bool)\n",
    "df_query_9['theoretical'] = df_query_9['theoretical'].fillna(False).astype(bool)\n",
    "df_query_9['repeatability'] = df_query_9['repeatability'].fillna(False).astype(bool)\n",
    "#display(df_query_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Analysis*</ins>\n",
    "For this data analysis, we select all papers that report threats to validity. For more detailed insights, we normalize the number of all papers reporting threats to validity based on the number of all unique papers per year, as the total number of papers per year varies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(df_query_9[['external', 'internal','construct', 'conclusion', 'reliability', 'generalizability', 'content', 'descriptive', 'theoretical', 'repeatability']].sum().sort_values())\n",
    "result.columns = ['number_of_papers_with_threats']\n",
    "result = result.rename(index={'external': 'External validity', 'internal': 'Internal validity','construct': 'Construct validity', 'conclusion': 'Conclusion validity', 'reliability': 'Reliability', 'generalizability': 'Generalizability', 'content': 'Content validity', 'descriptive': 'Descriptive validity', 'theoretical': 'Theoretical validity', 'repeatability': 'Repeatability'})\n",
    "number_of_papers_with_threats_mentioned = df_query_9[df_query_9['threats_label'] == 'mentioned']['threats_label'].count()\n",
    "mentioned = pd.DataFrame([number_of_papers_with_threats_mentioned], index=['Mentioned, but not classified'], columns=['number_of_papers_with_threats'])\n",
    "result = pd.concat([mentioned, result])\n",
    "#display(result)\n",
    "\n",
    "ax = result.plot(kind='barh', rot=0)\n",
    "#ax.invert_yaxis()\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.get_legend().remove()\n",
    "plt.title('Number of threats to validity reported in papers')\n",
    "plt.xlabel('Number of threats to validity reported')\n",
    "plt.ylabel('Threats to validity reported')\n",
    "plt.savefig('Figures/CQ9/number_of_threats_to_validity_reported.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "number_of_papers_with_threats = df_query_9[(df_query_9['threats_label'] != 'non')]['paper'].count()\n",
    "result['normalized'] = (result['number_of_papers_with_threats'] / number_of_papers_with_threats).round(3)\n",
    "#display(result)\n",
    "\n",
    "plt.figure()\n",
    "ax = result.loc[:, 'normalized'].plot(kind='barh', rot=0)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title('Normalized number of threats to validity reported in papers')\n",
    "plt.xlabel('Proportion of threats to validity reported')\n",
    "plt.ylabel('Threats to validity reported')\n",
    "plt.savefig('Figures/CQ9/proportion_of_threats_to_validity_reported.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Interpretation*</ins>\n",
    "Based on the figure [\"Normalized number of threats to validity reported in papers\"](Figures/CQ9/proportion_of_threats_to_validity_reported.png), we observe that mainly ten different types of validity are reported in all 570 papers analyzed. *External* (60.4% proporation), *internal* (56.1% proportion), and *construct* (47.9% proportion) validity are reported most frequently. All other types of validity have a proportion below 20%. It is striking that *conclusion* validity has only a proportion of 18.2%. Even if we consider the type *reliability* as a synonym of *conclusion* validity and add the proportions together, we still get a proportion of only 28.9%. In this regard, the reporting of threats to validity seems to be unbalanced as frequently researchers do not address the conclusion validity of their findings. In addition, we found that 33.6% of the papers analyzed that report validity threats simply mention threats to validity without further classification of the types of validity addressed. This lack of classification makes it difficult for the reader to easily assess whether the validity of the findings has been extensively discussed.\n",
    "\n",
    "Overall, the results show that researchers mainly deal with the *external*, *internal*, and *construct* validity of their findings. Although a positive development towards a sufficient addressing of threats to value as envisioned in the vision of [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) can be seen, a better consideration of the *conclusion* validity is necessary for a comprehensive consideration of threats to validity. Furthermore, while it is good that researchers report more and more threats to validity, a classification of the threats to validity reported is particularly helpful for the reader to determine whether the validity of the results has been extensively discussed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='q10'></a>\n",
    "### 3.10 How have the proportions of case studies and action research in the empirical methods used evolved over time?\n",
    "\n",
    "#### <ins>*Data Selection*</ins> \n",
    "\n",
    "*Explanation of the Competency Question*:\n",
    "\n",
    "According to [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), one may question the **industrial relevance of most the studies** in the **\"current\" state of practice (2007)**. For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision that researchers carry out **more case studies and actions research**. This predicted change leads to the corresponding competency question.\n",
    "\n",
    "*Required Data for the Analysis*:\n",
    "\n",
    "We must retrieve all papers with their publication year that use our ORKG template and report on the use of the empirical methods: case studies and action research.\n",
    "\n",
    "[Back to top](#step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Collection*</ins> \n",
    "Below, we retrieve the required data from KG-EmpiRE in the [ORKG](https://www.orkg.org/orkg/) using its [SPARQL endpoint](https://orkg.org/sparql/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '10'\n",
    "\n",
    "query_10 = \"\"\"\n",
    "        SELECT ?paper, ?year, ?dc_label\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                        orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "\n",
    "                OPTIONAL{?contribution orkgp:P56008 ?data_collection.\n",
    "                        ?data_collection rdfs:label ?dc_label.\n",
    "                }\n",
    "                FILTER(?dc_label != \"no collection\"^^xsd:string)\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_10)\n",
    "df_query_10 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Exploration*</ins>\n",
    "Below, we explore the retrieved data, including its cleaning and validation, to prepare the data for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_10['dc_label'] = df_query_10['dc_label'].astype('category')\n",
    "display(df_query_10['dc_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Analysis*</ins>\n",
    "For this data analysis, we consider all papers that report on the use of the empirical methods: case study and action research. A paper can involve more than one empirical method for data collection so that the number of empirical methods can be larger than the number of papers. We normalize the number of empirical methods (case study and action research) used based on the number of all unique papers with data collection per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers_per_year = pd.DataFrame(df_query_10.drop_duplicates(subset=['paper']).reset_index(drop=True)['year'].value_counts())\n",
    "all_papers_per_year.columns = ['number_of_papers_with_dc']\n",
    "all_papers_per_year = all_papers_per_year.sort_index()\n",
    "\n",
    "result = pd.DataFrame(df_query_10.groupby('year')['dc_label'].value_counts().unstack())\n",
    "result = result[result.sum().sort_values(ascending=False).index]\n",
    "result = result[['case study', 'action research']]\n",
    "#display(result)\n",
    "\n",
    "result = pd.concat([result, all_papers_per_year], axis=1)\n",
    "result['normalized case study'] = (result['case study'] / result['number_of_papers_with_dc']).round(2)\n",
    "result['normalized action research'] = (result['action research'] / result['number_of_papers_with_dc']).round(2)\n",
    "#display(result)\n",
    "\n",
    "ax = result.loc[:, 'normalized case study':'normalized action research'].plot(kind='bar', rot=0)\n",
    "ax.legend(bbox_to_anchor=(0.8, 0.8), labels=['Case study', 'Action research',])\n",
    "plt.title('Normalized number of case studies and action research used for data collection per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Proportion of empirical method used')\n",
    "plt.savefig('Figures/CQ10/proportion_of_case_studies_and_action_research.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "figure, axis = plt.subplots(1, 2, figsize=(20, 10), sharey=True)\n",
    "# Plot barplots\n",
    "bar1 = sns.barplot(data = result, x = result.index, y='normalized case study', ax=axis[0], color=sns.color_palette()[0])\n",
    "bar1.bar_label(bar1.containers[0], rotation=45)\n",
    "bar1.tick_params('x', labelrotation=45)\n",
    "bar2 = sns.barplot(data = result, x = result.index, y='normalized action research', ax=axis[1], color=sns.color_palette()[1])\n",
    "bar2.bar_label(bar2.containers[0], rotation=45)\n",
    "bar2.tick_params('x', labelrotation=45)\n",
    "\n",
    "# # Set titles\n",
    "plt.suptitle(\"Normalized number of case studies and action research used for data collection per year grouped by empirical method\")\n",
    "bar1.set(title = 'Normalized number of case studies used for data collection per year', ylabel='Proportion of case studies', xlabel='Year')\n",
    "bar2.set(title = 'Normalized number of action research used for data collection per year', ylabel='Proportion of action research', xlabel='Year')\n",
    "\n",
    "# # Set spacing between subplots\n",
    "figure.tight_layout()\n",
    "plt.savefig('Figures/CQ10/proportion_of_case_studies_and_action_research_grouped_by_method.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Interpretation*</ins>\n",
    "Based on the figure [\"Normalized number of case studies and action research used for data collection per year\"](Figures/CQ10/proportion_of_case_studies_and_action_research.png), we observe the following trends for case studies and action research used as empirical methods for data collection.\n",
    "\n",
    "1) The proportion of *case studies* decreases over time. We assume this change is a result of a clear definition of the term. According to [Wohlin](https://doi.org/10.1016/j.infsof.2021.106514), the term case study is often misused in software engineering research. Based on the manual curation of the 570 papers, we can confirm this finding. Prior to 2013, we found many papers that use the term case study (with an average proportion of 53.2% of all analyzed papers with a data collection), although at best they report an experiment or a larger use case in the sense of an application example. Despite the decrease, this finding represents a positive development of the empirical research in RE as researchers appear to be more aware of how a case study is defined.\n",
    "2) The proportion of *action research* is constantly low over the entire analyzed timeframe (2000 - 2022). In all years analyzed, the proportion of action research is at most 10% of the respective papers with an overall average proportion of only 2%. Furthermore, as of 2018, there is no publication using action research.\n",
    "\n",
    "For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision that researchers carry out more case studies and actions research. Regarding *case study*, we observe a decrease over time and *action research* is rarely used overall. For these reason the envisioned use of case studies and action research is not yet achieved. While action research is fundamentally used very little over the entire analyzed timeframe (2000 - 2022), we even observe a decrease in the use of case studies. Although the latter does not fundamentally help achieve the vision of [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), we believe this change nonetheless represents a positive development in empirical research in RE researchers appear to be more aware of how a case study is defined. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='q11'></a>\n",
    "### 3.11 How has the provision of data (the materials used, raw data collected, and study results identified) evolved over time?\n",
    "\n",
    "#### <ins>*Data Selection*</ins> \n",
    "\n",
    "*Explanation of the Competency Question*:\n",
    "\n",
    "According to [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), the **\"current\" state of practice (2007)** shows that **few studies** provide results, materials, and raw data that enable efficient cumulative research. For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision that **more research studies** are designed with the goal of enabling efficient use of its results by other researchers. This predicted change leads to the corresponding competency question.\n",
    "\n",
    "*Required Data for the Analysis*:\n",
    "\n",
    "We must retrieve all papers with their publication year that use our ORKG template and provide at least one url for the availiability of the materials used, raw data collected, and study results.\n",
    "\n",
    "[Back to top](#step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Collection*</ins> \n",
    "Below, we retrieve the required data from KG-EmpiRE in the [ORKG](https://www.orkg.org/orkg/) using its [SPARQL endpoint](https://orkg.org/sparql/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '11'\n",
    "\n",
    "query_11 = \"\"\"\n",
    "        SELECT ?paper, ?year, ?data, ?url\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                        orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "\n",
    "                OPTIONAL{?contribution orkgp:P56008 ?data_collection.\n",
    "                        ?data_collection rdfs:label ?dc_label.\n",
    "                        OPTIONAL{?data_collection orkgp:DATA ?data.\n",
    "                                OPTIONAL{?data orkgp:url ?url.}\n",
    "                                }\n",
    "                        }\n",
    "                FILTER(?dc_label != \"no collection\"^^xsd:string)\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_11)\n",
    "df_query_11 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Exploration*</ins>\n",
    "Below, we explore the retrieved data, including its cleaning and validation, to prepare the data for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Analysis*</ins>\n",
    "For this data analysis, we consider all papers that provide at least one url for the availiability of the materials used, raw data collected, and study results. A paper can involve more than one url for the data. For this reason, we determine the number of papers that provide at least one url and we normalize the number of papers with at least one url based on the number of all unique papers with data collection per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers_per_year = pd.DataFrame(df_query_11.drop_duplicates(subset=['paper']).reset_index(drop=True)['year'].value_counts())\n",
    "all_papers_per_year.columns = ['number_of_papers_with_dc']\n",
    "all_papers_per_year = all_papers_per_year.sort_index()\n",
    "\n",
    "result = pd.DataFrame(df_query_11.drop_duplicates(subset=['paper']).groupby('year')['url'].count())\n",
    "result = result[result.sum().sort_values(ascending=False).index]\n",
    "#display(result)\n",
    "\n",
    "ax = result.plot(kind='bar', rot=0)\n",
    "ax.get_legend().remove()\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title('Number of papers that provide at least one URL to data per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of papers with data')\n",
    "plt.savefig('Figures/CQ11/number_of_paper_with_data.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "result = pd.concat([result, all_papers_per_year], axis=1)\n",
    "result['normalized'] = (result['url'] / result['number_of_papers_with_dc']).round(2)\n",
    "#display(result)\n",
    "\n",
    "plt.figure()\n",
    "ax = result['normalized'].plot(kind='bar', rot=0)\n",
    "# ax.legend(bbox_to_anchor=(0.8, 0.8))\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title('Normalized number of papers that provide at least one URL to data per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Proportion of papers with data')\n",
    "plt.savefig('Figures/CQ11/proportion_of_paper_with_data.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Interpretation*</ins>\n",
    "Based on the figure [\"Normalized number of papers that provide at least one URL to data per year\"](Figures/CQ11/proportion_of_paper_with_data.png), an increasing proportion of papers that provide at least one URL to data can be observed over time. While before 2010 the average proportion of papers that provide at least one URL to data is 25.4%, the average proportion for the period 2010 - 2019 is 49.8%. For the **target state (2020 - 2025)**, the average proportion of papers that provide at least one URL to data is 71.3%. Based on these data, we observe a positive development towards the vision of [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) that the envisioned increase in **more research studies** providing results, materials, and raw data that enable efficient cumulative research can be achieved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='q12'></a>\n",
    "### 3.12 How has the reporting of research questions and answers evolved over time?\n",
    "\n",
    "#### <ins>*Data Selection*</ins> \n",
    "\n",
    "*Explanation of the Competency Question*:\n",
    "\n",
    "According to [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), the **\"current\" state of practice (2007)** shows that **results are hidden**. For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision that researchers **focus more on communicating important results**, such as the research question and its answer. This predicted change leads to the corresponding competency question.\n",
    "\n",
    "*Required Data for the Analysis*:\n",
    "\n",
    "We must retrieve all papers with their publication year that use our ORKG template and have information about the research questions and answer.\n",
    "\n",
    "[Back to top](#step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Collection*</ins> \n",
    "Below, we retrieve the required data from KG-EmpiRE in the [ORKG](https://www.orkg.org/orkg/) using its [SPARQL endpoint](https://orkg.org/sparql/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '12'\n",
    "\n",
    "query_12 = \"\"\"\n",
    "        SELECT ?paper, ?year, ?question, ?highlighted_q, ?highlighted_a\n",
    "                WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                        orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "\n",
    "                OPTIONAL{?contribution orkgp:P37330 ?rq.\n",
    "                        OPTIONAL{?rq orkgp:P44139 ?question.}\n",
    "                        OPTIONAL{?rq orkgp:P55039 ?highlighted_q.}\n",
    "                }\n",
    "                OPTIONAL{?contribution orkgp:P57004 ?answer.\n",
    "                        OPTIONAL{?answer orkgp:P55039 ?highlighted_a.}\n",
    "                }\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "                }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_12)\n",
    "df_query_12 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Exploration*</ins>\n",
    "Below, we explore the retrieved data, including its cleaning and validation, to prepare the data for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Analysis*</ins>\n",
    "For this data analysis, we consider all papers that report at least one research question (either highlighted or hidden). We also assume that all papers provide an answer (highlighted or hidden) in some way as they are published research paper. A paper can involve more than one research question so that the number of research questions can be larger than the number of papers. We normalize the number of papers with hightlighted/hidden research question(s) and anwers based on the number of all unique papers per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_per_year = df_query_12.drop_duplicates(subset=['paper']).reset_index(drop=True).groupby('year')['paper'].count()\n",
    "#display(papers_per_year)\n",
    "\n",
    "papers_with_rq = df_query_12.dropna()\n",
    "\n",
    "high_q_high_a = pd.DataFrame(papers_with_rq.loc[(papers_with_rq['highlighted_q'] == True) & (papers_with_rq['highlighted_a'] == True)].drop_duplicates(subset=['paper']).reset_index(drop=True).groupby('year')['paper'].count())\n",
    "high_q_high_a.columns = ['number_of_papers']\n",
    "high_q_hid_a = pd.DataFrame(papers_with_rq.loc[(papers_with_rq['highlighted_q'] == True) & (papers_with_rq['highlighted_a'] == False)].drop_duplicates(subset=['paper']).reset_index(drop=True).groupby('year')['paper'].count())\n",
    "high_q_hid_a.columns = ['number_of_papers']\n",
    "hid_q_high_a = pd.DataFrame(papers_with_rq.loc[(papers_with_rq['highlighted_q'] == False) & (papers_with_rq['highlighted_a'] == True)].drop_duplicates(subset=['paper']).reset_index(drop=True).groupby('year')['paper'].count())\n",
    "hid_q_high_a.columns = ['number_of_papers']\n",
    "#display(hid_q_high_a)\n",
    "hid_q_high_a = hid_q_high_a.fillna(0)\n",
    "hid_q_hid_a = pd.DataFrame(papers_with_rq.loc[(papers_with_rq['highlighted_q'] == False) & (papers_with_rq['highlighted_a'] == False)].drop_duplicates(subset=['paper']).reset_index(drop=True).groupby('year')['paper'].count())\n",
    "hid_q_hid_a.columns = ['number_of_papers']\n",
    "\n",
    "figure, axis = plt.subplots(2, 2, figsize=(20, 12), sharey=True)\n",
    "# Plot barplots\n",
    "bar1 = sns.barplot(data = high_q_high_a, x = high_q_high_a.index, y='number_of_papers', ax=axis[0,0], color=sns.color_palette()[0])\n",
    "bar1.bar_label(bar1.containers[0], rotation=45)\n",
    "bar1.tick_params('x', labelrotation=45)\n",
    "bar2 = sns.barplot(data = high_q_hid_a, x = high_q_hid_a.index, y='number_of_papers', ax=axis[0,1], color=sns.color_palette()[1])\n",
    "bar2.bar_label(bar2.containers[0], rotation=45)\n",
    "bar2.tick_params('x', labelrotation=45)\n",
    "bar3 = sns.barplot(data = hid_q_high_a, x = hid_q_high_a.index, y='number_of_papers', ax=axis[1,0], color=sns.color_palette()[2])\n",
    "bar3.bar_label(bar3.containers[0], rotation=45)\n",
    "bar3.tick_params('x', labelrotation=45)\n",
    "bar4 = sns.barplot(data = hid_q_hid_a, x = hid_q_hid_a.index, y='number_of_papers', ax=axis[1,1], color=sns.color_palette()[3])\n",
    "bar4.bar_label(bar4.containers[0], rotation=45)\n",
    "bar4.tick_params('x', labelrotation=45)\n",
    "\n",
    "# Set titles\n",
    "plt.suptitle(\"Number of papers highlighting/hiding research question(s) and answers per year grouped by highlighting/hiding combination\")\n",
    "bar1.set(title = 'Number of papers with highlighted research question(s) and highlighted answers per year', ylabel='Number of papers', xlabel='Year')\n",
    "bar2.set(title = 'Number of papers with highlighted research question(s) and hidden answers per year', ylabel='Number of papers', xlabel='Year')\n",
    "bar3.set(title = 'Number of papers with hidden research question(s) and highlighted answers per year', ylabel='Number of papers', xlabel='Year')\n",
    "bar4.set(title = 'Number of papers with hidden research questions(s) and hidden answers per year', ylabel='Number of papers', xlabel='Year')\n",
    "\n",
    "# Set spacing between subplots\n",
    "figure.tight_layout()\n",
    "plt.savefig('Figures/CQ12/number_of_papers_high_hide_rq_a.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "high_q_high_a['normalized'] = (high_q_high_a['number_of_papers'] / papers_per_year).round(2)\n",
    "high_q_hid_a['normalized'] = (high_q_hid_a['number_of_papers'] / papers_per_year).round(2)\n",
    "hid_q_high_a['normalized'] = (hid_q_high_a['number_of_papers'] / papers_per_year).round(2)\n",
    "hid_q_hid_a['normalized'] = (hid_q_hid_a['number_of_papers'] / papers_per_year).round(2)\n",
    "\n",
    "figure, axis = plt.subplots(2, 2, figsize=(20, 12), sharey=True)\n",
    "# Plot barplots\n",
    "bar1 = sns.barplot(data = high_q_high_a, x = high_q_high_a.index, y='normalized', ax=axis[0,0], color=sns.color_palette()[0])\n",
    "bar1.bar_label(bar1.containers[0], rotation=45)\n",
    "bar1.tick_params('x', labelrotation=45)\n",
    "bar2 = sns.barplot(data = high_q_hid_a, x = high_q_hid_a.index, y='normalized', ax=axis[0,1], color=sns.color_palette()[1])\n",
    "bar2.bar_label(bar2.containers[0], rotation=45)\n",
    "bar2.tick_params('x', labelrotation=45)\n",
    "bar3 = sns.barplot(data = hid_q_high_a, x = hid_q_high_a.index, y='normalized', ax=axis[1,0], color=sns.color_palette()[2])\n",
    "bar3.bar_label(bar3.containers[0], rotation=45)\n",
    "bar3.tick_params('x', labelrotation=45)\n",
    "bar4 = sns.barplot(data = hid_q_hid_a, x = hid_q_hid_a.index, y='normalized', ax=axis[1,1], color=sns.color_palette()[3])\n",
    "bar4.bar_label(bar4.containers[0], rotation=45)\n",
    "bar4.tick_params('x', labelrotation=45)\n",
    "\n",
    "# Set titles\n",
    "plt.suptitle(\"Normalized number of papers highlighting/hiding research question(s) and answers per year grouped by highlighting/hiding combination\")\n",
    "bar1.set(title = 'Proportion of papers with highlighted research question(s) and highlighted answers per year', ylabel='Proportion of papers', xlabel='Year')\n",
    "bar2.set(title = 'Proportion of papers with highlighted research question(s) and hidden answers per year', ylabel='Proportion of papers', xlabel='Year')\n",
    "bar3.set(title = 'Proportion of papers with hidden research question(s) and highlighted answers per year', ylabel='Proportion of papers', xlabel='Year')\n",
    "bar4.set(title = 'Proportion of papers with hidden research questions(s) and hidden answers per year', ylabel='Proportion of papers', xlabel='Year')\n",
    "\n",
    "# Set spacing between subplots\n",
    "figure.tight_layout()\n",
    "plt.savefig('Figures/CQ12/proportion_of_papers_high_hide_rq_a.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis, we consider all papers that do not report any research question. We also assume that even the papers without a research question provide an answer (highlighted or hidden) in some way as they are published research papers. We normalize the number of papers without any research question and highlighted/hidden answers based on the number of all unique papers per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_with_no_rq = df_query_12[df_query_12['question'].isnull()].reset_index(drop=True)\n",
    "no_rq_high_a = pd.DataFrame(papers_with_no_rq.loc[papers_with_no_rq['highlighted_a'] == True].drop_duplicates(subset=['paper']).reset_index(drop=True).groupby('year')['paper'].count())\n",
    "no_rq_high_a.columns = ['number_of_papers']\n",
    "no_rq_hid_a = pd.DataFrame(papers_with_no_rq.loc[(papers_with_no_rq['highlighted_a'] == False)].drop_duplicates(subset=['paper']).reset_index(drop=True).groupby('year')['paper'].count())\n",
    "no_rq_hid_a.columns = ['number_of_papers']\n",
    "#display(no_rq_high_a)\n",
    "#display(no_rq_hid_a)\n",
    "\n",
    "no_rq_high_a['normalized'] = (no_rq_high_a['number_of_papers'] / papers_per_year).round(2)\n",
    "no_rq_hid_a['normalized'] = (no_rq_hid_a['number_of_papers'] / papers_per_year).round(2)\n",
    "\n",
    "no_rq_high_a = no_rq_high_a.fillna(0)\n",
    "\n",
    "# Plot barplots\n",
    "figure, axis = plt.subplots(1, 2, figsize=(20, 7), sharey=True)\n",
    "bar1 = sns.barplot(data = no_rq_high_a, x = no_rq_high_a.index, y='number_of_papers', ax=axis[0], color=sns.color_palette()[0])\n",
    "bar1.bar_label(bar1.containers[0], rotation=45)\n",
    "bar1.tick_params('x', labelrotation=45)\n",
    "\n",
    "bar2 = sns.barplot(data = no_rq_hid_a, x = no_rq_hid_a.index, y='number_of_papers', ax=axis[1], color=sns.color_palette()[1])\n",
    "bar2.bar_label(bar2.containers[0], rotation=45)\n",
    "bar2.tick_params('x', labelrotation=45)\n",
    "\n",
    "# Set titles\n",
    "plt.suptitle(\"Number of papers without research question(s) and highlighted/hidden answers per year grouped by highlighed/hidden answer\")\n",
    "bar1.set(title = 'Number of papers without research question and highlighted answers per year', ylabel='Number of papers', xlabel='Year')\n",
    "bar2.set(title = 'Number of papers without research question and hidden answers per year', ylabel='Number of papers', xlabel='Year')\n",
    "\n",
    "# Set spacing between subplots\n",
    "figure.tight_layout()\n",
    "plt.savefig('Figures/CQ12/number_of_papers_without_rq_but_a.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "figure, axis = plt.subplots(1, 2, figsize=(20, 7), sharey=True)\n",
    "# Plot barplots\n",
    "bar1 = sns.barplot(data = no_rq_high_a, x = no_rq_high_a.index, y='normalized', ax=axis[0], color=sns.color_palette()[0])\n",
    "bar1.bar_label(bar1.containers[0], rotation=45)\n",
    "bar1.tick_params('x', labelrotation=45)\n",
    "bar2 = sns.barplot(data = no_rq_hid_a, x = no_rq_hid_a.index, y='normalized', ax=axis[1], color=sns.color_palette()[1])\n",
    "bar2.bar_label(bar2.containers[0], rotation=45)\n",
    "bar2.tick_params('x', labelrotation=45)\n",
    "\n",
    "# Set titles\n",
    "plt.suptitle(\"Normlaized number of papers without research question(s) and highlighted/hidden answers per year grouped by highlighed/hidden answer\")\n",
    "bar1.set(title = 'Proportion of papers without research question and highlighted answers per year', ylabel='Proportion of papers', xlabel='Year')\n",
    "bar2.set(title = 'Proportion of papers without research question and hidden answers per year', ylabel='Proportion of papers', xlabel='Year')\n",
    "\n",
    "# Set spacing between subplots\n",
    "figure.tight_layout()\n",
    "plt.savefig('Figures/CQ12/proportion_of_papers_without_rq_but_a.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Interpretation*</ins>\n",
    "In the figure [\"Normalized number of papers highlighting/hiding research question(s) and answers per year grouped by highlighting/hiding combination\"](Figures/CQ12/proportion_of_papers_high_hide_rq_a.png), we see the development trend for all four combinations of highlighted/hidden research question(s) and answers pairs:\n",
    "\n",
    "1) The proportion of papers with highlighted research question(s) and highlighted answers is overall rather low with an average proportion of only 7.7%. For 2022, however, we observe a fivefold increase in the proportion of papers highlighting their research question(s) and answers. Although, the overall average proportion is low, the development is positive as researchers focus more on communicating (highlighting) their results.\n",
    "2) The proportion of papers with highlighted research question(s) and answers hidden in the running text is overall high with an average proportion of 25.7%. We observe a constant increase of this proportion of papers over the years with its current maximum of 61% in 2021, which can be partly interpreted positively. While researchers highlight their research question(s) as one important element of their paper, they hide the associated answer in the running text. As a consequence, the reader has to find the answer to the research question in the paper himself, which makes it difficult to get a quick and easy overview of the paper with its central results.\n",
    "3) The proportion of papers with research question(s) hidden in the running text and highlighted answers is very low with only 4% in 2011 analyzed which corresponds to one paper. Based on our manual curation, we can report that this paper is a special case, as the authors failed to formulate their research questions as questions and instead offer only a bullet point list of aspects to be investigated.\n",
    "4) The proportion of papers with research question(s) and answers hidden in the running text is overall low with an average proportion of 10%. While the proportion increases slightly until 2018, we observe that from 2019 to 2022 the proportion is at a maximum of 6%. In particular, for the **target state (2020 - 2025)**, the average percentage is only 5%, which means that a small number of papers hide their research question(s) and answers in the running text and thus, conversely, more researchers make an effort to visibly communicate their important findings.\n",
    "\n",
    "In the figure [\"Normlaized number of papers without research question(s) and highlighted/hidden answers per year grouped by highlighed/hidden answer\"](Figures/CQ12/proportion_of_papers_without_rq_but_a.png), we see the development trend of papers without a research question and highlighted or hidden answers:\n",
    "\n",
    "1) The proportion of papers without a research question and a highlighted answer is always 0% which means that researchers who do not pose a research question also do not highlight any results as an answer to the problem under study.\n",
    "2) The proportion of papers without a research question and a hidden answer is decreasing over the years but has an average proportion of 56.4%. However, from 2018 until 2022 the proportion is again decreasing with its current smallest value of 12% in 2022.\n",
    "\n",
    "Based on these results, we observe a positive development towards the vision of [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) as researchers focus more on communicating (highlighting) the important results of their research, as envisioned."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='q13'></a>\n",
    "### 3.13 What empirical methods are used to conduct integrative and interpretive (systematic literature) reviews, so-called secondary research?\n",
    "\n",
    "#### <ins>*Data Selection*</ins> \n",
    "\n",
    "*Explanation of the Competency Question*:\n",
    "\n",
    "According to [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), the **\"current\" state of practice (2007)** shows (literature) **reviews**, so-called secondary research, are mainly **narrative and biased**, and researchers have **little appreciation of the value of systematic (literature) reviews**. For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision that **scientific methods are used to undertake integrative and interpretive (literature) reviews**. This predicted change leads to the corresponding competency question.\n",
    "\n",
    "*Required Data for the Analysis*:\n",
    "\n",
    "We must retrieve all papers that use our ORKG template and secondardy research as the empirical method for data collection.\n",
    "\n",
    "[Back to top](#step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Collection*</ins> \n",
    "Below, we retrieve the required data from KG-EmpiRE in the [ORKG](https://www.orkg.org/orkg/) using its [SPARQL endpoint](https://orkg.org/sparql/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '13'\n",
    "\n",
    "query_13 = \"\"\"\n",
    "        SELECT ?paper, ?dc_label, ?method_label\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                       orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "\n",
    "                ?contribution orkgp:P56008 ?data_collection.\n",
    "                ?data_collection rdfs:label ?dc_label;\n",
    "                                orkgp:P57021 ?method.\n",
    "                ?method rdfs:label ?method_label.\n",
    "                \n",
    "                FILTER(?dc_label = \"secondary research\"^^xsd:string)\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_13)\n",
    "df_query_13 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Exploration*</ins>\n",
    "Below, we explore the retrieved data, including its cleaning and validation, to prepare the data for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_13['dc_label'] = df_query_13['dc_label'].astype('category')\n",
    "df_query_13['method_label'] = df_query_13['method_label'].astype('category')\n",
    "display(df_query_13['dc_label'].value_counts())\n",
    "display(df_query_13['method_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Analysis*</ins>\n",
    "For this data analysis, we consider all papers that that use our ORKG template and secondardy research as the empirical method for data collection. From these papers, we extract the empirical methods used for secondary research. We normalize the number of papers using empirical mehtods for secondary research based on the number of all papers that use secondary research for data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df_query_13['method_label'].value_counts().rename_axis('method_label').to_frame('counts')\n",
    "result.index = result.index.map(str.capitalize)\n",
    "#display(result)\n",
    "\n",
    "ax = result.plot(kind='barh', rot=0)\n",
    "ax.invert_yaxis()\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.get_legend().remove()\n",
    "plt.title('Number of empirical methods used for secondary research')\n",
    "plt.xlabel('Number of empirical method used')\n",
    "plt.ylabel('Empirical method used')\n",
    "plt.savefig('Figures/CQ13/number_of_empirical_methods_used_for_secondary_research.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "number_of_all_papers = result['counts'].sum()\n",
    "result['normalized'] = (result['counts'] / number_of_all_papers).round(2)\n",
    "#display(result)\n",
    "\n",
    "plt.figure()\n",
    "ax = result.loc[:, 'normalized'].plot(kind='barh', rot=0)\n",
    "ax.invert_yaxis()\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title('Normalized number of empirical methods used for secondary research')\n",
    "plt.xlabel('Proportion of empirical method used')\n",
    "plt.ylabel('Empirical method used')\n",
    "plt.savefig('Figures/CQ13/proportion_of_empirical_methods_used_for_secondary_research.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Interpretation*</ins>\n",
    "Based on the figure [\"Normalized number of empirical methods used for secondary research\"](Figures/CQ13/proportion_of_empirical_methods_used_for_secondary_research.png), we observe that mainly three empirical methods are used for secondary reserach. These three methods are *archive analysis* (59% proportion), *literature review* (14% proportion), and *sytematic literature reviews* (14% proportion). In addition, we found seven others methods based on the extracted names whose proportion is below 3%. *Archive analysis* is the most frequently used method for secondary reserach. This method included all types of analyses based on archived data, such as data from issue trackers, app stores, forums, or Twitter. The next two most commonly used methods are literature review and systematic literature reviews, which are probably the best known methods of secondary research.\n",
    "\n",
    "Overall, the results show researchers use a **larger set of research methods and techniques**. In particular, there are essentially six different methods used for data collection and three different methods used for data analysis. However, the proportion of *action research* for data collection and especially *inferential statistics* for data analysis is very low."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='q14'></a>\n",
    "### 3.14 How has the proportions of empirical methods to conduct (systematic literature) reviews, so-called secondary research, evolved over time?\n",
    "\n",
    "#### <ins>*Data Selection*</ins> \n",
    "\n",
    "*Explanation of the Competency Question*:\n",
    "\n",
    "According to [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), the **\"current\" state of practice (2007)** shows (literature) **reviews**, so-called secondary research, are mainly **narrative and biased**, and researchers have **little appreciation of the value of systematic (literature) reviews**. For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision that **scientific methods are used to undertake integrative and interpretive (literature) reviews**. This predicted change leads to the corresponding competency question.\n",
    "\n",
    "*Required Data for the Analysis*:\n",
    "\n",
    "We must retrieve all papers with their publication year that use our ORKG template and secondardy research as the empirical method for data collection.\n",
    "\n",
    "[Back to top](#step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Collection*</ins> \n",
    "Below, we retrieve the required data from KG-EmpiRE in the [ORKG](https://www.orkg.org/orkg/) using its [SPARQL endpoint](https://orkg.org/sparql/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '14'\n",
    "\n",
    "query_14 = \"\"\"\n",
    "        SELECT ?paper, ?year, ?dc_label, ?method_label\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                        orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "\n",
    "                ?contribution orkgp:P56008 ?data_collection.\n",
    "                ?data_collection rdfs:label ?dc_label;\n",
    "                                orkgp:P57021 ?method.\n",
    "                ?method rdfs:label ?method_label.\n",
    "                \n",
    "                FILTER(?dc_label = \"secondary research\"^^xsd:string)\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_14)\n",
    "df_query_14 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Exploration*</ins>\n",
    "Below, we explore the retrieved data, including its cleaning and validation, to prepare the data for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_14['dc_label'] = df_query_14['dc_label'].astype('category')\n",
    "df_query_14['method_label'] = df_query_14['method_label'].astype('category')\n",
    "display(df_query_14['dc_label'].value_counts())\n",
    "display(df_query_14['method_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Analysis*</ins>\n",
    "For this data analysis, we consider all papers that that use our ORKG template and secondardy research as the empirical method for data collection. From these papers, we extract the empirical methods used for secondary research. We normalize the number of papers using empirical mehtods for secondary research based on the number of all papers that use secondary research for data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers_per_year = pd.DataFrame(df_query_14.drop_duplicates(subset=['paper']).reset_index(drop=True)['year'].value_counts())\n",
    "all_papers_per_year.columns = ['number_of_papers']\n",
    "all_papers_per_year = all_papers_per_year.sort_index()\n",
    "\n",
    "result = pd.DataFrame(df_query_14.groupby('year')['method_label'].value_counts().unstack())\n",
    "result = result[result.sum().sort_values(ascending=False).index]\n",
    "#display(result)\n",
    "\n",
    "result = pd.concat([result, all_papers_per_year], axis=1)\n",
    "result['normalized archive analysis'] = (result['archive analysis'] / result['number_of_papers']).round(2)\n",
    "result['normalized systematic literature review'] = (result['systematic literature review'] / result['number_of_papers']).round(2)\n",
    "result['normalized literature review'] = (result['literature review'] / result['number_of_papers']).round(2)\n",
    "result['normalized systematic review'] = (result['systematic review'] / result['number_of_papers']).round(2)\n",
    "result['normalized systematic literature map'] = (result['systematic literature map'] / result['number_of_papers']).round(2)\n",
    "result['normalized tertiary literature review'] = (result['tertiary literature review'] / result['number_of_papers']).round(2)\n",
    "result['normalized document analysis'] = (result['document analysis'] / result['number_of_papers']).round(2)\n",
    "result['normalized document inspection'] = (result['document inspection'] / result['number_of_papers']).round(2)\n",
    "result['normalized literature study'] = (result['literature study'] / result['number_of_papers']).round(2)\n",
    "result['normalized literature survey'] = (result['literature survey'] / result['number_of_papers']).round(2)\n",
    "#display(result)\n",
    "\n",
    "ax = result.loc[:, 'normalized archive analysis':'normalized literature survey'].plot(kind='bar', rot=0)\n",
    "ax.legend(bbox_to_anchor=(1.0, 0.8), labels=['Archive analysis', 'Systematic literature review', 'Literature review', 'Systematic literature map', 'Systematic review', 'Tertiary literature review', 'Document analysis', 'Document inspection', 'Literature study', 'Literature survey'])\n",
    "# #make_axes_area_auto_adjustable(ax)\n",
    "plt.title('Normalized number of empirical methods used for secondary research per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Proportion of empirical method used')\n",
    "plt.savefig('Figures/CQ14/proportion_of_empirical_methods_used_for_secondaty_research.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "figure, axis = plt.subplots(5, 2, figsize=(22, 25), sharey=True)\n",
    "# Plot barplots\n",
    "bar1 = sns.barplot(data = result, x = result.index, y='normalized archive analysis', ax=axis[0,0], color=sns.color_palette()[0])\n",
    "bar1.bar_label(bar1.containers[0])\n",
    "bar1.tick_params('x', labelrotation=45)\n",
    "bar2 = sns.barplot(data = result, x = result.index, y='normalized systematic literature review', ax=axis[0,1], color=sns.color_palette()[1])\n",
    "bar2.bar_label(bar2.containers[0])\n",
    "bar2.tick_params('x', labelrotation=45)\n",
    "bar3 = sns.barplot(data = result, x = result.index, y='normalized literature review', ax=axis[1,0], color=sns.color_palette()[2])\n",
    "bar3.bar_label(bar3.containers[0])\n",
    "bar3.tick_params('x', labelrotation=45)\n",
    "bar4 = sns.barplot(data = result, x = result.index, y='normalized systematic literature map', ax=axis[1,1], color=sns.color_palette()[4])\n",
    "bar4.bar_label(bar4.containers[0])\n",
    "bar4.tick_params('x', labelrotation=45)\n",
    "bar5 = sns.barplot(data = result, x = result.index, y='normalized systematic review', ax=axis[2,0], color=sns.color_palette()[5])\n",
    "bar5.bar_label(bar5.containers[0])\n",
    "bar5.tick_params('x', labelrotation=45)\n",
    "bar6 = sns.barplot(data = result, x = result.index, y='normalized tertiary literature review', ax=axis[2,1], color=sns.color_palette()[6])\n",
    "bar6.bar_label(bar6.containers[0])\n",
    "bar6.tick_params('x', labelrotation=45)\n",
    "bar7 = sns.barplot(data = result, x = result.index, y='normalized document analysis', ax=axis[3,0], color=sns.color_palette()[7])\n",
    "bar7.bar_label(bar7.containers[0])\n",
    "bar7.tick_params('x', labelrotation=45)\n",
    "bar8 = sns.barplot(data = result, x = result.index, y='normalized document inspection', ax=axis[3,1], color=sns.color_palette()[8])\n",
    "bar8.bar_label(bar8.containers[0])\n",
    "bar8.tick_params('x', labelrotation=45)\n",
    "bar9 = sns.barplot(data = result, x = result.index, y='normalized literature study', ax=axis[4,0], color=sns.color_palette()[9])\n",
    "bar9.bar_label(bar9.containers[0])\n",
    "bar9.tick_params('x', labelrotation=45)\n",
    "bar10 = sns.barplot(data = result, x = result.index, y='normalized literature survey', ax=axis[4,1], color=sns.color_palette()[0])\n",
    "bar10.bar_label(bar10.containers[0])\n",
    "bar10.tick_params('x', labelrotation=45)\n",
    "\n",
    "# # Set titles\n",
    "plt.suptitle(\"Normalized number of empirical methods used for secondary research per year grouped by empirical method\")\n",
    "bar1.set(title = 'Normalized number of archive analysis used for secondary research per year', ylabel='Proportion of archive analysis', xlabel='Year')\n",
    "bar2.set(title = 'Normalized number of systematic literature review used for secondary research per year', ylabel='Proportion of systematic literature review', xlabel='Year')\n",
    "bar3.set(title = 'Normalized number of literature review used for secondary research per year', ylabel='Proportion of literature review', xlabel='Year')\n",
    "bar4.set(title = 'Normalized number of systematic literature map used for secondary research per year', ylabel='Proportion of systematic literature map', xlabel='Year')\n",
    "bar5.set(title = 'Normalized number of systematic review used for secondary research per year', ylabel='Proportion of systematic review', xlabel='Year')\n",
    "bar6.set(title = 'Normalized number of tertiary literature review used for secondary research per year', ylabel='Proportion of tertiary literature review', xlabel='Year')\n",
    "bar7.set(title = 'Normalized number of document analysis used for secondary research per year', ylabel='Proportion of document analysis', xlabel='Year')\n",
    "bar8.set(title = 'Normalized number of document inspection used for secondary research per year', ylabel='Proportion of document inspection', xlabel='Year')\n",
    "bar9.set(title = 'Normalized number of literature study used for secondary research per year', ylabel='Proportion of literature study', xlabel='Year')\n",
    "bar10.set(title = 'Normalized number of literature survey used for secondary research per year', ylabel='Proportion of literature survey', xlabel='Year')\n",
    "\n",
    "# # Set spacing between subplots\n",
    "figure.tight_layout()\n",
    "plt.savefig('Figures/CQ14/proportion_of_empirical_methods_used_for_secondary_research_grouped_by_method.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Interpretation*</ins>\n",
    "Based on the figure [\"Normalized number of empirical methods used for secondary research per year grouped by method\"](Figures/CQ14/proportion_of_empirical_methods_used_for_secondary_research_grouped_by_method.png), we observe that mainly three empirical methods are used for secondary reserach. These three methods are *archive analysis* (59% proportion), *literature review* (14% proportion), and *sytematic literature reviews* (14% proportion). In addition, we found seven others methods based on the extracted names whose proportion is below 3%. In addition to the frequent use of *archive analysis* over the years, it can be observed that from 2008 onwards researchers perform literature reviews and systematic literature reviews with increasing frequency. In particular, for the **target state (2020 - 2025)**, the average proportion of papers with systematic literature reviews is 45.5%.\n",
    "\n",
    "According to [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), the **\"current\" state of practice (2007)** shows (literature) **reviews**, so-called secondary research, are mainly **narrative and biased**, and researchers have **little appreciation of the value of systematic (literature) reviews**. For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision that **scientific methods are used to undertake integrative and interpretive (literature) reviews**. This predicted change leads to the corresponding competency question.\n",
    "\n",
    "Based on these results, we observe a positive development towards the vision of [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) that a greater appreciation of the value of systematic (literature) reviews as envisioned for the **target state (2020 - 2025)** can be achieved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='q15'></a>\n",
    "### 3.15 How many different research methods are used per publication?\n",
    "\n",
    "#### <ins>*Data Selection*</ins> \n",
    "\n",
    "*Explanation of the Competency Question*:\n",
    "\n",
    "According to [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), the **\"current\" state of practice (2007)** shows that there is **limited** advice on how to **combine data from diverse study types**. For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision that **methods are available** for synthesizing evidence from **variety of perspectives and approaches**. This predicted change leads to the corresponding competency question.\n",
    "\n",
    "*Required Data for the Analysis*:\n",
    "\n",
    "We must retrieve all papers that use our ORKG template and report on the use of empirical methods. According to [Dan (2017)](https://doi.org/10.1002/9781118901731.iecrm0083), empirical methods include data collection and data analysis. An empirical method can therefore be a method for data collection and data analysis. For this reason, we identify number of empirical methods used for data collection and data analysis respectively. Based on the individual paper, we can determine the sum of all empirical methods per publication.\n",
    "\n",
    "[Back to top](#step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Collection*</ins> \n",
    "Below, we retrieve the required data from KG-EmpiRE in the [ORKG](https://www.orkg.org/orkg/) using its [SPARQL endpoint](https://orkg.org/sparql/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '15.1'\n",
    "\n",
    "query_15_1 = \"\"\"\n",
    "        SELECT ?paper, (COUNT(?dc_label) AS ?number_of_dc_methods), ?year\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                        orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "\n",
    "                ?contribution orkgp:P56008 ?data_collection.\n",
    "                ?data_collection rdfs:label ?dc_label.\n",
    "                \n",
    "                FILTER((?dc_label != \"no collection\"^^xsd:string))\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        } GROUP BY ?paper ?year\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_15_1)\n",
    "df_query_15_1 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')\n",
    "\n",
    "ID = '15.2'\n",
    "query_15_2 = \"\"\"\n",
    "        SELECT ?paper, (COUNT(DISTINCT ?inferential) AS ?number_of_inf_methods), (COUNT(DISTINCT ?descriptive) AS ?number_of_des_methods), (COUNT(DISTINCT ?machine_learning) AS ?number_of_ml_methods), (COUNT(DISTINCT ?other_methods) AS ?number_of_other_methods), ?year\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                        orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "\n",
    "                ?contribution orkgp:P15124 ?data_analysis.\n",
    "                ?data_analysis rdfs:label ?da_label.\n",
    "                \n",
    "                OPTIONAL{?data_analysis orkgp:P56043 ?inferential.}\n",
    "                OPTIONAL{?data_analysis orkgp:P56048 ?descriptive.}\n",
    "                OPTIONAL{?data_analysis orkgp:P57016 ?machine_learning.}\n",
    "                OPTIONAL{?data_analysis orkgp:P76003 ?other_methods.}\n",
    "                \n",
    "                FILTER(?da_label != \"no analysis\"^^xsd:string)\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        } GROUP BY ?paper ?year\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_15_2)\n",
    "df_query_15_2 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Exploration*</ins>\n",
    "Below, we explore the retrieved data, including its cleaning and validation, to prepare the data for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_15_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_15_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Analysis*</ins>\n",
    "For this data analysis, we consider all papers that that use our ORKG template and secondardy research as the empirical method for data collection. From these papers, we extract the empirical methods used for secondary research. We normalize the number of papers using empirical mehtods for secondary research based on the number of all papers that use secondary research for data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(df_query_15_1, df_query_15_2, on=['paper', 'year'], how='outer').fillna(0)\n",
    "result['number_of_all_methods'] = result['number_of_dc_methods'] + result.loc[:,'number_of_inf_methods':'number_of_other_methods'].sum(axis=1)\n",
    "#display(result)\n",
    "\n",
    "number_of_papers_with_x_methods = pd.DataFrame(result.groupby('number_of_all_methods')['paper'].count())\n",
    "number_of_papers_with_x_methods['normalized'] = (number_of_papers_with_x_methods['paper'] / number_of_papers_with_x_methods['paper'].sum()).round(3)\n",
    "#display(number_of_papers_with_x_methods)\n",
    "\n",
    "plt.figure()\n",
    "ax = number_of_papers_with_x_methods['paper'].plot(kind='bar', rot=0)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title('Number of papers using X empirical methods for data collection and data analysis')\n",
    "plt.xlabel('Number of empirical methods used')\n",
    "plt.ylabel('Number of papers using X empirical method')\n",
    "plt.savefig('Figures/CQ15/number_of_papers_using_x_empirical_methods.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "ax = number_of_papers_with_x_methods['normalized'].plot(kind='bar', rot=0)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title('Normalized number of papers using X empirical methods for data collection and data analysis')\n",
    "plt.xlabel('Number of empirical methods used')\n",
    "plt.ylabel('Proportion of papers using X empirical method')\n",
    "plt.savefig('Figures/CQ15/proportion_of_papers_using_x_empirical_methods.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Interpretation*</ins>\n",
    "Based on the figure [\"Normalized number of papers using X empirical methods for data collection and data analysis\"](Figures/CQ15/proportion_of_papers_using_x_empirical_methods.png), we observe that papers use one to twelve empirical methods for data collection and analysis. Most papers use three (31.3% proportion) to four (21.6% proportion) empiricial methods. The use of three or more methods in one papers requires the need for methods to synthesize evidence from **variety of perspectives and approaches** as envisioned by [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30). Based on our data, we cannot say whether such methods for synthesizing evidence are already available for the **target state (2020 - 2025)** as envisioned. However, our results imply, based on the increased number of methods used per paper, that there is such a need for methods to synthesize evidence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='q16'></a>\n",
    "### 3.16 How has the number of research methods used per publication evolved over time?\n",
    "\n",
    "#### <ins>*Data Selection*</ins> \n",
    "\n",
    "*Explanation of the Competency Question*:\n",
    "\n",
    "According to [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30), the **\"current\" state of practice (2007)** shows that there is **limited** advice on how to **combine data from diverse study types**. For the **target state (2020 - 2025)**, [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30) envision that **methods are available** for synthesizing evidence from **variety of perspectives and approaches**. This predicted change leads to the corresponding competency question.\n",
    "\n",
    "*Required Data for the Analysis*:\n",
    "\n",
    "We must retrieve all papers that use our ORKG template and report on the use of empirical methods. According to [Dan (2017)](https://doi.org/10.1002/9781118901731.iecrm0083), empirical methods include data collection and data analysis. An empirical method can therefore be a method for data collection and data analysis. For this reason, we identify number of empirical methods used for data collection and data analysis respectively. Based on the individual paper, we can determine the sum of all empirical methods per publication.\n",
    "\n",
    "[Back to top](#step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Collection*</ins> \n",
    "Below, we retrieve the required data from KG-EmpiRE in the [ORKG](https://www.orkg.org/orkg/) using its [SPARQL endpoint](https://orkg.org/sparql/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '16.1'\n",
    "\n",
    "query_16_1 = \"\"\"\n",
    "        SELECT ?paper, (COUNT(?dc_label) AS ?number_of_dc_methods), ?year\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                        orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "\n",
    "                ?contribution orkgp:P56008 ?data_collection.\n",
    "                ?data_collection rdfs:label ?dc_label.\n",
    "                \n",
    "                FILTER((?dc_label != \"no collection\"^^xsd:string))\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        } GROUP BY ?paper ?year\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_16_1)\n",
    "df_query_16_1 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')\n",
    "\n",
    "ID = '16.2'\n",
    "query_16_2 = \"\"\"\n",
    "        SELECT ?paper, (COUNT(DISTINCT ?inferential) AS ?number_of_inf_methods), (COUNT(DISTINCT ?descriptive) AS ?number_of_des_methods), (COUNT(DISTINCT ?machine_learning) AS ?number_of_ml_methods), (COUNT(DISTINCT ?other_methods) AS ?number_of_other_methods), ?year\n",
    "        WHERE {\n",
    "                ?paper orkgp:P31 ?contribution;\n",
    "                        orkgp:P29 ?year.\n",
    "                ?contribution a orkgc:C27001.\n",
    "\n",
    "                ?contribution orkgp:P15124 ?data_analysis.\n",
    "                ?data_analysis rdfs:label ?da_label.\n",
    "                \n",
    "                OPTIONAL{?data_analysis orkgp:P56043 ?inferential.}\n",
    "                OPTIONAL{?data_analysis orkgp:P56048 ?descriptive.}\n",
    "                OPTIONAL{?data_analysis orkgp:P57016 ?machine_learning.}\n",
    "                OPTIONAL{?data_analysis orkgp:P76003 ?other_methods.}\n",
    "                \n",
    "                FILTER(?da_label != \"no analysis\"^^xsd:string)\n",
    "                #FILTER(xsd:integer(?year) > \"2005\"^^xsd:integer)\n",
    "        } GROUP BY ?paper ?year\n",
    "        \"\"\"\n",
    "\n",
    "retrieve_data(ID, query_16_2)\n",
    "df_query_16_2 = pd.read_csv('SPARQL-Data/query_'+ ID + '_data_' + DATE + '.csv', encoding='utf-8', encoding_errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Exploration*</ins>\n",
    "Below, we explore the retrieved data, including its cleaning and validation, to prepare the data for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_16_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(df_query_16_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Analysis*</ins>\n",
    "For this data analysis, we consider all papers that that use our ORKG template and secondardy research as the empirical method for data collection. From these papers, we extract the empirical methods used for secondary research. We normalize the number of papers using empirical mehtods for secondary research based on the number of all papers that use secondary research for data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(df_query_16_1, df_query_16_2, on=['paper', 'year'], how='outer').fillna(0)\n",
    "result['number_of_all_methods'] = result['number_of_dc_methods'] + result.loc[:,'number_of_inf_methods':'number_of_other_methods'].sum(axis=1)\n",
    "papers_per_year = result.groupby(['year', 'number_of_all_methods'])['paper'].count()\n",
    "#display(papers_per_year)\n",
    "\n",
    "data = papers_per_year.unstack(level=1, fill_value=0)\n",
    "#display(data)\n",
    "\n",
    "ax = data.plot(kind='bar', subplots=True, rot=0, figsize=(18, 15), layout=(6, 2),  sharey=True, sharex=False, xlabel='Year', ylabel='Number of papers', legend=None, title='Number of papers using X empirical methods for data collection and data analysis per year grouped by number of empirical methods')\n",
    "ax[0,0].set_title('Number of papers using 1 empricial methods per year')\n",
    "ax[0,0].bar_label(ax[0,0].containers[0], rotation=45)\n",
    "ax[0,0].tick_params('x', labelrotation=45)\n",
    "ax[0,1].set_title('Number of papers using 2 empricial method per year')\n",
    "ax[0,1].bar_label(ax[0,1].containers[0], rotation=45)\n",
    "ax[0,1].tick_params('x', labelrotation=45)\n",
    "ax[1,0].set_title('Number of papers using 3 empricial methods per year')\n",
    "ax[1,0].bar_label(ax[1,0].containers[0], rotation=45)\n",
    "ax[1,0].tick_params('x', labelrotation=45)\n",
    "ax[1,1].set_title('Number of papers using 4 empricial methods per year')\n",
    "ax[1,1].bar_label(ax[1,1].containers[0], rotation=45)\n",
    "ax[1,1].tick_params('x', labelrotation=45)\n",
    "ax[2,0].set_title('Number of papers using 5 empricial methods per year')\n",
    "ax[2,0].bar_label(ax[2,0].containers[0], rotation=45)\n",
    "ax[2,0].tick_params('x', labelrotation=45)\n",
    "ax[2,1].set_title('Number of papers using 6 empricial methods per year')\n",
    "ax[2,1].bar_label(ax[2,1].containers[0], rotation=45)\n",
    "ax[2,1].tick_params('x', labelrotation=45)\n",
    "ax[3,0].set_title('Number of papers using 7 empricial methods per year')\n",
    "ax[3,0].bar_label(ax[3,0].containers[0], rotation=45)\n",
    "ax[3,0].tick_params('x', labelrotation=45)\n",
    "ax[3,1].set_title('Number of papers using 8 empricial methods per year')\n",
    "ax[3,1].bar_label(ax[3,1].containers[0], rotation=45)\n",
    "ax[3,1].tick_params('x', labelrotation=45)\n",
    "ax[4,0].set_title('Number of papers using 9 empricial methods per year')\n",
    "ax[4,0].bar_label(ax[4,0].containers[0], rotation=45)\n",
    "ax[4,0].tick_params('x', labelrotation=45)\n",
    "ax[4,1].set_title('Number of papers using 10 empricial methods per year')\n",
    "ax[4,1].bar_label(ax[4,1].containers[0], rotation=45)\n",
    "ax[4,1].tick_params('x', labelrotation=45)\n",
    "ax[5,0].set_title('Number of papers using 12 empricial methods per year')\n",
    "ax[5,0].bar_label(ax[5,0].containers[0], rotation=45)\n",
    "ax[5,0].tick_params('x', labelrotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figures/CQ16/number_of_papers_using_x_empirical_methods_per_year.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "number_of_papers_with_x_methods = pd.DataFrame(result.groupby(['year'])['paper'].count())\n",
    "data['normalized 1.0'] = (data.iloc[:,0] / number_of_papers_with_x_methods.iloc[:,0]).round(2)\n",
    "data['normalized 2.0'] = (data.iloc[:,1] / number_of_papers_with_x_methods.iloc[:,0]).round(2)\n",
    "data['normalized 3.0'] = (data.iloc[:,2] / number_of_papers_with_x_methods.iloc[:,0]).round(2)\n",
    "data['normalized 4.0'] = (data.iloc[:,3] / number_of_papers_with_x_methods.iloc[:,0]).round(2)\n",
    "data['normalized 5.0'] = (data.iloc[:,4] / number_of_papers_with_x_methods.iloc[:,0]).round(2)\n",
    "data['normalized 6.0'] = (data.iloc[:,5] / number_of_papers_with_x_methods.iloc[:,0]).round(2)\n",
    "data['normalized 7.0'] = (data.iloc[:,6] / number_of_papers_with_x_methods.iloc[:,0]).round(2)\n",
    "data['normalized 8.0'] = (data.iloc[:,7] / number_of_papers_with_x_methods.iloc[:,0]).round(2)\n",
    "data['normalized 9.0'] = (data.iloc[:,8] / number_of_papers_with_x_methods.iloc[:,0]).round(2)\n",
    "data['normalized 10.0'] = (data.iloc[:,9] / number_of_papers_with_x_methods.iloc[:,0]).round(2)\n",
    "data['normalized 12.0'] = (data.iloc[:,10] / number_of_papers_with_x_methods.iloc[:,0]).round(2)\n",
    "\n",
    "#display(data.iloc[:,11:22])\n",
    "\n",
    "ax = data.iloc[:,11:22].plot(kind='bar', subplots=True, rot=0, figsize=(18, 15), layout=(6, 2), sharey=True, sharex=False, xlabel='Year', ylabel='Proportion of papers', legend=None, title='Normalized number of papers using X empirical methods for data collection and data analysis per year grouped by number of empirical methods')\n",
    "ax[0,0].set_title('Normalized number of papers using 1 empricial methods per year')\n",
    "ax[0,0].bar_label(ax[0,0].containers[0], rotation=45)\n",
    "ax[0,0].tick_params('x', labelrotation=45)\n",
    "ax[0,1].set_title('Normalized number of papers using 2 empricial method per year')\n",
    "ax[0,1].bar_label(ax[0,1].containers[0], rotation=45)\n",
    "ax[0,1].tick_params('x', labelrotation=45)\n",
    "ax[1,0].set_title('Normalized number of papers using 3 empricial methods per year')\n",
    "ax[1,0].bar_label(ax[1,0].containers[0], rotation=45)\n",
    "ax[1,0].tick_params('x', labelrotation=45)\n",
    "ax[1,1].set_title('Normalized number of papers using 4 empricial methods per year')\n",
    "ax[1,1].bar_label(ax[1,1].containers[0], rotation=45)\n",
    "ax[1,1].tick_params('x', labelrotation=45)\n",
    "ax[2,0].set_title('Normalized number of papers using 5 empricial methods per year')\n",
    "ax[2,0].bar_label(ax[2,0].containers[0], rotation=45)\n",
    "ax[2,0].tick_params('x', labelrotation=45)\n",
    "ax[2,1].set_title('Normalized number of papers using 6 empricial methods per year')\n",
    "ax[2,1].bar_label(ax[2,1].containers[0], rotation=45)\n",
    "ax[2,1].tick_params('x', labelrotation=45)\n",
    "ax[3,0].set_title('Normalized number of papers using 7 empricial methods per year')\n",
    "ax[3,0].bar_label(ax[3,0].containers[0], rotation=45)\n",
    "ax[3,0].tick_params('x', labelrotation=45)\n",
    "ax[3,1].set_title('Normalized number of papers using 8 empricial methods per year')\n",
    "ax[3,1].bar_label(ax[3,1].containers[0], rotation=45)\n",
    "ax[3,1].tick_params('x', labelrotation=45)\n",
    "ax[4,0].set_title('Normalized number of papers using 9 empricial methods per year')\n",
    "ax[4,0].bar_label(ax[4,0].containers[0], rotation=45)\n",
    "ax[4,0].tick_params('x', labelrotation=45)\n",
    "ax[4,1].set_title('Normalized number of papers using 10 empricial methods per year')\n",
    "ax[4,1].bar_label(ax[4,1].containers[0], rotation=45)\n",
    "ax[4,1].tick_params('x', labelrotation=45)\n",
    "ax[5,0].set_title('Normalized number of papers using 12 empricial methods per year')\n",
    "ax[5,0].bar_label(ax[5,0].containers[0], rotation=45)\n",
    "ax[5,0].tick_params('x', labelrotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figures/CQ16/proportion_of_papers_using_x_empirical_methods_per_year.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>*Data Interpretation*</ins>\n",
    "Based on the figure [\"Normalized number of papers using X empirical methods for data collection and data analysis per year grouped by number of empirical methods\"](Figures/CQ16/proportion_of_papers_using_x_empirical_methods_per_year.png), we observe that proportion of papers using only one or two empirical methods for data collection and data analysis steadily decreases over time. In contrast, we observe a steady increase of using thee or more empiricial methods for data collection and data analysis over time. In particular, from 2016 onwards, researchers often use four or even five different empirical methods. Based on these results, we observe a positive development towards the vision of [Sjøberg et al. (2007)](https://doi.org/10.1109/FOSE.2007.30). Researchers combine data using different methods for data collection and data analysis. Based on our data, we cannot say whether correspondings methods for synthesizing evidence are already available for the **target state (2020 - 2025)** as envisioned.  However, our results indicate that there is a need for methods to synthesize findings due to the increase in the number of methods used per paper in recent years. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16a8259e1791bb0fb9bae0f359302269cb6b9f3eeeb34666ca6d1d1ecd9183a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
