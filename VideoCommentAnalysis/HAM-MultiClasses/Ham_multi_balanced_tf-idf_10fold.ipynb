{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91bd7bbb-cf72-44f1-9224-357f35780c27",
   "metadata": {},
   "source": [
    "## 1. Loading the data and creating balanced data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f4c3d56-688c-48f2-b587-853fd440ff45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr.                   0\n",
      "Comment in English    0\n",
      "Spam / Ham            0\n",
      "Polarity              0\n",
      "Feature Request       0\n",
      "Problem Report        0\n",
      "Safety                0\n",
      "Efficiency            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "# Load the table in a dataframe for further data analysis\n",
    "comments_df = pd.read_csv('ham_comments_multiclass.csv')\n",
    "\n",
    "# Replace all empty cells with no_aspect and the cells containing x with respective aspect\n",
    "comments_df.fillna('no_aspect', inplace=True)\n",
    "comments_df[\"Feature Request\"].replace({'x': 'feature'}, inplace=True)\n",
    "comments_df[\"Problem Report\"].replace({'x': 'problem'}, inplace=True)\n",
    "comments_df[\"Safety\"].replace({'x': 'safety'}, inplace=True)\n",
    "comments_df[\"Efficiency\"].replace({'x': 'efficiency'}, inplace=True)\n",
    "\n",
    "# Check if the dataframe contains any empty cells. \n",
    "# If all columns have 0 empty cells than the dataframe is complete.\n",
    "print(comments_df.isna().sum())\n",
    "\n",
    "# Extract all comments where the subject is feature request\n",
    "feature = comments_df[comments_df['Feature Request'] == 'feature']\n",
    "\n",
    "# Extract all comments where the subject is not feature request\n",
    "no_feature = comments_df[comments_df['Feature Request'] == 'no_aspect']\n",
    "\n",
    "# Extract all comments where the subject is problem report\n",
    "problem = comments_df[comments_df['Problem Report'] == 'problem']\n",
    "\n",
    "# Extract all comments where the subject is not problem report\n",
    "no_problem = comments_df[comments_df['Problem Report'] == 'no_aspect']\n",
    "\n",
    "# Extract all safety related comments\n",
    "safety = comments_df[comments_df['Safety'] == 'safety']\n",
    "\n",
    "# Extract all comments not related to safety\n",
    "no_safety = comments_df[comments_df['Safety'] == 'no_aspect']\n",
    "\n",
    "# Extract all efficiency related comments\n",
    "efficiency = comments_df[comments_df['Efficiency'] == 'efficiency']\n",
    "\n",
    "# Extract all comments not related to efficiency\n",
    "no_efficiency = comments_df[comments_df['Efficiency'] == 'no_aspect']\n",
    "\n",
    "# Use only as many no_feature comments as there are feature comments to have a balanced dataset\n",
    "no_feature = no_feature.sample(feature.shape[0])\n",
    "problem = problem.sample(no_problem.shape[0])\n",
    "no_safety = no_safety.sample(safety.shape[0])\n",
    "no_efficiency = no_efficiency.sample(efficiency.shape[0])\n",
    "\n",
    "# Create new balanced datasets\n",
    "balanced_feature_df = no_feature.append(feature, ignore_index = True)\n",
    "balanced_problem_df = no_problem.append(problem, ignore_index = True)\n",
    "balanced_safety_df = no_safety.append(safety, ignore_index = True)\n",
    "balanced_efficiency_df = no_efficiency.append(efficiency, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6fdccd-2001-4598-8607-e3efae5a6f9a",
   "metadata": {},
   "source": [
    "## 2. Perfoming 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4c628ca-7101-4e2a-b3ee-fa4be2a20d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE\n",
      "Model: LR\n",
      "Accuracy: 0.754064039408867\n",
      "F1Score: 0.7504410028054928\n",
      "FbScore: 0.7530037468456102\n",
      "Recall: 0.7534024921157273\n",
      "Precision: 0.7537124640065815\n",
      "Model: SVM\n",
      "Accuracy: 0.7433497536945813\n",
      "F1Score: 0.739295456411119\n",
      "FbScore: 0.7431830464942343\n",
      "Recall: 0.7439487106031223\n",
      "Precision: 0.7493909289884522\n",
      "Model: RF\n",
      "Accuracy: 0.7257389162561577\n",
      "F1Score: 0.7223658365644753\n",
      "FbScore: 0.7261696955822516\n",
      "Recall: 0.7266806028938382\n",
      "Precision: 0.7249660388630977\n",
      "Model: NB\n",
      "Accuracy: 0.6693349753694581\n",
      "F1Score: 0.6573900965671869\n",
      "FbScore: 0.6635799656336598\n",
      "Recall: 0.6647767918356152\n",
      "Precision: 0.6742543803805414\n",
      "PROBLEM\n",
      "Model: LR\n",
      "Accuracy: 0.6704225352112677\n",
      "F1Score: 0.668854726862879\n",
      "FbScore: 0.6703279600093222\n",
      "Recall: 0.6740862806148109\n",
      "Precision: 0.6747053718241767\n",
      "Model: SVM\n",
      "Accuracy: 0.6732394366197183\n",
      "F1Score: 0.6720095429686538\n",
      "FbScore: 0.673694833540215\n",
      "Recall: 0.6782687683300346\n",
      "Precision: 0.6796642871599012\n",
      "Model: RF\n",
      "Accuracy: 0.6366197183098592\n",
      "F1Score: 0.6333405417351392\n",
      "FbScore: 0.6354197739033421\n",
      "Recall: 0.6419747711558348\n",
      "Precision: 0.6467411881012963\n",
      "Model: NB\n",
      "Accuracy: 0.5887323943661971\n",
      "F1Score: 0.58630116492498\n",
      "FbScore: 0.5876166900965982\n",
      "Recall: 0.5908068357605586\n",
      "Precision: 0.5910599881288554\n",
      "SAFETY\n",
      "Model: LR\n",
      "Accuracy: 0.8235023041474655\n",
      "F1Score: 0.8224862583372714\n",
      "FbScore: 0.8250846535544054\n",
      "Recall: 0.8272361243655284\n",
      "Precision: 0.8253052322461552\n",
      "Model: SVM\n",
      "Accuracy: 0.8218894009216591\n",
      "F1Score: 0.8207020127136365\n",
      "FbScore: 0.8229268948601287\n",
      "Recall: 0.8248038585636974\n",
      "Precision: 0.8233922106883893\n",
      "Model: RF\n",
      "Accuracy: 0.8173323092677933\n",
      "F1Score: 0.8162413643678386\n",
      "FbScore: 0.8184238306207066\n",
      "Recall: 0.8201757079301121\n",
      "Precision: 0.8183479906805253\n",
      "Model: NB\n",
      "Accuracy: 0.6680747567844342\n",
      "F1Score: 0.6622081821836322\n",
      "FbScore: 0.6651365045486934\n",
      "Recall: 0.669128293516412\n",
      "Precision: 0.6754056982733453\n",
      "EFFICIENCY\n",
      "Model: LR\n",
      "Accuracy: 0.740625\n",
      "F1Score: 0.7374147178711074\n",
      "FbScore: 0.7401160149215785\n",
      "Recall: 0.7407623641408471\n",
      "Precision: 0.7434682010456005\n",
      "Model: SVM\n",
      "Accuracy: 0.74375\n",
      "F1Score: 0.740698759836533\n",
      "FbScore: 0.7434296568589088\n",
      "Recall: 0.7440482938973652\n",
      "Precision: 0.7458985794047714\n",
      "Model: RF\n",
      "Accuracy: 0.7375\n",
      "F1Score: 0.733659933807347\n",
      "FbScore: 0.7347675223711485\n",
      "Recall: 0.7351805409932346\n",
      "Precision: 0.7396468546932944\n",
      "Model: NB\n",
      "Accuracy: 0.6375\n",
      "F1Score: 0.6253178187910704\n",
      "FbScore: 0.6350976563560172\n",
      "Recall: 0.6376071666551543\n",
      "Precision: 0.6554156312794757\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, fbeta_score\n",
    "\n",
    "# Get the comments of the balanced data sets for each aspect\n",
    "X1 = balanced_feature_df['Comment in English'].astype('U').values\n",
    "X2 = balanced_problem_df['Comment in English'].astype('U').values\n",
    "X3 = balanced_safety_df['Comment in English'].astype('U').values\n",
    "X4 = balanced_efficiency_df['Comment in English'].astype('U').values\n",
    "\n",
    "# Get the labels of the comments of the balanced data set for each aspect\n",
    "y1 = balanced_feature_df['Feature Request'].values\n",
    "y2 = balanced_problem_df['Problem Report'].values\n",
    "y3 = balanced_safety_df['Safety'].values\n",
    "y4 = balanced_efficiency_df['Efficiency'].values\n",
    "\n",
    "# Apply bow to the comments of the balanced data set for each aspect\n",
    "v = TfidfVectorizer()\n",
    "X1_vec = v.fit_transform(X1)\n",
    "X2_vec = v.fit_transform(X2)\n",
    "X3_vec = v.fit_transform(X3)\n",
    "X4_vec = v.fit_transform(X4)\n",
    "\n",
    "# Define 10fold crossvalidation\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# Function to create the reporting for the single algorithms and aspect consisting of the average precision, recall, f1, and accuracy\n",
    "def reporting(name, model, feature, data, fb_value):\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    fbs= []\n",
    "\n",
    "    # Perform the 10folds\n",
    "    for train_index, val_index in cv.split(data):\n",
    "        # Train the model\n",
    "        model.fit(data[train_index].toarray(), feature[train_index])\n",
    "        # Predict the labels of the test data\n",
    "        pred = model.predict(data[val_index].toarray())\n",
    "        \n",
    "        # Get the report for the currnt fold\n",
    "        report = classification_report(feature[val_index], pred, output_dict=True)\n",
    "        fb = fbeta_score(feature[val_index], pred, average='macro', beta = fb_value)\n",
    "                \n",
    "        # Add the single measures of the current fold to the array for calculating the averages \n",
    "        accuracies.append(report['accuracy'])\n",
    "        macro_avg = report['macro avg']\n",
    "        precisions.append(macro_avg['precision']) \n",
    "        recalls.append(macro_avg['recall'])\n",
    "        f1s.append(macro_avg['f1-score'])\n",
    "        fbs.append(fb)\n",
    "        \n",
    "        # If needed, the confusion matrix of the fold can be visualized\n",
    "        #confusion_matrix_rf_balanced = confusion_matrix(feature[val_index], pred)\n",
    "        # Plot the confusion matrix for Voting Classifier\n",
    "        #display_labels = ['F', 'no_F']\n",
    "\n",
    "        #disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_rf_balanced, display_labels=display_labels)\n",
    "        #disp = disp.plot(cmap = 'viridis')\n",
    "        #plt.grid(False)\n",
    "        #plt.rcParams.update({'font.size': 15})\n",
    "        #plt.tight_layout()\n",
    "        \n",
    "    # Print the average values of the metrics for current model and aspect\n",
    "    print('Model:', name)\n",
    "    print('Accuracy:', sum(accuracies) / len(accuracies))\n",
    "    print('F1Score:', sum(f1s) / len(f1s))\n",
    "    print('FbScore:', sum(fbs) / len(fbs))\n",
    "    print('Recall:', sum(recalls) / len(recalls))\n",
    "    print('Precision:', sum(precisions) / len(precisions))\n",
    "    \n",
    "    #print()\n",
    "    #print(sum(accuracies) / len(accuracies))\n",
    "    #print(sum(f1s) / len(f1s))\n",
    "    #print(sum(fbs) / len(fbs))\n",
    "    #print(sum(recalls) / len(recalls))\n",
    "    #print(sum(precisions) / len(precisions))\n",
    "\n",
    "# Create the models we want to test\n",
    "model1 = LogisticRegression()\n",
    "model2 = SVC()\n",
    "model3 = GaussianNB()\n",
    "model4 = RandomForestClassifier()\n",
    "\n",
    "# Create the reportings\n",
    "print('FEATURE')\n",
    "reporting('LR', model1, y1, X1_vec, 5.38)\n",
    "reporting('SVM', model2, y1, X1_vec, 5.38)\n",
    "reporting('RF', model4, y1, X1_vec, 5.38)\n",
    "reporting('NB', model3, y1, X1_vec, 5.38)\n",
    "print('PROBLEM')\n",
    "reporting('LR', model1, y2, X2_vec, 1.87)\n",
    "reporting('SVM', model2, y2, X2_vec, 1.87)\n",
    "reporting('RF', model4, y2, X2_vec, 1.87)\n",
    "reporting('NB', model3, y2, X2_vec, 1.87)\n",
    "print('SAFETY')\n",
    "reporting('LR', model1, y3, X3_vec, 2.45)\n",
    "reporting('SVM', model2, y3, X3_vec, 2.45)\n",
    "reporting('RF', model4, y3, X3_vec, 2.45)\n",
    "reporting('NB', model3, y3, X3_vec, 2.45)\n",
    "print('EFFICIENCY')\n",
    "reporting('LR', model1, y4, X4_vec, 4.78)\n",
    "reporting('SVM', model2, y4, X4_vec, 4.78)\n",
    "reporting('RF', model4, y4, X4_vec, 4.78)\n",
    "reporting('NB', model3, y4, X4_vec, 4.78)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
