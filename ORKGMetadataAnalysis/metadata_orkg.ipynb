{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the Metadata of Publications in the Open Research Knowledge Graph \n",
    "This Jupyter notebook contains different analyses on the metadata of publications stored in the Open Research Knowledge Graph [ORKG](https://www.orkg.org/orkg/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data from the ORKG SPAQRL endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from SPARQLWrapper import SPARQLWrapper, CSV\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "ENDPOINT_URL = \"https://www.orkg.org/orkg/triplestore\"\n",
    "\n",
    "PREFIXES =  \"\"\"\n",
    "            PREFIX orkgr: <http://orkg.org/orkg/resource/>\n",
    "            PREFIX orkgc: <http://orkg.org/orkg/class/>\n",
    "            PREFIX orkgp: <http://orkg.org/orkg/predicate/>\n",
    "            PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "            PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "            PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "            \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT ?paper, ?research_field, ?doi, ?title, ?author, ?orcid, ?month, ?year, ?url, ?venue\n",
    "WHERE {\n",
    "  ?paper a orkgc:Paper.\n",
    "  OPTIONAL{?paper rdfs:label ?title.}\n",
    "  OPTIONAL{?paper orkgp:P26 ?doi.}\n",
    "  OPTIONAL{?paper orkgp:P30 ?field.\n",
    "           ?field rdfs:label ?research_field.}\n",
    "  OPTIONAL{?paper orkgp:P27 ?author_resrc.\n",
    "           BIND(IF(isLiteral(?author_resrc), ?author_resrc, \"\") AS ?name1)\n",
    "           OPTIONAL{?author_resrc rdfs:label ?author_label;\n",
    "                            orkgp:HAS_ORCID ?orcid.}\n",
    "           BIND(IF(BOUND(?author_label),?author_label, \"\") AS ?name2)\n",
    "           BIND(IF(?name1 = \"\", ?name2, ?name1) AS ?author)\n",
    "          }\n",
    "  \n",
    "  OPTIONAL{?paper orkgp:P28 ?month_resrc.\n",
    "           BIND(IF(isLiteral(?month_resrc), ?month_resrc, \"\") AS ?month1)\n",
    "           OPTIONAL{?month_resrc rdfs:label ?month_label.}\n",
    "           BIND(IF(BOUND(?month_label),?month_label, \"\") AS ?month2)\n",
    "           BIND(IF(?month1 = \"\", ?month2, ?month1) AS ?month)\n",
    "          }\n",
    "  \n",
    "  OPTIONAL{?paper orkgp:P29 ?year_resrc.\n",
    "           BIND(IF(isLiteral(?year_resrc), ?year_resrc, \"\") AS ?year1)\n",
    "           OPTIONAL{?year_resrc rdfs:label ?year_label.}\n",
    "           BIND(IF(BOUND(?year_label),?year_label, \"\") AS ?year2)\n",
    "           BIND(IF(?year1 = \"\", ?year2, ?year1) AS ?year)\n",
    "          }\n",
    "  \n",
    "  OPTIONAL{?paper orkgp:url ?url.}\n",
    "  OPTIONAL{?paper orkgp:HAS_VENUE ?venue_resrc.\n",
    "           ?venue_resrc rdfs:label ?venue.}\n",
    "} ORDER BY ?paper\n",
    "        \"\"\"\n",
    "\n",
    "user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "\n",
    "sparql = SPARQLWrapper(ENDPOINT_URL, agent=user_agent)\n",
    "sparql.setQuery(PREFIXES+query)\n",
    "sparql.setReturnFormat(CSV)\n",
    "\n",
    "try:\n",
    "        results = sparql.queryAndConvert()\n",
    "except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "now = datetime.now()\n",
    "with open('query_result_' + now.strftime('%Y-%m-%d') + '.csv', 'wb') as file:\n",
    "        file.write(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Validation and Check\n",
    "1. Reading the data and checking the shape and column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe: (42216, 10)\n",
      "Column names: Index(['paper', 'research_field', 'doi', 'title', 'author', 'orcid', 'month',\n",
      "       'year', 'url', 'venue'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('query_result_' + now.strftime('%Y-%m-%d') + '.csv', encoding='utf-8', encoding_errors='ignore')\n",
    "\n",
    "print('Shape of the dataframe: '+ str(df.shape))\n",
    "print('Column names: ' + str(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Checking for NaN values in each column for the entire dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       paper\n",
      "False  42216\n",
      "       research_field\n",
      "False           41998\n",
      "True              218\n",
      "         doi\n",
      "False  35670\n",
      "True    6546\n",
      "       title\n",
      "False  42206\n",
      "True      10\n",
      "       author\n",
      "False   41806\n",
      "True      410\n",
      "       orcid\n",
      "True   39145\n",
      "False   3071\n",
      "       month\n",
      "False  32048\n",
      "True   10168\n",
      "        year\n",
      "False  40420\n",
      "True    1796\n",
      "         url\n",
      "True   33571\n",
      "False   8645\n",
      "       venue\n",
      "False  26735\n",
      "True   15481\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"max_rows\", None)\n",
    "for column in df:\n",
    "    print(df[column].isna().value_counts(dropna=False).to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Derterming the number of NaN entries of the column **paper** and the number of unique papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN entries: 0\n",
      "Number of unique papers: 10099\n"
     ]
    }
   ],
   "source": [
    "#print(df.drop_duplicates(subset='paper')['paper'].value_counts(dropna=False).sum())\n",
    "print('Number of NaN entries: ' + str(df['paper'].isna().sum()))\n",
    "print('Number of unique papers: '+ str(df['paper'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Checking the number of unique papers per **research field** and the number of unique papers without a research field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique papers without a research field: 118\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>research_field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Science</th>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bioinformatics</th>\n",
       "      <td>1191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ecology and Evolutionary Biology</th>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Information Science</th>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Artificial Intelligence</th>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toxicology</th>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computer Sciences</th>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urban Studies and Planning</th>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medicinal Chemistry and Pharmaceutics</th>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Natural Language Processing</th>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oceanography</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virology</th>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineering</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plasma and Beam Physics</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Databases/Information Systems</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       research_field\n",
       "Science                                          3001\n",
       "Bioinformatics                                   1191\n",
       "Ecology and Evolutionary Biology                  968\n",
       "Information Science                               550\n",
       "Artificial Intelligence                           321\n",
       "Toxicology                                        295\n",
       "Computer Sciences                                 243\n",
       "Urban Studies and Planning                        203\n",
       "Medicinal Chemistry and Pharmaceutics             187\n",
       "Natural Language Processing                       164\n",
       "Oceanography                                      126\n",
       "Virology                                          109\n",
       "Engineering                                       108\n",
       "Plasma and Beam Physics                            98\n",
       "Databases/Information Systems                      97"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique_papers = df.drop_duplicates(subset='paper')\n",
    "print('Number of unique papers without a research field: ' + str(df_unique_papers['research_field'].isna().sum()))\n",
    "df_unique_papers['research_field'].value_counts().to_frame().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Checking the number of incorrect entries for the column **doi** and the number of unique papers without a DOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of incorrect DOIs :50\n",
      "                                                    doi\n",
      "https://doi.org/10.1016/j.eswa.2019.05.052            1\n",
      " 10.34865/mb311549d5_1                                1\n",
      "https://doi.org/10.14778/2536336.2536343              1\n",
      "hdl.handle.net/10520/AJA0038223X_3168                 1\n",
      "https://doi.org/10.1016/j.procs.2016.09.123           1\n",
      "doi.org/10.1016/j.artint.2012.03.006                  1\n",
      "doi.org/10.1016/j.jbi.2013.09.008                     1\n",
      " 10.34865/mb7934d5_2ad                                1\n",
      " 10.34865/mb11207d5_1                                 1\n",
      " 10.34865/mb10766kskd5_1                              1\n",
      " 10.34865/mb7943verd5_1                               1\n",
      " 10.34865/mb10001d5_1                                 1\n",
      " 10.34865/mb0228fstd5_2ad                             1\n",
      "https://www.nature.com/articles/s41598-019-40043-5    1\n",
      " 10.34865/mb6772d5_2ad                                1\n",
      "Number of unique papers without a DOI: 2256\n"
     ]
    }
   ],
   "source": [
    "incorrect_DOIs = df_unique_papers[~df_unique_papers['doi'].str.startswith('10', na=False)]\n",
    "print('Number of incorrect DOIs :' + str(incorrect_DOIs['doi'].value_counts().sum()))\n",
    "print(incorrect_DOIs['doi'].value_counts().to_frame().head(15))\n",
    "print('Number of unique papers without a DOI: ' + str(df_unique_papers['doi'].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Checking the number of unique papers with a specific **title** and the number of unique papers without a title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique papers without a title: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Governing nonprofit platform ecosystems – an information platform for refugees</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linking sea level rise and socioeconomic indicators under the Shared Socioeconomic Pathways</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Absolute measurement of the resonance lines in heliumlike vanadium on an electron-beam ion trap</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Creating the European Literary Text Collection (ELTeC): Challenges and Perspectives</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Theoretical energies for the &lt;i&gt;n&lt;/i&gt; = 1 and 2 states of the helium isoelectronic sequence up to &lt;i&gt;Z&lt;/i&gt; = 100</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Phyical Performance Test Profile (IPPTP)</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solution-processed high-performance p-channel copper tin sulfide thin-film transistors</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two New Phytoecdysteroids From Sphenocentrum jollyanum Pierre Root</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model and heuristics for the Assembly Line Worker Integration and Balancing Problem</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Present-Day Atmospheric Simulations Using GISS ModelE: Comparison to In Situ, Satellite, and Reanalysis Data</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Graph Based Tool for Modelling Planning Processes in Building Engineering</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Markovian Model for the Analysis of Age of Information in IoT Networks</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Optimization of Pulsed Electric Field Treatment for the Extraction of Bioactive Compounds from Blackcurrant</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alkaloids and flavonoids from African phytochemicals as potential inhibitors of SARS-Cov-2 RNA-dependent RNA polymerase: an in silico perspective</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title\n",
       "Governing nonprofit platform ecosystems – an in...     14\n",
       "Linking sea level rise and socioeconomic indica...     14\n",
       "Absolute measurement of the resonance lines in ...     11\n",
       "Creating the European Literary Text Collection ...      9\n",
       "Theoretical energies for the <i>n</i> = 1 and 2...      6\n",
       "International Phyical Performance Test Profile ...      5\n",
       "Solution-processed high-performance p-channel c...      5\n",
       "Two New Phytoecdysteroids From Sphenocentrum jo...      4\n",
       "BERT: Pre-training of Deep Bidirectional Transf...      4\n",
       "Model and heuristics for the Assembly Line Work...      4\n",
       "Present-Day Atmospheric Simulations Using GISS ...      4\n",
       "A Graph Based Tool for Modelling Planning Proce...      4\n",
       "A Markovian Model for the Analysis of Age of In...      3\n",
       "Optimization of Pulsed Electric Field Treatment...      3\n",
       "Alkaloids and flavonoids from African phytochem...      3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#duplicated_title = df.drop_duplicates(subset=['paper'])\n",
    "print('Number of unique papers without a title: ' + str(df_unique_papers['title'].isna().sum()))\n",
    "df_unique_papers['title'].value_counts().loc[lambda x : x >= 2].to_frame().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique papers without a month: 3116\n",
      "1               1641\n",
      "10               564\n",
      "7                539\n",
      "9                514\n",
      "5                503\n",
      "12               486\n",
      "8                484\n",
      "6                482\n",
      "4                463\n",
      "3                463\n",
      "11               437\n",
      "2                405\n",
      "October 2020       1\n",
      "0                  1\n",
      "Name: month, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique papers without a month: ' + str(df_unique_papers['month'].isna().sum()))\n",
    "print(df_unique_papers['month'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(md_df['year_number'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_df = md_df[['paper','field_label']].drop_duplicates()\n",
    "\n",
    "pd.set_option(\"max_rows\", None)\n",
    "field_df[['field_label']].value_counts(dropna=False)\n",
    "\n",
    "sns.countplot(y='field_label', data=field_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "nsfg['nbrnaliv'].replace([98,99], np.nan, inplace=True)\n",
    "\n",
    "df['paper'] = md_df['paper'].astype('str')\n",
    "df['field'] = md_df['field_label'].astype('category')\n",
    "df['DOI'] = md_df['DOI'].astype('str')\n",
    "df['title'] = md_df['title'].astype('str')\n",
    "df['author'] = md_df['name'].astype('str')\n",
    "df['orcid'] = md_df['id'].astype('str')\n",
    "df['month'] = md_df['month_number'].fillna(0.0).astype('int')\n",
    "df['year'] = md_df['year_number'].fillna(0.0).astype('int')\n",
    "df['url'] = md_df['paper_url'].astype('str')\n",
    "df['venue'] = md_df['venue_label'].astype('str')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16a8259e1791bb0fb9bae0f359302269cb6b9f3eeeb34666ca6d1d1ecd9183a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
