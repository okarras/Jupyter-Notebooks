{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the Metadata of Publications in the Open Research Knowledge Graph \n",
    "This Jupyter notebook contains different analyses on the metadata of publications stored in the Open Research Knowledge Graph [ORKG](https://www.orkg.org/orkg/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data from the ORKG SPAQRL endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from SPARQLWrapper import SPARQLWrapper, CSV\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "ENDPOINT_URL = \"https://www.orkg.org/orkg/triplestore\"\n",
    "\n",
    "PREFIXES =  \"\"\"\n",
    "            PREFIX orkgr: <http://orkg.org/orkg/resource/>\n",
    "            PREFIX orkgc: <http://orkg.org/orkg/class/>\n",
    "            PREFIX orkgp: <http://orkg.org/orkg/predicate/>\n",
    "            PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "            PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "            PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "            \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT ?paper, ?research_field, ?doi, ?title, ?author, ?orcid, ?month, ?year, ?url, ?venue\n",
    "WHERE {\n",
    "  ?paper a orkgc:Paper.\n",
    "  OPTIONAL{?paper rdfs:label ?title.}\n",
    "  OPTIONAL{?paper orkgp:P26 ?doi.}\n",
    "  OPTIONAL{?paper orkgp:P30 ?field.\n",
    "           ?field rdfs:label ?research_field.}\n",
    "  OPTIONAL{?paper orkgp:P27 ?author_resrc.\n",
    "           BIND(IF(isLiteral(?author_resrc), ?author_resrc, \"\") AS ?name1)\n",
    "           OPTIONAL{?author_resrc rdfs:label ?author_label;\n",
    "                            orkgp:HAS_ORCID ?orcid.}\n",
    "           BIND(IF(BOUND(?author_label),?author_label, \"\") AS ?name2)\n",
    "           BIND(IF(?name1 = \"\", ?name2, ?name1) AS ?author)\n",
    "          }\n",
    "  \n",
    "  OPTIONAL{?paper orkgp:P28 ?month_resrc.\n",
    "           BIND(IF(isLiteral(?month_resrc), ?month_resrc, \"\") AS ?month1)\n",
    "           OPTIONAL{?month_resrc rdfs:label ?month_label.}\n",
    "           BIND(IF(BOUND(?month_label),?month_label, \"\") AS ?month2)\n",
    "           BIND(IF(?month1 = \"\", ?month2, ?month1) AS ?month)\n",
    "          }\n",
    "  \n",
    "  OPTIONAL{?paper orkgp:P29 ?year_resrc.\n",
    "           BIND(IF(isLiteral(?year_resrc), ?year_resrc, \"\") AS ?year1)\n",
    "           OPTIONAL{?year_resrc rdfs:label ?year_label.}\n",
    "           BIND(IF(BOUND(?year_label),?year_label, \"\") AS ?year2)\n",
    "           BIND(IF(?year1 = \"\", ?year2, ?year1) AS ?year)\n",
    "          }\n",
    "  \n",
    "  OPTIONAL{?paper orkgp:url ?url.}\n",
    "  OPTIONAL{?paper orkgp:HAS_VENUE ?venue_resrc.\n",
    "           ?venue_resrc rdfs:label ?venue.}\n",
    "} ORDER BY ?paper\n",
    "        \"\"\"\n",
    "\n",
    "user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "\n",
    "sparql = SPARQLWrapper(ENDPOINT_URL, agent=user_agent)\n",
    "sparql.setQuery(PREFIXES+query)\n",
    "sparql.setReturnFormat(CSV)\n",
    "\n",
    "try:\n",
    "        results = sparql.queryAndConvert()\n",
    "except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "now = datetime.now()\n",
    "with open('query_result_' + now.strftime('%Y-%m-%d') + '.csv', 'wb') as file:\n",
    "        file.write(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Validation and Check\n",
    "1. Reading the data and checking the shape and column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe: (64260, 10)\n",
      "Column names: Index(['paper', 'research_field', 'doi', 'title', 'author', 'orcid', 'month',\n",
      "       'year', 'url', 'venue'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('query_result_' + now.strftime('%Y-%m-%d') + '.csv', encoding='utf-8', encoding_errors='ignore')\n",
    "\n",
    "print('Shape of the dataframe: '+ str(df.shape))\n",
    "print('Column names: ' + str(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Checking for NaN values in each column for the entire dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       paper\n",
      "False  64260\n",
      "       research_field\n",
      "False           63809\n",
      "True              451\n",
      "         doi\n",
      "False  54981\n",
      "True    9279\n",
      "       title\n",
      "False  64250\n",
      "True      10\n",
      "       author\n",
      "False   63766\n",
      "True      494\n",
      "       orcid\n",
      "True   59691\n",
      "False   4569\n",
      "       month\n",
      "False  49030\n",
      "True   15230\n",
      "        year\n",
      "False  62051\n",
      "True    2209\n",
      "         url\n",
      "True   47410\n",
      "False  16850\n",
      "       venue\n",
      "False  48074\n",
      "True   16186\n"
     ]
    }
   ],
   "source": [
    "#pd.set_option(\"max_rows\", None)\n",
    "for column in df:\n",
    "    print(df[column].isna().value_counts(dropna=False).to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Derterming the number of NaN entries of the column **paper** and the number of unique papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN entries: 0\n",
      "Number of unique papers: 13995\n"
     ]
    }
   ],
   "source": [
    "#print(df.drop_duplicates(subset='paper')['paper'].value_counts(dropna=False).sum())\n",
    "print('Number of NaN entries: ' + str(df['paper'].isna().sum()))\n",
    "print('Number of unique papers: '+ str(df['paper'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Checking the number of unique papers per **research field** and the number of unique papers without a research field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique papers without a research field: 181\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>research_field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Science</th>\n",
       "      <td>3141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bioinformatics</th>\n",
       "      <td>1195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ecology and Evolutionary Biology</th>\n",
       "      <td>976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medicine</th>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Artificial Intelligence</th>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Software Engineering</th>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Information Science</th>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Natural Language Processing</th>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virology</th>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Operations Research, Systems Engineering and Industrial Engineering</th>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computer and Systems Architecture</th>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toxicology</th>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computer Engineering</th>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computer Sciences</th>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Semantic Web</th>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    research_field\n",
       "Science                                                       3141\n",
       "Bioinformatics                                                1195\n",
       "Ecology and Evolutionary Biology                               976\n",
       "Medicine                                                       786\n",
       "Artificial Intelligence                                        414\n",
       "Software Engineering                                           410\n",
       "Information Science                                            408\n",
       "Natural Language Processing                                    387\n",
       "Virology                                                       361\n",
       "Operations Research, Systems Engineering and In...             346\n",
       "Computer and Systems Architecture                              334\n",
       "Toxicology                                                     295\n",
       "Computer Engineering                                           276\n",
       "Computer Sciences                                              251\n",
       "Semantic Web                                                   206"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique_papers = df.drop_duplicates(subset='paper')\n",
    "print('Number of unique papers without a research field: ' + str(df_unique_papers['research_field'].isna().sum()))\n",
    "df_unique_papers['research_field'].value_counts().to_frame().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Checking the number of incorrect entries for the column **doi** and the number of unique papers without a DOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of incorrect DOIs :850\n",
      "                                              doi\n",
      "https://doi.org/10.1126/science.aad5177         2\n",
      "https://doi.org/10.1016/j.eswa.2019.05.052      1\n",
      "https://doi.org/10.1038/sj.gt.3302887           1\n",
      "https://doi.org/10.1177/0272989x19883631        1\n",
      "https://doi.org/10.3390/molecules20046237       1\n",
      "https://doi.org/10.1177/0300060515613223        1\n",
      "https://doi.org/10.1186/s13395-017-0139-5       1\n",
      "https://doi.org/10.1212/wnl.0000000000004570    1\n",
      "https://doi.org/10.1089/hum.2013.210            1\n",
      "https://doi.org/10.1096/fj.201802488r           1\n",
      "https://doi.org/10.1016/j.nmd.2017.10.004       1\n",
      "https://doi.org/10.1016/j.nmd.2017.06.557       1\n",
      "https://doi.org/10.1016/j.nmd.2012.05.002       1\n",
      "https://doi.org/10.1186/s13395-019-0207-0       1\n",
      "https://doi.org/10.1038/nbt.4148                1\n",
      "Number of unique papers without a DOI: 2986\n"
     ]
    }
   ],
   "source": [
    "incorrect_DOIs = df_unique_papers[~df_unique_papers['doi'].str.startswith('10', na=False)]\n",
    "print('Number of incorrect DOIs :' + str(incorrect_DOIs['doi'].value_counts().sum()))\n",
    "print(incorrect_DOIs['doi'].value_counts().to_frame().head(15))\n",
    "print('Number of unique papers without a DOI: ' + str(df_unique_papers['doi'].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Checking the number of unique papers with a specific **title** and the number of unique papers without a title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique papers without a title: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>An Intrusion Detection Model for Wireless Sensor Networks With an Improved V-Detector Algorithm</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Governing nonprofit platform ecosystems – an information platform for refugees</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Absolute measurement of the resonance lines in heliumlike vanadium on an electron-beam ion trap</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Two-Layer Dimension Reduction and Two-Tier Classification Model for Anomaly-Based Intrusion Detection in IoT Backbone Networks</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Creating the European Literary Text Collection (ELTeC): Challenges and Perspectives</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stark broadening of spectral lines along the isoelectronic sequence of Li</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A semi-automated, KNIME-based workflow for biofilm assays</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stark broadening of resonance transitions in B III</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>دور الحكومة الإلكترونية في الحد من ظاهرة الفساد الإداري دراسة استطلاعية لآراء العاملين على الخدمات الإلكترونية في الإدارات العامة في لبنان</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spectral line profiles of n=4 to n=5 transitions in C IV, N V and O VI</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title\n",
       "An Intrusion Detection Model for Wireless Senso...     36\n",
       "Governing nonprofit platform ecosystems – an in...     14\n",
       "Absolute measurement of the resonance lines in ...     11\n",
       "A Two-Layer Dimension Reduction and Two-Tier Cl...      9\n",
       "Creating the European Literary Text Collection ...      9\n",
       "...                                                   ...\n",
       "Stark broadening of spectral lines along the is...      2\n",
       "A semi-automated, KNIME-based workflow for biof...      2\n",
       "Stark broadening of resonance transitions in B III      2\n",
       "دور الحكومة الإلكترونية في الحد من ظاهرة الفساد...      2\n",
       "Spectral line profiles of n=4 to n=5 transition...      2\n",
       "\n",
       "[181 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of unique papers without a title: ' + str(df_unique_papers['title'].isna().sum()))\n",
    "df_unique_papers['title'].value_counts().loc[lambda x : x >= 2].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique papers without a month: 4312\n",
      "1               1867\n",
      "9                853\n",
      "10               806\n",
      "7                802\n",
      "8                797\n",
      "5                704\n",
      "6                696\n",
      "12               666\n",
      "3                663\n",
      "4                646\n",
      "11               610\n",
      "2                571\n",
      "October 2020       1\n",
      "0                  1\n",
      "Name: month, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique papers without a month: ' + str(df_unique_papers['month'].isna().sum()))\n",
    "print(df_unique_papers['month'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'md_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmd_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear_number\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts(dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'md_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(md_df['year_number'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_df = md_df[['paper','field_label']].drop_duplicates()\n",
    "\n",
    "pd.set_option(\"max_rows\", None)\n",
    "field_df[['field_label']].value_counts(dropna=False)\n",
    "\n",
    "sns.countplot(y='field_label', data=field_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "nsfg['nbrnaliv'].replace([98,99], np.nan, inplace=True)\n",
    "\n",
    "df['paper'] = md_df['paper'].astype('str')\n",
    "df['field'] = md_df['field_label'].astype('category')\n",
    "df['DOI'] = md_df['DOI'].astype('str')\n",
    "df['title'] = md_df['title'].astype('str')\n",
    "df['author'] = md_df['name'].astype('str')\n",
    "df['orcid'] = md_df['id'].astype('str')\n",
    "df['month'] = md_df['month_number'].fillna(0.0).astype('int')\n",
    "df['year'] = md_df['year_number'].fillna(0.0).astype('int')\n",
    "df['url'] = md_df['paper_url'].astype('str')\n",
    "df['venue'] = md_df['venue_label'].astype('str')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16a8259e1791bb0fb9bae0f359302269cb6b9f3eeeb34666ca6d1d1ecd9183a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
