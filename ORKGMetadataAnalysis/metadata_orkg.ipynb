{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the Metadata of Publications in the Open Research Knowledge Graph \n",
    "This Jupyter notebook contains different analyses on the metadata of publications stored in the Open Research Knowledge Graph [ORKG](https://www.orkg.org/orkg/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data from the ORKG SPAQRL endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from SPARQLWrapper import SPARQLWrapper, CSV\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "ENDPOINT_URL = \"https://www.orkg.org/orkg/triplestore\"\n",
    "\n",
    "PREFIXES =  \"\"\"\n",
    "            PREFIX orkgr: <http://orkg.org/orkg/resource/>\n",
    "            PREFIX orkgc: <http://orkg.org/orkg/class/>\n",
    "            PREFIX orkgp: <http://orkg.org/orkg/predicate/>\n",
    "            PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "            PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "            PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "            \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT ?paper, ?research_field, ?doi, ?title, ?author, ?orcid, ?month, ?year, ?url, ?venue\n",
    "WHERE {\n",
    "  ?paper a orkgc:Paper.\n",
    "  OPTIONAL{?paper rdfs:label ?title.}\n",
    "  OPTIONAL{?paper orkgp:P26 ?doi.}\n",
    "  OPTIONAL{?paper orkgp:P30 ?field.\n",
    "           ?field rdfs:label ?research_field.}\n",
    "  OPTIONAL{?paper orkgp:P27 ?author_resrc.\n",
    "           BIND(IF(isLiteral(?author_resrc), ?author_resrc, \"\") AS ?name1)\n",
    "           OPTIONAL{?author_resrc rdfs:label ?author_label;\n",
    "                            orkgp:HAS_ORCID ?orcid.}\n",
    "           BIND(IF(BOUND(?author_label),?author_label, \"\") AS ?name2)\n",
    "           BIND(IF(?name1 = \"\", ?name2, ?name1) AS ?author)\n",
    "          }\n",
    "  \n",
    "  OPTIONAL{?paper orkgp:P28 ?month_resrc.\n",
    "           BIND(IF(isLiteral(?month_resrc), ?month_resrc, \"\") AS ?month1)\n",
    "           OPTIONAL{?month_resrc rdfs:label ?month_label.}\n",
    "           BIND(IF(BOUND(?month_label),?month_label, \"\") AS ?month2)\n",
    "           BIND(IF(?month1 = \"\", ?month2, ?month1) AS ?month)\n",
    "          }\n",
    "  \n",
    "  OPTIONAL{?paper orkgp:P29 ?year_resrc.\n",
    "           BIND(IF(isLiteral(?year_resrc), ?year_resrc, \"\") AS ?year1)\n",
    "           OPTIONAL{?year_resrc rdfs:label ?year_label.}\n",
    "           BIND(IF(BOUND(?year_label),?year_label, \"\") AS ?year2)\n",
    "           BIND(IF(?year1 = \"\", ?year2, ?year1) AS ?year)\n",
    "          }\n",
    "  \n",
    "  OPTIONAL{?paper orkgp:url ?url.}\n",
    "  OPTIONAL{?paper orkgp:HAS_VENUE ?venue_resrc.\n",
    "           ?venue_resrc rdfs:label ?venue.}\n",
    "} ORDER BY ?paper\n",
    "        \"\"\"\n",
    "\n",
    "user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "\n",
    "sparql = SPARQLWrapper(ENDPOINT_URL, agent=user_agent)\n",
    "sparql.setQuery(PREFIXES+query)\n",
    "sparql.setReturnFormat(CSV)\n",
    "\n",
    "try:\n",
    "        results = sparql.queryAndConvert()\n",
    "except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "now = datetime.now()\n",
    "with open('query_result_' + now.strftime('%Y-%m-%d') + '.csv', 'wb') as file:\n",
    "        file.write(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Validation and Check\n",
    "1. Reading the data and checking the shape and column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe: (41364, 10)\n",
      "Column names: Index(['paper', 'research_field', 'doi', 'title', 'author', 'orcid', 'month',\n",
      "       'year', 'url', 'venue'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('query_result_' + now.strftime('%Y-%m-%d') + '.csv', encoding='utf-8', encoding_errors='ignore')\n",
    "\n",
    "print('Shape of the dataframe: '+ str(df.shape))\n",
    "print('Column names: ' + str(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Checking for NaN values in each column for the entire dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       paper\n",
      "False  41364\n",
      "       research_field\n",
      "False           41176\n",
      "True              188\n",
      "         doi\n",
      "False  34910\n",
      "True    6454\n",
      "       title\n",
      "False  41354\n",
      "True      10\n",
      "       author\n",
      "False   40974\n",
      "True      390\n",
      "       orcid\n",
      "True   38415\n",
      "False   2949\n",
      "       month\n",
      "False  31442\n",
      "True    9922\n",
      "        year\n",
      "False  39601\n",
      "True    1763\n",
      "         url\n",
      "True   33192\n",
      "False   8172\n",
      "       venue\n",
      "False  25966\n",
      "True   15398\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"max_rows\", None)\n",
    "for column in df:\n",
    "    print(df[column].isna().value_counts(dropna=False).to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Derterming the number of NaN entries of the column **paper** and the number of unique papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN entries: 0\n",
      "Number of unique papers: 9880\n"
     ]
    }
   ],
   "source": [
    "#print(df.drop_duplicates(subset='paper')['paper'].value_counts(dropna=False).sum())\n",
    "print('Number of NaN entries: ' + str(df['paper'].isna().sum()))\n",
    "print('Number of unique papers: '+ str(df['paper'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Checking the number of unique papers per **research field** and the number of unique papers without a research field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique papers without a research field: 108\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>research_field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Science</th>\n",
       "      <td>3216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bioinformatics</th>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ecology and Evolutionary Biology</th>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Information Science</th>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Artificial Intelligence</th>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toxicology</th>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computer Sciences</th>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urban Studies and Planning</th>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medicinal Chemistry and Pharmaceutics</th>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Natural Language Processing</th>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oceanography</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineering</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virology</th>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plasma and Beam Physics</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Databases/Information Systems</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       research_field\n",
       "Science                                          3216\n",
       "Bioinformatics                                   1188\n",
       "Ecology and Evolutionary Biology                  968\n",
       "Information Science                               324\n",
       "Artificial Intelligence                           304\n",
       "Toxicology                                        295\n",
       "Computer Sciences                                 238\n",
       "Urban Studies and Planning                        203\n",
       "Medicinal Chemistry and Pharmaceutics             187\n",
       "Natural Language Processing                       160\n",
       "Oceanography                                      126\n",
       "Engineering                                       108\n",
       "Virology                                          106\n",
       "Plasma and Beam Physics                            98\n",
       "Databases/Information Systems                      96"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique_papers = df.drop_duplicates(subset='paper')\n",
    "print('Number of unique papers without a research field: ' + str(df_unique_papers['research_field'].isna().sum()))\n",
    "df_unique_papers['research_field'].value_counts().to_frame().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Checking the number of incorrect entries for the column **doi** and the number of unique papers without a DOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of incorrect DOIs :47\n",
      "                                             doi\n",
      "https://doi.org/10.1016/j.eswa.2019.05.052     1\n",
      " 10.34865/mb0228fstd5_2ad                      1\n",
      "https://doi.org/10.1016/j.procs.2016.09.123    1\n",
      "doi.org/10.1016/j.artint.2012.03.006           1\n",
      "doi.org/10.1016/j.jbi.2013.09.008              1\n",
      " 10.34865/mb7934d5_2ad                         1\n",
      " 10.34865/mb11207d5_1                          1\n",
      " 10.34865/mb10766kskd5_1                       1\n",
      " 10.34865/mb7943verd5_1                        1\n",
      " 10.34865/mb10001d5_1                          1\n",
      " 10.34865/mb311549d5_1                         1\n",
      " 10.34865/mb6772d5_2ad                         1\n",
      "https://doi.org/10.14778/2536336.2536343       1\n",
      " 10.34865/mb744025stad5_2ad                    1\n",
      " 10.34865/mb8759ismd5_2ad                      1\n",
      "Number of unique papers without a DOI: 2215\n"
     ]
    }
   ],
   "source": [
    "incorrect_DOIs = df_unique_papers[~df_unique_papers['doi'].str.startswith('10', na=False)]\n",
    "print('Number of incorrect DOIs :' + str(incorrect_DOIs['doi'].value_counts().sum()))\n",
    "print(incorrect_DOIs['doi'].value_counts().to_frame().head(15))\n",
    "print('Number of unique papers without a DOI: ' + str(df_unique_papers['doi'].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Checking the number of unique papers with a specific **title** and the number of unique papers without a title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique papers without a title: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linking sea level rise and socioeconomic indicators under the Shared Socioeconomic Pathways</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Governing nonprofit platform ecosystems – an information platform for refugees</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Creating the European Literary Text Collection (ELTeC): Challenges and Perspectives</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solution-processed high-performance p-channel copper tin sulfide thin-film transistors</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two New Phytoecdysteroids From Sphenocentrum jollyanum Pierre Root</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model and heuristics for the Assembly Line Worker Integration and Balancing Problem</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Graph Based Tool for Modelling Planning Processes in Building Engineering</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Present-Day Atmospheric Simulations Using GISS ModelE: Comparison to In Situ, Satellite, and Reanalysis Data</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScholOnto: an ontology-based digital library server for research documents and discourse</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Preliminary estimation of the basic reproduction number of novel coronavirus (2019-nCoV) in China, from 2019 to 2020: A data-driven analysis in the early phase of the outbreak</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FaBiO and CiTO: Ontologies for describing bibliographic resources and citations</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The SPAR Ontologies</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Document Components Ontology (DoCO)</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Publishing Workflow Ontology (PWO)</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title\n",
       "Linking sea level rise and socioeconomic indica...     14\n",
       "Governing nonprofit platform ecosystems – an in...     14\n",
       "Creating the European Literary Text Collection ...      9\n",
       "Solution-processed high-performance p-channel c...      5\n",
       "BERT: Pre-training of Deep Bidirectional Transf...      4\n",
       "Two New Phytoecdysteroids From Sphenocentrum jo...      4\n",
       "Model and heuristics for the Assembly Line Work...      4\n",
       "A Graph Based Tool for Modelling Planning Proce...      4\n",
       "Present-Day Atmospheric Simulations Using GISS ...      4\n",
       "ScholOnto: an ontology-based digital library se...      3\n",
       "Preliminary estimation of the basic reproductio...      3\n",
       "FaBiO and CiTO: Ontologies for describing bibli...      3\n",
       "The SPAR Ontologies                                     3\n",
       "The Document Components Ontology (DoCO)                 3\n",
       "The Publishing Workflow Ontology (PWO)                  3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#duplicated_title = df.drop_duplicates(subset=['paper'])\n",
    "print('Number of unique papers without a title: ' + str(df_unique_papers['title'].isna().sum()))\n",
    "df_unique_papers['title'].value_counts().loc[lambda x : x >= 2].to_frame().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'md_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17140/3989855182.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmd_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'month_number'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'md_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(md_df['month_number'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(md_df['year_number'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_df = md_df[['paper','field_label']].drop_duplicates()\n",
    "\n",
    "pd.set_option(\"max_rows\", None)\n",
    "field_df[['field_label']].value_counts(dropna=False)\n",
    "\n",
    "sns.countplot(y='field_label', data=field_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "nsfg['nbrnaliv'].replace([98,99], np.nan, inplace=True)\n",
    "\n",
    "df['paper'] = md_df['paper'].astype('str')\n",
    "df['field'] = md_df['field_label'].astype('category')\n",
    "df['DOI'] = md_df['DOI'].astype('str')\n",
    "df['title'] = md_df['title'].astype('str')\n",
    "df['author'] = md_df['name'].astype('str')\n",
    "df['orcid'] = md_df['id'].astype('str')\n",
    "df['month'] = md_df['month_number'].fillna(0.0).astype('int')\n",
    "df['year'] = md_df['year_number'].fillna(0.0).astype('int')\n",
    "df['url'] = md_df['paper_url'].astype('str')\n",
    "df['venue'] = md_df['venue_label'].astype('str')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1753be5da04732d05159eb7bf4bc65a0acd5a0cc85597053c991de7197b9bfde"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
