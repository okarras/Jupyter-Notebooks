{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the Metadata of Publications in the Open Research Knowledge Graph \n",
    "This Jupyter notebook contains different analyses on the metadata of publications stored in the Open Research Knowledge Graph [ORKG](https://www.orkg.org/orkg/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data from the ORKG SPAQRL endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from SPARQLWrapper import SPARQLWrapper, CSV\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "ENDPOINT_URL = \"https://www.orkg.org/orkg/triplestore\"\n",
    "\n",
    "PREFIXES =  \"\"\"\n",
    "            PREFIX orkgr: <http://orkg.org/orkg/resource/>\n",
    "            PREFIX orkgc: <http://orkg.org/orkg/class/>\n",
    "            PREFIX orkgp: <http://orkg.org/orkg/predicate/>\n",
    "            PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "            PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "            PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "            \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT ?paper, ?research_field, ?doi, ?title, ?author, ?orcid, ?month, ?year, ?url, ?venue\n",
    "WHERE {\n",
    "  ?paper a orkgc:Paper.\n",
    "  OPTIONAL{?paper rdfs:label ?title.}\n",
    "  OPTIONAL{?paper orkgp:P26 ?doi.}\n",
    "  OPTIONAL{?paper orkgp:P30 ?field.\n",
    "           ?field rdfs:label ?research_field.}\n",
    "  OPTIONAL{?paper orkgp:P27 ?author_resrc.\n",
    "           BIND(IF(isLiteral(?author_resrc), ?author_resrc, \"\") AS ?name1)\n",
    "           OPTIONAL{?author_resrc rdfs:label ?author_label;\n",
    "                            orkgp:HAS_ORCID ?orcid.}\n",
    "           BIND(IF(BOUND(?author_label),?author_label, \"\") AS ?name2)\n",
    "           BIND(IF(?name1 = \"\", ?name2, ?name1) AS ?author)\n",
    "          }\n",
    "  \n",
    "  OPTIONAL{?paper orkgp:P28 ?month_resrc.\n",
    "           BIND(IF(isLiteral(?month_resrc), ?month_resrc, \"\") AS ?month1)\n",
    "           OPTIONAL{?month_resrc rdfs:label ?month_label.}\n",
    "           BIND(IF(BOUND(?month_label),?month_label, \"\") AS ?month2)\n",
    "           BIND(IF(?month1 = \"\", ?month2, ?month1) AS ?month)\n",
    "          }\n",
    "  \n",
    "  OPTIONAL{?paper orkgp:P29 ?year_resrc.\n",
    "           BIND(IF(isLiteral(?year_resrc), ?year_resrc, \"\") AS ?year1)\n",
    "           OPTIONAL{?year_resrc rdfs:label ?year_label.}\n",
    "           BIND(IF(BOUND(?year_label),?year_label, \"\") AS ?year2)\n",
    "           BIND(IF(?year1 = \"\", ?year2, ?year1) AS ?year)\n",
    "          }\n",
    "  \n",
    "  OPTIONAL{?paper orkgp:url ?url.}\n",
    "  OPTIONAL{?paper orkgp:HAS_VENUE ?venue_resrc.\n",
    "           ?venue_resrc rdfs:label ?venue.}\n",
    "} ORDER BY ?paper\n",
    "        \"\"\"\n",
    "\n",
    "user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "\n",
    "sparql = SPARQLWrapper(ENDPOINT_URL, agent=user_agent)\n",
    "sparql.setQuery(PREFIXES+query)\n",
    "sparql.setReturnFormat(CSV)\n",
    "\n",
    "try:\n",
    "        results = sparql.queryAndConvert()\n",
    "except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "now = datetime.now()\n",
    "with open('query_result_' + now.strftime('%Y-%m-%d') + '.csv', 'wb') as file:\n",
    "        file.write(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Validation and Check\n",
    "1. Reading the data and checking the shape and column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('query_result_' + now.strftime('%Y-%m-%d') + '.csv', encoding='utf-8', encoding_errors='ignore')\n",
    "\n",
    "print('Shape of the dataframe: '+ str(df.shape))\n",
    "print('Column names: ' + str(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Checking for NaN values in each column for the entire dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_rows\", None)\n",
    "for column in df:\n",
    "    print(df[column].isna().value_counts(dropna=False).to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Derterming the number of NaN entries of the column **paper** and the number of unique papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.drop_duplicates(subset='paper')['paper'].value_counts(dropna=False).sum())\n",
    "print('Number of NaN entries: ' + str(df['paper'].isna().sum()))\n",
    "print('Number of unique papers: '+ str(df['paper'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Checking the number of unique papers per **research field** and the number of unique papers without a research field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_papers = df.drop_duplicates(subset='paper')\n",
    "print('Number of unique papers without a research field: ' + str(df_unique_papers['research_field'].isna().sum()))\n",
    "df_unique_papers['research_field'].value_counts().to_frame().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Checking the number of incorrect entries for the column **doi** and the number of unique papers without a DOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_DOIs = df_unique_papers[~df_unique_papers['doi'].str.startswith('10', na=False)]\n",
    "print('Number of incorrect DOIs :' + str(incorrect_DOIs['doi'].value_counts().sum()))\n",
    "print(incorrect_DOIs['doi'].value_counts().to_frame().head(15))\n",
    "print('Number of unique papers without a DOI: ' + str(df_unique_papers['doi'].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Checking the number of unique papers with a specific **title** and the number of unique papers without a title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique papers without a title: ' + str(df_unique_papers['title'].isna().sum()))\n",
    "df_unique_papers['title'].value_counts().loc[lambda x : x >= 2].to_frame().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique papers without a month: ' + str(df_unique_papers['month'].isna().sum()))\n",
    "print(df_unique_papers['month'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(md_df['year_number'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_df = md_df[['paper','field_label']].drop_duplicates()\n",
    "\n",
    "pd.set_option(\"max_rows\", None)\n",
    "field_df[['field_label']].value_counts(dropna=False)\n",
    "\n",
    "sns.countplot(y='field_label', data=field_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "nsfg['nbrnaliv'].replace([98,99], np.nan, inplace=True)\n",
    "\n",
    "df['paper'] = md_df['paper'].astype('str')\n",
    "df['field'] = md_df['field_label'].astype('category')\n",
    "df['DOI'] = md_df['DOI'].astype('str')\n",
    "df['title'] = md_df['title'].astype('str')\n",
    "df['author'] = md_df['name'].astype('str')\n",
    "df['orcid'] = md_df['id'].astype('str')\n",
    "df['month'] = md_df['month_number'].fillna(0.0).astype('int')\n",
    "df['year'] = md_df['year_number'].fillna(0.0).astype('int')\n",
    "df['url'] = md_df['paper_url'].astype('str')\n",
    "df['venue'] = md_df['venue_label'].astype('str')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16a8259e1791bb0fb9bae0f359302269cb6b9f3eeeb34666ca6d1d1ecd9183a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
