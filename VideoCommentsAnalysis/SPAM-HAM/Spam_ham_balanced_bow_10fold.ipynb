{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d5fc9f-743d-49f8-8a60-fd08f169fef3",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eba0fb8-4bce-4db5-938b-6b0b7b18891b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr.                   0\n",
      "Comment in English    0\n",
      "Spam / Ham            0\n",
      "Polarity              0\n",
      "Likes                 0\n",
      "Replies               0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "spam    3636\n",
       "ham      764\n",
       "Name: Spam / Ham, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "# Load the table in a dataframe for further data analysis\n",
    "comments_df = pd.read_csv('spam_or_ham_and_polarity.csv')\n",
    "\n",
    "# Check if the dataframe contains any empty cells. \n",
    "# If all columns have 0 empty cells than the dataframe is complete.\n",
    "print(comments_df.isna().sum())\n",
    "\n",
    "# Count the number of comments that are spam and ham\n",
    "comments_df['Spam / Ham'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46649e8-2ccc-483a-b796-3a959d0811fe",
   "metadata": {},
   "source": [
    "## 2. Creating a balanced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "937d9b99-a9ce-4872-a90a-7be7f0b42702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nr.</th>\n",
       "      <th>Comment in English</th>\n",
       "      <th>Spam / Ham</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Replies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2797.0</td>\n",
       "      <td>is it jst me or the idea is stupid nd it will ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146.0</td>\n",
       "      <td>Is it only for Tesla owners</td>\n",
       "      <td>spam</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2629.0</td>\n",
       "      <td>Price to make 100 billion</td>\n",
       "      <td>spam</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4390.0</td>\n",
       "      <td>This is amazing... how does Elon come up with ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1762.0</td>\n",
       "      <td>Anyone else find a design flaw with this video...</td>\n",
       "      <td>spam</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>4457.0</td>\n",
       "      <td>Why not just hyperloop it?</td>\n",
       "      <td>ham</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>4458.0</td>\n",
       "      <td>I don't think those platforms would be necessa...</td>\n",
       "      <td>ham</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>4459.0</td>\n",
       "      <td>Then you'll create more traffic above with peo...</td>\n",
       "      <td>ham</td>\n",
       "      <td>negative</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>4464.0</td>\n",
       "      <td>That looks extremely expensive and I understan...</td>\n",
       "      <td>ham</td>\n",
       "      <td>negative</td>\n",
       "      <td>285</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>4465.0</td>\n",
       "      <td>I don't know...this doesn't seem like a good i...</td>\n",
       "      <td>ham</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1528 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Nr.                                 Comment in English Spam / Ham  \\\n",
       "0     2797.0  is it jst me or the idea is stupid nd it will ...       spam   \n",
       "1      146.0                        Is it only for Tesla owners       spam   \n",
       "2     2629.0                          Price to make 100 billion       spam   \n",
       "3     4390.0  This is amazing... how does Elon come up with ...       spam   \n",
       "4     1762.0  Anyone else find a design flaw with this video...       spam   \n",
       "...      ...                                                ...        ...   \n",
       "1523  4457.0                         Why not just hyperloop it?        ham   \n",
       "1524  4458.0  I don't think those platforms would be necessa...        ham   \n",
       "1525  4459.0  Then you'll create more traffic above with peo...        ham   \n",
       "1526  4464.0  That looks extremely expensive and I understan...        ham   \n",
       "1527  4465.0  I don't know...this doesn't seem like a good i...        ham   \n",
       "\n",
       "      Polarity  Likes  Replies  \n",
       "0     negative      0        0  \n",
       "1      neutral      1        0  \n",
       "2      neutral      0        0  \n",
       "3     positive      0        0  \n",
       "4     negative      0        0  \n",
       "...        ...    ...      ...  \n",
       "1523   neutral      0        0  \n",
       "1524   neutral      0        0  \n",
       "1525  negative     23       11  \n",
       "1526  negative    285       17  \n",
       "1527  negative      2        3  \n",
       "\n",
       "[1528 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All comments that are labeled as ham\n",
    "ham = comments_df[comments_df['Spam / Ham'] == 'ham']\n",
    "\n",
    "# All comments that are labeled as spam\n",
    "spam = comments_df[comments_df['Spam / Ham'] == 'spam']\n",
    "\n",
    "# Use only as many spam comments as there are ham comments to have a balanced dataset\n",
    "spam = spam.sample(ham.shape[0])\n",
    "\n",
    "# Create a new balanced dataset\n",
    "balanced_comments_df = spam.append(ham, ignore_index = True)\n",
    "balanced_comments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bc44a9-f921-4988-9ad3-b1616a459eeb",
   "metadata": {},
   "source": [
    "## 3. Loading the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57cd6c56-7d61-468a-b774-2591c1211241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\KarrasO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d174066-3205-4e03-85a2-3ee29e35d4c9",
   "metadata": {},
   "source": [
    "## 4. Defining the BOW function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39e9bfbc-95b5-4b86-9f94-c8e764d66b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# only_letters, tokenization, stemming, stopwords_removal are boolean values\n",
    "# that decide how the text is going to be preprocessed\n",
    "def clean_text(only_letters, tokenization, stemming, stopwords_removal, comments):\n",
    "    \n",
    "    # Create a new Porter Stemmer object\n",
    "    porter_stemmer = PorterStemmer()\n",
    "\n",
    "    processed_comments_df = []\n",
    "\n",
    "    # Iterate through each comment in the balanced dataset\n",
    "    for i in range(len(comments)):\n",
    "        \n",
    "        comment = comments[i]\n",
    "        \n",
    "        if(only_letters):\n",
    "            # Keep only letters and spaces\n",
    "            comment = re.sub('[^a-zA-Z]', ' ', comment)\n",
    "            # Turn all letters to lower case\n",
    "            comment = comment.lower()\n",
    "\n",
    "        if(tokenization):\n",
    "            # Turn comment to tokens\n",
    "            comment = comment.split()\n",
    "\n",
    "        if(stemming):\n",
    "            # Do stemming\n",
    "            comment = [porter_stemmer.stem(word) for word in comment]\n",
    "\n",
    "        if(stopwords_removal):\n",
    "            # Remove stop words\n",
    "            comment = [word for word in comment if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "        if(tokenization): # Join words again to form a text\n",
    "            comment = \" \".join(comment)\n",
    "        \n",
    "        # Add processed comment \n",
    "        processed_comments_df.append(comment)\n",
    "        \n",
    "    return processed_comments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54c20bc-37de-4151-a2c6-322a30d209b2",
   "metadata": {},
   "source": [
    "## 5. Performing 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c97367f9-850c-4aeb-a667-6c0a5ae5aa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LR\n",
      "Accuracy: 0.8088966288269693\n",
      "F1Score: 0.808538997389012\n",
      "FbScore: 0.8092999118002207\n",
      "Recall: 0.8094415982762155\n",
      "Precision: 0.8108718967096997\n",
      "Model: SVM\n",
      "Accuracy: 0.801702786377709\n",
      "F1Score: 0.8014027794947459\n",
      "FbScore: 0.8019908532141098\n",
      "Recall: 0.8020877526228356\n",
      "Precision: 0.8027910403019177\n",
      "Model: RF\n",
      "Accuracy: 0.801685586515308\n",
      "F1Score: 0.8015794502983947\n",
      "FbScore: 0.8022729949542027\n",
      "Recall: 0.8023604940071477\n",
      "Precision: 0.8023094762887689\n",
      "Model: NB\n",
      "Accuracy: 0.6760534915720673\n",
      "F1Score: 0.6693902341801424\n",
      "FbScore: 0.6754071206412011\n",
      "Recall: 0.6765916617122827\n",
      "Precision: 0.6919706280859296\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, fbeta_score\n",
    "\n",
    "# Get the comments of the balanced data set\n",
    "X = balanced_comments_df['Comment in English'].astype('U').values\n",
    "\n",
    "# Get the labels of the comments of the balanced data set\n",
    "y = balanced_comments_df['Spam / Ham'].values\n",
    "\n",
    "# Apply bow to the comments\n",
    "X_vec = CountVectorizer().fit_transform(clean_text(True, True, True, True, X))\n",
    "\n",
    "# Define 10fold crossvalidation\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# Function to create the reporting for the single algorithms consisting of the average precision, recall, f1, and accuracy\n",
    "def reporting(name, model):       \n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    fbs = []\n",
    "    \n",
    "    # Perform the 10folds\n",
    "    for train_index, val_index in cv.split(X_vec):\n",
    "        # Train the model\n",
    "        model.fit(X_vec[train_index].toarray(), y[train_index])\n",
    "        # Predict the labels of the test data\n",
    "        pred = model.predict(X_vec[val_index].toarray())\n",
    "        \n",
    "        # Get the report for the currnt fold\n",
    "        report = classification_report(y[val_index], pred, output_dict=True)\n",
    "        fb = fb = fbeta_score(y[val_index], pred, average='macro', beta=5.76)\n",
    "        \n",
    "        # Add the single measures of the current fold to the array for calculating the averages \n",
    "        accuracies.append(report['accuracy'])\n",
    "        macro_avg = report['macro avg']\n",
    "        precisions.append(macro_avg['precision']) \n",
    "        recalls.append(macro_avg['recall'])\n",
    "        f1s.append(macro_avg['f1-score'])\n",
    "        fbs.append(fb)\n",
    "        \n",
    "        # If needed, the confusion matrix of the fold can be visualized\n",
    "        #confusion_matrix_rf_balanced = confusion_matrix(y[val_index], pred)\n",
    "        # Plot the confusion matrix for Voting Classifier\n",
    "        #display_labels = ['Ham', 'Spam']\n",
    "\n",
    "        #disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_rf_balanced, display_labels=display_labels)\n",
    "        #disp = disp.plot(cmap = 'viridis')\n",
    "        #plt.grid(False)\n",
    "        #plt.rcParams.update({'font.size': 15})\n",
    "        #plt.tight_layout()\n",
    "    \n",
    "    # Print the average values of the metrics for current model\n",
    "    print('Model:', name)\n",
    "    print('Accuracy:', sum(accuracies) / len(accuracies))\n",
    "    print('F1Score:', sum(f1s) / len(f1s))\n",
    "    print('FbScore:', sum(fbs) / len(fbs))\n",
    "    print('Recall:', sum(recalls) / len(recalls))\n",
    "    print('Precision:', sum(precisions) / len(precisions))\n",
    "    #print()\n",
    "    #print(sum(accuracies) / len(accuracies))\n",
    "    #print(sum(f1s) / len(f1s))\n",
    "    #print(sum(fbs) / len(fbs))\n",
    "    #print(sum(recalls) / len(recalls))\n",
    "    #print(sum(precisions) / len(precisions))\n",
    "    \n",
    "# Create the models we want to test\n",
    "model1 = LogisticRegression()\n",
    "model2 = SVC()\n",
    "model3 = GaussianNB()\n",
    "model4 = RandomForestClassifier()\n",
    "\n",
    "# Create the reportings\n",
    "reporting('LR', model1)\n",
    "reporting('SVM', model2)\n",
    "reporting('RF', model4)\n",
    "reporting('NB', model3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
