{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b242497-a5cf-4719-b4d6-7d4044b48c50",
   "metadata": {},
   "source": [
    "## 1. Loading the data and creating balanced data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f46dfa2b-927e-42fb-b0b6-1eb502cd7655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr.                   0\n",
      "Comment in English    0\n",
      "Spam / Ham            0\n",
      "Polarity              0\n",
      "Feature Request       0\n",
      "Problem Report        0\n",
      "Safety                0\n",
      "Efficiency            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "# Load the table in a dataframe for further data analysis\n",
    "comments_df = pd.read_csv('ham_comments_multiclass.csv')\n",
    "\n",
    "# Replace all empty cells with no_aspect and the cells containing x with respective aspect\n",
    "comments_df.fillna('no_aspect', inplace=True)\n",
    "comments_df[\"Feature Request\"].replace({'x': 'feature'}, inplace=True)\n",
    "comments_df[\"Problem Report\"].replace({'x': 'problem'}, inplace=True)\n",
    "comments_df[\"Safety\"].replace({'x': 'safety'}, inplace=True)\n",
    "comments_df[\"Efficiency\"].replace({'x': 'efficiency'}, inplace=True)\n",
    "\n",
    "# Check if the dataframe contains any empty cells. \n",
    "# If all columns have 0 empty cells than the dataframe is complete.\n",
    "print(comments_df.isna().sum())\n",
    "\n",
    "# Extract all comments where the subject is feature request\n",
    "feature = comments_df[comments_df['Feature Request'] == 'feature']\n",
    "\n",
    "# Extract all comments where the subject is not feature request\n",
    "no_feature = comments_df[comments_df['Feature Request'] == 'no_aspect']\n",
    "\n",
    "# Extract all comments where the subject is problem report\n",
    "problem = comments_df[comments_df['Problem Report'] == 'problem']\n",
    "\n",
    "# Extract all comments where the subject is not problem report\n",
    "no_problem = comments_df[comments_df['Problem Report'] == 'no_aspect']\n",
    "\n",
    "# Extract all safety related comments\n",
    "safety = comments_df[comments_df['Safety'] == 'safety']\n",
    "\n",
    "# Extract all comments not related to safety\n",
    "no_safety = comments_df[comments_df['Safety'] == 'no_aspect']\n",
    "\n",
    "# Extract all efficiency related comments\n",
    "efficiency = comments_df[comments_df['Efficiency'] == 'efficiency']\n",
    "\n",
    "# Extract all comments not related to efficiency\n",
    "no_efficiency = comments_df[comments_df['Efficiency'] == 'no_aspect']\n",
    "\n",
    "# Use only as many no_feature comments as there are feature comments to have a balanced dataset\n",
    "no_feature = no_feature.sample(feature.shape[0])\n",
    "problem = problem.sample(no_problem.shape[0])\n",
    "no_safety = no_safety.sample(safety.shape[0])\n",
    "no_efficiency = no_efficiency.sample(efficiency.shape[0])\n",
    "\n",
    "# Create new balanced datasets\n",
    "balanced_feature_df = no_feature.append(feature, ignore_index = True)\n",
    "balanced_problem_df = no_problem.append(problem, ignore_index = True)\n",
    "balanced_safety_df = no_safety.append(safety, ignore_index = True)\n",
    "balanced_efficiency_df = no_efficiency.append(efficiency, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bea0cd3-745e-4d56-ba21-f796701827b5",
   "metadata": {},
   "source": [
    "## 2. Loading the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "290a2061-c4d2-4fa3-98d4-b96ed177196b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\KarrasO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579fc8f1-4279-4329-9ed0-9b4910d7e240",
   "metadata": {},
   "source": [
    "## 3. Defining the BOW function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afec7735-bf98-41ad-ba7d-a7d45fb6df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# only_letters, tokenization, stemming, stopwords_removal are boolean values\n",
    "# that decide how the text is going to be preprocessed\n",
    "def clean_text(only_letters, tokenization, stemming, stopwords_removal, comments):\n",
    "    \n",
    "    # Create a new Porter Stemmer object\n",
    "    porter_stemmer = PorterStemmer()\n",
    "\n",
    "    processed_comments_df = []\n",
    "\n",
    "    # Iterate through each comment in the balanced dataset\n",
    "    for i in range(len(comments)):\n",
    "        \n",
    "        comment = comments[i]\n",
    "        \n",
    "        if(only_letters):\n",
    "            # Keep only letters and spaces\n",
    "            comment = re.sub('[^a-zA-Z]', ' ', comment)\n",
    "            # Turn all letters to lower case\n",
    "            comment = comment.lower()\n",
    "\n",
    "        if(tokenization):\n",
    "            # Turn comment to tokens\n",
    "            comment = comment.split()\n",
    "\n",
    "        if(stemming):\n",
    "            # Do stemming\n",
    "            comment = [porter_stemmer.stem(word) for word in comment]\n",
    "\n",
    "        if(stopwords_removal):\n",
    "            # Remove stop words\n",
    "            comment = [word for word in comment if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "        if(tokenization): # Join words again to form a text\n",
    "            comment = \" \".join(comment)\n",
    "        \n",
    "        # Add processed comment \n",
    "        processed_comments_df.append(comment)\n",
    "        \n",
    "    return processed_comments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0477d73-e095-486f-a36d-6d1f5f52b842",
   "metadata": {},
   "source": [
    "## 4. Performing 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8308a83c-7bdc-4cea-98d6-352765a862ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE\n",
      "Model: LR\n",
      "Accuracy: 0.7149014778325123\n",
      "F1Score: 0.7104785668016431\n",
      "FbScore: 0.7166946802756134\n",
      "Recall: 0.7177477302109655\n",
      "Precision: 0.7213898193309959\n",
      "Model: SVM\n",
      "Accuracy: 0.7045566502463054\n",
      "F1Score: 0.7006952627112062\n",
      "FbScore: 0.7063737178994354\n",
      "Recall: 0.7073245912584148\n",
      "Precision: 0.7103506127944982\n",
      "Model: RF\n",
      "Accuracy: 0.7216748768472907\n",
      "F1Score: 0.7187183358648573\n",
      "FbScore: 0.7251437243217346\n",
      "Recall: 0.7261427869516105\n",
      "Precision: 0.7266456990721696\n",
      "Model: NB\n",
      "Accuracy: 0.6660098522167488\n",
      "F1Score: 0.6587399063976905\n",
      "FbScore: 0.6626462932793279\n",
      "Recall: 0.6634020432182198\n",
      "Precision: 0.668319046794279\n",
      "PROBLEM\n",
      "Model: LR\n",
      "Accuracy: 0.6647887323943662\n",
      "F1Score: 0.6626354730755122\n",
      "FbScore: 0.6647701078695594\n",
      "Recall: 0.669967129467983\n",
      "Precision: 0.6708381087439422\n",
      "Model: SVM\n",
      "Accuracy: 0.6464788732394366\n",
      "F1Score: 0.6424755631210253\n",
      "FbScore: 0.6441082806195617\n",
      "Recall: 0.6490516435767002\n",
      "Precision: 0.6525336971270338\n",
      "Model: RF\n",
      "Accuracy: 0.6563380281690142\n",
      "F1Score: 0.6543174905168024\n",
      "FbScore: 0.6559255924416811\n",
      "Recall: 0.6602607430795284\n",
      "Precision: 0.6615364466697646\n",
      "Model: NB\n",
      "Accuracy: 0.5563380281690141\n",
      "F1Score: 0.5442712286831574\n",
      "FbScore: 0.5479780485215737\n",
      "Recall: 0.5570510558621472\n",
      "Precision: 0.5613549922180253\n",
      "SAFETY\n",
      "Model: LR\n",
      "Accuracy: 0.8332309267793139\n",
      "F1Score: 0.8316530808874827\n",
      "FbScore: 0.8331519258634119\n",
      "Recall: 0.8345789459929265\n",
      "Precision: 0.8346079589408391\n",
      "Model: SVM\n",
      "Accuracy: 0.7996927803379416\n",
      "F1Score: 0.796731425034797\n",
      "FbScore: 0.7980487335911058\n",
      "Recall: 0.8010129755336838\n",
      "Precision: 0.8100963587857013\n",
      "Model: RF\n",
      "Accuracy: 0.8077572964669738\n",
      "F1Score: 0.8047667838527313\n",
      "FbScore: 0.8057240836294435\n",
      "Recall: 0.8080794497197233\n",
      "Precision: 0.8156482324258573\n",
      "Model: NB\n",
      "Accuracy: 0.6761136712749616\n",
      "F1Score: 0.6642466194726688\n",
      "FbScore: 0.6678066612286113\n",
      "Recall: 0.674712353263234\n",
      "Precision: 0.695296471777386\n",
      "EFFICIENCY\n",
      "Model: LR\n",
      "Accuracy: 0.7375\n",
      "F1Score: 0.7337247250903266\n",
      "FbScore: 0.7392895151182663\n",
      "Recall: 0.7407647359949991\n",
      "Precision: 0.7487185621396149\n",
      "Model: SVM\n",
      "Accuracy: 0.71875\n",
      "F1Score: 0.7159921898401873\n",
      "FbScore: 0.7200254193524723\n",
      "Recall: 0.7208125661318386\n",
      "Precision: 0.7202974598930482\n",
      "Model: RF\n",
      "Accuracy: 0.753125\n",
      "F1Score: 0.7504720734438826\n",
      "FbScore: 0.7541024862522396\n",
      "Recall: 0.7548070569781096\n",
      "Precision: 0.7545593009931245\n",
      "Model: NB\n",
      "Accuracy: 0.596875\n",
      "F1Score: 0.5915939345156449\n",
      "FbScore: 0.6013619196920137\n",
      "Recall: 0.603361039974817\n",
      "Precision: 0.6046740832267148\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, fbeta_score\n",
    "\n",
    "# Get the comments of the balanced data sets for each aspect\n",
    "X1 = balanced_feature_df['Comment in English'].astype('U').values\n",
    "X2 = balanced_problem_df['Comment in English'].astype('U').values\n",
    "X3 = balanced_safety_df['Comment in English'].astype('U').values\n",
    "X4 = balanced_efficiency_df['Comment in English'].astype('U').values\n",
    "\n",
    "# Get the labels of the comments of the balanced data set for each aspect\n",
    "y1 = balanced_feature_df['Feature Request'].values\n",
    "y2 = balanced_problem_df['Problem Report'].values\n",
    "y3 = balanced_safety_df['Safety'].values\n",
    "y4 = balanced_efficiency_df['Efficiency'].values\n",
    "\n",
    "# Apply bow to the comments of the balanced data set for each aspect\n",
    "X1_vec = CountVectorizer().fit_transform(clean_text(True, True, True, True, X1))\n",
    "X2_vec = CountVectorizer().fit_transform(clean_text(True, True, True, True, X2))\n",
    "X3_vec = CountVectorizer().fit_transform(clean_text(True, True, True, True, X3))\n",
    "X4_vec = CountVectorizer().fit_transform(clean_text(True, True, True, True, X4))\n",
    "\n",
    "# Define 10fold crossvalidation\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# Function to create the reporting for the single algorithms and aspect consisting of the average precision, recall, f1, and accuracy\n",
    "def reporting(name, model, feature, data, fb_value):       \n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    fbs = []\n",
    "\n",
    "    # Perform the 10folds\n",
    "    for train_index, val_index in cv.split(data):\n",
    "        # Train the model\n",
    "        model.fit(data[train_index].toarray(), feature[train_index])\n",
    "        # Predict the labels of the test data\n",
    "        pred = model.predict(data[val_index].toarray())\n",
    "        \n",
    "        # Get the report for the currnt fold\n",
    "        report = classification_report(feature[val_index], pred, output_dict=True)\n",
    "        fb = fbeta_score(feature[val_index], pred, average='macro', beta = fb_value)\n",
    "        \n",
    "        # Add the single measures of the current fold to the array for calculating the averages \n",
    "        accuracies.append(report['accuracy'])\n",
    "        macro_avg = report['macro avg']\n",
    "        precisions.append(macro_avg['precision']) \n",
    "        recalls.append(macro_avg['recall'])\n",
    "        f1s.append(macro_avg['f1-score'])\n",
    "        fbs.append(fb)\n",
    "        \n",
    "        # If needed, the confusion matrix of the fold can be visualized\n",
    "        #confusion_matrix_rf_balanced = confusion_matrix(feature[val_index], pred)\n",
    "        # Plot the confusion matrix for Voting Classifier\n",
    "        #display_labels = ['Aspect', 'NOT_Aspect']\n",
    "\n",
    "        #disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_rf_balanced, display_labels=display_labels)\n",
    "        #disp = disp.plot(cmap = 'viridis')\n",
    "        #plt.grid(False)\n",
    "        #plt.rcParams.update({'font.size': 15})\n",
    "        #plt.tight_layout()\n",
    "    \n",
    "    # Print the average values of the metrics for current model and aspect\n",
    "    print('Model:', name)\n",
    "    print('Accuracy:', sum(accuracies) / len(accuracies))\n",
    "    print('F1Score:', sum(f1s) / len(f1s))\n",
    "    print('FbScore:', sum(fbs) / len(fbs))\n",
    "    print('Recall:', sum(recalls) / len(recalls))\n",
    "    print('Precision:', sum(precisions) / len(precisions))\n",
    "    \n",
    "    #print()\n",
    "    #print(sum(accuracies) / len(accuracies))\n",
    "    #print(sum(f1s) / len(f1s))\n",
    "    #print(sum(fbs) / len(fbs))\n",
    "    #print(sum(recalls) / len(recalls))\n",
    "    #print(sum(precisions) / len(precisions))\n",
    "    \n",
    "# Create the models we want to test\n",
    "model1 = LogisticRegression()\n",
    "model2 = SVC()\n",
    "model3 = GaussianNB()\n",
    "model4 = RandomForestClassifier()\n",
    "\n",
    "# Create the reportings\n",
    "print('FEATURE')\n",
    "reporting('LR', model1, y1, X1_vec, 5.38)\n",
    "reporting('SVM', model2, y1, X1_vec, 5.38)\n",
    "reporting('RF', model4, y1, X1_vec, 5.38)\n",
    "reporting('NB', model3, y1, X1_vec, 5.38)\n",
    "print('PROBLEM')\n",
    "reporting('LR', model1, y2, X2_vec, 1.87)\n",
    "reporting('SVM', model2, y2, X2_vec, 1.87)\n",
    "reporting('RF', model4, y2, X2_vec, 1.87)\n",
    "reporting('NB', model3, y2, X2_vec, 1.87)\n",
    "print('SAFETY')\n",
    "reporting('LR', model1, y3, X3_vec, 2.45)\n",
    "reporting('SVM', model2, y3, X3_vec, 2.45)\n",
    "reporting('RF', model4, y3, X3_vec, 2.45)\n",
    "reporting('NB', model3, y3, X3_vec, 2.45)\n",
    "print('EFFICIENCY')\n",
    "reporting('LR', model1, y4, X4_vec, 4.78)\n",
    "reporting('SVM', model2, y4, X4_vec, 4.78)\n",
    "reporting('RF', model4, y4, X4_vec, 4.78)\n",
    "reporting('NB', model3, y4, X4_vec, 4.78)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
